\chapter{Conclusion}

In this thesis we have considered uncertainties in the theoretical predictions that go into PDF fits, and how these theory uncertainties can impact the PDFs, both in changes to the PDFs' central valus and in changes to their uncertainties. In Chapter~\ref{chapter:thuncs} we showed how, under the assumptions that the theory uncertainties are Gaussian and independent of the experimental data, they can be included in PDF fits. This is by simply adding a theory covariance matrix to the existing experimental covariance matrix, so that uncertainties from theory and experiment stand on an equal footing. This theory covariance matrix is the covariance between the theoretical predictions and the unknown ``true" values fron nature.

The complexity of this procedure lies primarily in constructing the theory covariance matrix, which cannot be determined exactly due to our lack of knowledge of the underlying truth. Instead we can consider a series of nuisance parameters which encapsulate the size of the shifts between predicted values and true values. This theory covariance matrix then acts as a prior when it is included in a PDF fit. We can in principle recalculate it using the new information obtained by the fit and then iterate to convergence. However, for a well determined prior this convergence should be fast. 

We applied this procedure for including theory uncertainties in PDF fits to some of the dominant sources of uncertainties: missing higher order uncertainties (MHOUs, Chapter~\ref{chapter:mhous}) and nuclear uncertainties (Chapter~\ref{chapter:nuclear}). MHOUs, which arise from the use of predictions to less than all orders in perturbation theory, were estimated using the established method of scale variation, where the artificial factorisation and renormalisation scales are varied to obtain a set of predictions. We developed multiple prescriptions for combining these variations into a covariance matrix, and carried out PDF fits at NLO using the different prescriptions. We checked the efficacy of the prescriptions by comparing to the known results at NNLO. We adopted the ``9 point" prescription, which performs the best, and encapsulates many features of the missing higher orders. We note that limitations in this prescription arise from the  coarse categorisation of data into different processes, and the use of only one factorsation scale. For example, CHORUS data are categorised as charged current DIS, but in reality have a component of charged current and of neutral current. The factorisation scale variation could also be split up at the least into a singlet and a non-singlet component, to allow a better exploration of scale variation space. We saw that a large part of the missing higher orders that weren't encapsulated by the 9 point prescription was correlated globally, suggesting that this could be linked to the factorsation scale.

Nuclear uncertainties come from the use of data for deuteron and nuclear targets in fits for proton PDFs. The nuclear environment causes changes to the observables which are hard to quantify precisely, and these propagate through to the PDFs. To estimate the uncertainties we used an empirical approach using nuclear PDFs, which contain information about the nuclear environment. We constructed one nuclear covariance matrix for the deuteron data and one for the heavy nuclear data. We included these as default in the imminent NNPDF4.0 determination, both at NLO and NNLO, noting that they help to resolve tension between the nuclear and Drell-Yan data. 

Finally, we considered the use of PDFs in making physics predictions, and how this is complicated by the presence of theory uncertainties. Theory uncertainties must be included in the PDF and in the prediction itself, but there exist correlations between these two which must be taken into account, otherwise the overall uncertainty will be inflated. We determined formulae for computing these correlations, and used them to make fully correlated predictions with theory uncertainties. We showed that when fitting a PDF a combination of Bayesian learning of information from the experimental data during the fitting process, and correlations between the fit and the predictions, result in both more accurate and more precise predictions, and an improvement in $\chi^2$. The improvement in accuracy and precision is dependent on the type of prediction being made, whereby predictions with a closer proximity to data in the fit (in terms of process type and kinematics) will be more significantly updated.

This work extends naturally to the systematic inclusion of theory uncertainties from other sources. These include: uncertainties due to chosen values of parameters such as the strong coupling constant and the quark masses; and uncertainties due to unknown higher twist contributions to the predictions. These are both the subject of current investigation, but will contribute smaller effects than MHOUs and nuclear uncertainties. Furthermore, the work on MHOUs will be extended to NNLO and become standard in future NNPDF releases. The extension from NLO to NNLO is conceptually trivial but requires technical hurdles to be overcome. Doing this upgrade would also be a good time to consider more complex renormalisation and factorisation scale splittings. 