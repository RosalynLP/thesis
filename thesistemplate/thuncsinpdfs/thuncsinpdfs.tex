\chapter{Theory uncertainties in PDFs - 10\%}
\bi 
\item What are theory uncertainties?
\item Why are they now important?
\item Types of unc - see below
\item Bayesian interpretation of these uncertainties - there is one "true" value e.g. for the higher order value, so need to estimate uncertainty bc will never know the size of e.g. MHOU unless you go ahead and calc - maybe ref d'Agostini paper on Bayesian interpretation
\item Will use Bayesian framework and assume Gaussianity of the expected true value of theory calc
\item Show C+S in fit - plus sign because exp and th unc are independent so combine errors in quadrature. They are also on an equal footing in terms of their effect on the PDFs
\item When many datasets/global fit, can have v strong theory correlations even across different experiments, because the underlying theory connects them

\ei
\section{Fitting PDFs including theory uncertainties}
Historically, experimental uncertainties have been the dominant source of error in PDF fits. 
In the NNPDF framework both replica generation and computation of $\chi^2$ 
are currently based entirely on these. We must now try to match the ongoing drive to 
increase experimental precision by including errors introduced at the theoretical level. This is
especially important given recent data sets such as the $Z$ boson transverse momentum
distributions~\cite{Aad:2014xaa,Khachatryan:2015oaa,Aad:2015auj}, which have very high experimental precision. Without
the inclusion of theoretical errors, this has led to tension with the other datasets.

In future NNPDF fits theoretical uncertainties will be included following a procedure outlined
by Ball \& Desphande \cite{Ball:2018odr}. This hinges on a result from Bayesian statistics
which applies to Gaussian errors. Namely, theory uncertainties can be included by directly 
adding a theoretical
covariance matrix to the experimental covariance matrix prior to the fitting. A brief summary of
the derivation is given below.

When determining PDFs we incorporate information from experiments in the form of $N_{dat}$ experimental data points $D_i$, $i=1,...,N_{dat}$. The associated uncertainties and their correlations are encapsulated in an experimental covariance matrix $C_{ij}$. Parts of the matrix which associate two independent experiments will be populated by zeros. However we would expect there to be correlations between data points from the same detector, for example.

Each data point is a measurement of some fundamental ``true" value, $\truev_i$, dictated by the underlying physics. In order to make use of the data in a Bayesian framework, we assume that the experimental values follow a Gaussian distribution about the unknown $\truev$. Then, assuming the same prior for $D$ and $\truev$, we can write an expression for the conditional probability of $\truev$ given the known data $D$:
\beq
\label{eqn:gaussexp}
P(\truev|D) = P(D|\truev) \propto \exp\bigg( -\frac{1}{2}(\truev_i-D_i)C_{ij}^{-1}(\truev_j - D_j)\bigg).
\eeq
However, in a PDF fit we cannot fit to the unknown true values $\truev$, and must make do with predictions based on current theory $T_i$. This is the origin of theory uncertainties in PDF fits; where our theory is incomplete, fails to describe the physics well enough, or where approximations are made, we will introduce all kinds of subtle biases into the PDF fit. The theory predictions themselves also depend on PDFs, so uncertainties already present in the PDFs are propagated through. This, in particular, leads to a high level of correlation because the PDFs are universal, and shared between all the theory predictions. 

We can take a similar approach when writing an expression for the conditional probability of the true values $\truev$ given the available theory predictions $T$, by assuming that the true values are Gaussianly distributed about the theory predictions.
\beq
\label{eqn:gausstheory}
P(\truev|T) = P(T|\truev) \propto \exp\bigg( -\frac{1}{2}(\truev_i-T_i)S_{ij}^{-1}(\truev_j - T_j)\bigg),
\eeq
where $S_{ij}$ is a ``theory covariance matrix" encapsulating the magnitude and correlation of the various theory errors. We will need to do some work to determine $S_{ij}$ for the different sources of error, and this will be outlined in detail in the following chapters. 

When we fit PDFs we aim to maximise the probability that a PDF-dependent theory is true given the experimental data available. This amounts to maximising $P(T|D)$, marginalised over the unknown true values $\truev$. To make this more useful for fitting purposes, we can relate this to $P(D|T)$ using Bayes' Theorem:
\beq
P(D|T)P(\truev |DT) = P(\truev |T)P(D|\truev T),
\eeq
where we note that the experimental data $D$ do not depend on our modelled values $T$, so $P(D|\truev T) = P(D|\truev)$. So we can integrate Bayes' Theorem over the possible values of the $N$-dimensional true values $\truev$:
\beq
\int D^N \truev P(D|T)P(\truev |DT) = \int D^N \truev P(\truev |T) P(D|\truev), 
\eeq
and, because $\int D^N \truev P(\truev |TD) = 1$ as all possible probabilities for the true values must sum to one, 
\beq
P(D|T) =  \int D^N \truev P(\truev |T) P(D|\truev). 
\eeq
We can always write the theory predictions $T$ in terms of their shifts $\D$ relative the true values $\truev$:
\beq
\D_i \equiv \truev_i - T_i.
\eeq
These shifts quantify the accuracy of the theoretical predictions, and can be thought of as nuisance parameters in the PDF fit. We can express the above integral in terms of the shifts $\D_i$, making use of the assumptions of Gaussianity in Eqns. \ref{eqn:gaussexp} and \ref{eqn:gausstheory}:
\beq
\begin{split}
\label{eq:probdatgivth}
P(D|T) &\propto \int D^N \D \exp \bigg(-\frac{1}{2}(D_i - T_i -\D_i)\\
&\times C_{ij}^{-1} (D_j -T_j -\D_j) - \frac{1}{2}\D_i S_{ij}^{-1} \D_j \bigg).
\end{split}
\eeq
To evalute the Gaussian integrals, consider the exponent: switching to a vector notation for the time being, we can expand this out and then complete the square, making use of the symmetry of $S$ and $C$:
\bdm
(D-T-\D)^T C^{-1}(D-T-\D) + \D^T S^{-1} \D  
= D^T(C^{-1} + S^{-1})\D -\D^T C^{-1} (D-T)
 - (D-T)^T C^{-1}\D + (D-T)^T C^{-1}(D-T) 
= (\D - (C^{-1} + S^{-1})^{-1} C^{-1}(D-T))^T(C^{-1}+S^{-1}) 
\times (\D - (C^{-1} + S^{-1})^{-1} C^{-1}(D-T)) 
-(D-T)^TC^{-1}(C^{-1} + S^{-1})^{-1}C^{-1}(D-T) 
+(D-T)^T C^{-1}(D-T).
\edm
Now, integrating Eqn. \ref{eq:probdatgivth} over $\D$ leads to a constant from the Gaussian integrals, which we can absorb, and only the parts of the exponent without $\D$ remain:
\bdm
P(T|D) = P(D|T) \propto \exp \bigg(-\frac{1}{2}(D-T)^T (C^{-1}-C^{-1}(C^{-1}+S^{-1})^{-1}C^{-1})(D-T) \bigg).
\edm
We can further simplify this by noting that
\bdm
(C^{-1}+S^{-1})^{-1} = (C^{-1}(C+S)S^{-1})^{-1} = S(C+S)^{-1}C,
\edm
which means we can rewrite
\bdm
C^{-1}-C^{-1}(C^{-1}+S^{-1})^{-1}C^{-1} = C^{-1} - C^{-1}S(C+S)^{-1} = (C^{-1}(C+S)-C^{-1}S)(C+S)^{-1} =(C+S)^{-1}.
\edm
Finally, with indices restored we are left with 
\bdm
P(T|D) \propto \exp \bigg(-\frac{1}{2}(D_i-T_i)(C+S)^{-1}_{ij}(D_j-T_j) \bigg).
\edm
Comparing this result to Eqn. \ref{eqn:gaussexp}, we can confirm that when we possess theoretical predictions, $T_i$, rather than true values, $\truev_i$, we can account for this by adding a theoretical covariance matrix, $S_{ij}$ to the experimental covariance matrix, $C_{ij}$ \cite{Ball:2018odr}. This means the theory uncertainties are on an equal footing with experimental systematic uncertainties. Note that $C_{ij}$ is positive definite by construction and so $(C+S)_{ij}$ is always invertible, even if $S_{ij}$ has negative eigenvalues.

Now all that remains is to construct a theory covariance matrix which parametrises each instance of theoretical uncertainty. This is a nebulous task, given that we are not privy to the true values, $\truev$, and so are unable to simply apply the formal definition
\beq
S_{ij} = \langle (\truev_i - T_i) (\truev_j - T_j) \rangle,
\eeq
where $\langle \cdot \rangle$ denotes an average over true values, $\truev$. We need to find methods to calculate the various contributions $S_{ij}$ (be them MHOUs, nuclear corrections, higher twist corrections etc.) which not only encapsulate the per-point theoretical errors but also preserve the correlations between different data points. Unlike experimental uncertainties, these correlations can exist outwith individual experiments; in fact, all data in PDF fits depend themselves on PDFs, and this common link will lead to correlations between all datapoints, albeit of varying strength. 

The following chapters address several important types of theoretical uncertainties: MHOUs; nuclear uncertainties; deuteron uncertainties. For each type, we show how to construct a theoretical covariance matrix, and present and discuss the results of PDF fits including these covariance matrices.
