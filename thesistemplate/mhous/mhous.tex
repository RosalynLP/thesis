\section{Introduction}
\label{sec:introduction}

An accurate estimate of the uncertainty in Standard Model (SM) predictions
is a crucial ingredient for precision phenomenology at the Large Hadron 
Collider (LHC).
%
Now, and for several years to come~\cite{Cepeda:2019klc,Azzi:2019yne},
theoretical 
uncertainties for hadron collider processes are
dominated by the missing higher order uncertainty (MHOU) in perturbative 
QCD calculations, usually estimated by scale 
variation, and by parton distribution function (PDF) uncertainties.
%
Of course, PDFs 
summarize the information on the nucleon structure extracted from other
SM processes~\cite{Gao:2017yyd}: effectively, PDFs provide a way of obtaining
a prediction for a given process in terms of other processes.
%
This way of thinking
about PDFs immediately shows that MHOUs are present 
not only in the perturbative prediction for a particular process, but 
also in the underlying processes used for the PDF determination.

Current PDF uncertainties essentially only
include the propagated uncertainty arising from statistical and
systematic uncertainties in the experimental data used in their 
determination.
%
Methodological uncertainties related for example to
the choice of functional form for the PDFs, or the fitting methodology employed, can be kept under control using closure tests~\cite{Ball:2014uwa}, and with care can be made negligible in the data region.
%
Parametric uncertainties, such as those related to the value of
the strong coupling $\alpha_s(m_Z)$ or the charm mass $m_c$ can be included by 
performing fits for a range of parameters.
%
However up until now MHOUs have never been included in a PDF fit: what is 
usually called the ``PDF uncertainty'' does not include 
the MHOU in the theoretical calculations used for PDF determination, and, 
more generally, does not typically include any source of theory 
uncertainty. 

Historically,
this is related to the fact that MHOUs
have always been
considered as likely to be small in comparison to other
PDF uncertainties, especially since NNLO PDFs have become the default
standard.
%
However, it is clear that as PDF uncertainties become
smaller and smaller, at some point MHOUs will become significant. 
In the most recent NNPDF set, NNPDF3.1~\cite{Ball:2017nwa}, PDF
uncertainties at the electroweak scale can be as low as 1\%.
%
Given that the
typical size of MHOU on NNLO QCD processes is at the percent level (see
e.g.~\cite{Campbell:2017hsr}) their neglect seems difficult to justify a priori.


Besides contributing to the overall size of PDF uncertainty, more subtly the MHOU might affect the relative weights of different datasets 
included in the fit: a dataset which is accurately described by NNLO theory because it has small MHOU should in principle carry more weight than one which is poorly described because it has large MHOU. The neglect of MHOUs might thus be biasing current global PDF fits.

It is the purpose of this paper to set up a general formalism for the
inclusion of theoretical uncertainties, specifically MHOUs, in PDF
determinations, and then to perform a first phenomenological
exploration of their impact on LHC phenomenology.
%
The development of this treatment of MHOUs will involve three main ingredients.
%
The first
is the formulation of a general theory for the inclusion  in PDF fits of
generic theoretical uncertainties, of which MHOUs are a particular
case.
%
The second is the choice of a specific method for estimating the 
MHOU in each of the cross-sections that enter the PDF fit.
%
The third is the construction of a set of tools for the
validation of this methodology, to check that the MHOU is being correctly 
estimated.

The first ingredient in our approach is common to any kind of theory 
uncertainty: theory uncertainties include not only MHOUs, but also any other aspect in which the theory used in order to obtain
predictions for the physical processes that enter the PDF fit is 
incompletely known. These
include higher twists~\cite{Ball:2013gsa} and other power-suppressed corrections, nuclear
corrections when nuclear targets are involved~\cite{Ball:2018twp}, final state corrections for non-inclusive processes, and so forth.
%
All of these uncertainties are only meaningful in a
Bayesian sense: there is only one correct value of the
next-order perturbative correction, not a distribution of values.
%
They thus necessarily involve a process of informed estimation
or guesswork: the only way to actually know the size of, say, a missing
higher order correction, is to calculate it.

We will show by adopting a Bayesian
point of view, and assigning a Gaussian probability distribution to the
expected true value of the theory calculation, that the impact of 
any missing theoretical contribution can be encoded as an 
additive contribution to the experimental covariance matrix used in the 
PDF fit \cite{Ball:2018odr}. The combination is additive because experimental and theoretical uncertainties are by their nature independent, and are thus combined in quadrature. In a global fit, theoretical uncertainties 
can be strongly correlated not only across data points within a given 
experiment, but also between different experiments, and even different 
processes, so we need a theoretical covariance matrix which includes all these correlations across all the datasets included in the fit.

This then immediately raises the issue of choosing a meaningful way to
estimate the MHOU, which in particular incorporates these correlations.
%
The standard way of estimating MHOUs in perturbative QCD calculations is 
to perform a variation of the
renormalization and factorization scales, denoted as $\mu_r$ and $\mu_f$
respectively, with various choices for the range and combination of variations existing.
%
While the shortcomings of this method are well known, and various alternatives have been discussed~\cite{Cacciari:2011ze,David:2013gaa,Bagnaschi:2014wea},
this remains the default and most widely used option.
%
In the present context, its main advantage is its universality (it can be applied in the same way to any
of the processes used in the fit), and the way in which it implicitly incorporates correlations (for example predictions for data points in the same process which are kinematically close will be automatically correlated), even across different processes (through the PDFs, which are the same in every process).
%
Thus while in principle our covariance matrix formalism allows for the
inclusion of any method for estimating MHOUs in a PDF determination, here 
we will specifically use scale variation.

In order to do this, we need to examine systematically the underpinnings 
of scale variation as a means to estimate theory uncertainties, since 
different definitions of scale variation have been used in different contexts.
%
Indeed, the standard definitions of renormalization and
factorization scale typically used for deep-inelastic scattering and 
hadronic collisions are not the same.
%
Because  PDF fits include both types of processes,
it is important to understand in detail how these
definitions relate to each other, in order to be
able to correlate the scale variations in a meaningful
way.
%
Specifically, we will show that one may estimate the MHOU for any process 
by combining two independent scale variations: one
to estimate the MHOU in the perturbative evolution of the PDFs
(missing higher orders in the DGLAP splitting functions), and the other 
to estimate the MHOU in the perturbative calculation of the 
partonic cross-sections (missing
higher orders in the hard-scattering matrix elements).

Once the scales to be varied are understood, the remaining task
is to choose a particular prescription to be used to construct the 
theoretical covariance matrix.
%
In estimating MHOUs for a given process, the most commonly adopted option 
is the so-called seven-point envelope prescription, in which 
$\mu_r$ and $\mu_f$ are independently varied by a factor of two about
the central choice 
while ensuring that $1/2 \le \mu_r/\mu_f\le 2$, and the MHOU is then
taken as the envelope of the results. 
%
For our purposes this is insufficient: rather than taking an envelope,
we wish to contruct a covariance matrix out of the scale variations.
In particular, because theoretical uncertainties are correlated across processes (through the evolution of the PDFs), we need a prescription for determining the entries of the covariance matrix both within a single process and 
across pairs of processes. 
%

We will discuss in detail a variety of options to achieve this, based on a general ``$n$-point prescription''.
%
These  options will differ from each other in the choice
of the number of independent variations, the directions of such
variations in the $(\mu_r,\mu_f)$ plane, and the way the variations
are correlated (or not) across different processes.

The validation of these point prescriptions, and the choice of the
optimal one to be used for PDF determinations is a nontrivial
problem, which however admits an elegant solution.
%
The validation can be performed at NLO, by comparing the estimate of the MHOU encoded in the theory covariance matrix to the known next (NNLO)
order correction. The problem is then to compare the probability
distribution of expected higher-order results to the unique answer given by the NNLO calculation.
%
The solution to this problem is to view the set
of shifts between the NLO and NNLO computations for all the processes under
consideration as a vector, with one component for each 
of the data points. The theory
covariance matrix corresponding to each prescription then defines a
one-sigma ellipsoid in a subspace of this space.
%
The validation is performed by projecting the shift vector into the ellipsoid: if the theory covariance matrix gives a sensible estimate of the MHOU at NLO, the shift vector will lie almost entirely within the ellipsoid.
%
Using this strategy, we will validate a variety of scale variation prescriptions
on a similar dataset to that of the global NNPDF3.1 analysis.
%
Since the dimension of the space of datapoints is typically two orders of magnitude higher than the dimension of the subspace of the ellipsoid, this is a highly nontrivial test.

Once a prescription has been selected and used to construct the theory
covariance matrix, it is possible to perform a PDF fit based
on it.
Within the NNPDF methodology, an ensemble of PDF replicas is fitted to data
replicas.
%
Data replicas are generated in a way which reflects the
uncertainties and correlations of the underlying data, as encoded in
their covariance matrix.
%
The best-fit PDF replica for each data
replica is then determined by minimizing a figure of merit ($\chi^2$) which
is computed using the covariance matrix.
%
As mentioned, and as we shall show in
Sect.~\ref{sec:thcovmat}, the theory contribution
appears as an independent contribution to the total covariance matrix,
uncorrelated with the experimental one and simply added to
it.
%
Therefore,  once the
covariance matrix is supplemented by an extra theory contribution coming 
from MHOUs, this should be treated on the same footing as any other
contribution, and it will thus affect both the data replica generation, and
the fitting of PDF replicas to data replicas.

Qualitatively, one may expect the inclusion of the MHOU in the data replica
generation to increase the spread of the data replicas, and thus lead in 
itself to an increase in overall PDF uncertainties. On the other hand 
the inclusion of the MHOU in the fitting might also  reduce 
tensions within the fit due to the imperfection of the theory and, since 
these are highly correlated, result in significant shifts in central values, 
and overall a better fit with reduced uncertainties. The combined effect
of including the MHOU in both the data generation and the fitting is thus not
at all obvious.

We will investigate these effects by performing PDF determinations in
which MHOUs are included in either, or both, the replica
generation and the PDF replica fitting. Once again, results can be 
validated at NLO by comparing NLO PDFs determined with the theory 
covariance matrix to NNLO PDFs.
%
A successful validation should show that the best-fit NLO PDF moves
towards the central NNLO result upon inclusion of the theory covariance 
matrix in both replica generation and fitting, due to a relaxation of 
tensions in the NLO fit, and that the NNLO PDF differs from the NLO PDF 
by an amount which is correctly estimated by the NLO uncertainty band.
%
As we shall see, this is indeed the case, and in fact it will
turn out that often the uncertainty band does not increase or even decreases 
upon inclusion of the theory covariance matrix.

Having determined PDFs which now account for the MHOU associated
to the processes that enter the fit, the natural
questions which then arise are what is their impact, and more
generallly
how they should be used for precision
LHC phenomenology.
On order to address the first question, we
will compute predictions with MHOUs for typical LHC standard
candle processes, both with and without including the MHOU in the PDF, and
provide a first phenomenological exploration and assessment of the
impact of these uncertainties.

The second  question is not entirely trivial
and we will address it in detail.
%
Indeed, scale variation is
routinely performed in order to estimate the MHOU in theoretical predictions for
hadron collider processes. Clearly, when obtaining a prediction, we
should avoid double counting a
MHOU which has already been included in the PDF.
%
Instances in which
this might happen include not only the trivial situation in which a
prediction is obtained for a process which has already been used for
PDF determination, but also the somewhat more subtle situation in
which the MHOU in the PDF and the observable which is being predicted
are correlated through perturbative
evolution~\cite{Harland-Lang:2018bxd}.
We will discuss this situation, and provide guidelines for the usage of PDFs with MHOUs. 

This paper is broadly divided into two main parts.
%
In the  first part, we
construct a general formalism for the inclusion of theory uncertainties
and specifically MHOUs in PDF determination, and show how to construct and 
validate a theory covariance matrix.
%
In the second part, we
perform a first investigation of the phenomenological implications of
these theory uncertainties.
%
The structure of the paper is the following: in
Sect.~\ref{sec:thcovmat} we show, using a Bayesian approach,
that under certain assumptions any type of theory uncertainty can be included as a contribution
to the covariance matrix.
%
In Sect.~\ref{sec:scalevarn} we summarize
the theory of scale variation and use it to review,
compare  and systematize different definitions which have been used
in the literature.
%
In Sect.~\ref{sec:prescriptions} we then formulate
a number of ``point prescriptions'' for the theory covariance matrix, both for a single process, and also to account for 
correlations between a pair of processes.
In Sect.~\ref{sec:results} we compute the theory covariance matrix for
a variety of prescriptions, we test them against known higher
order corrections, and use this comparison to select an optimal prescription.

We then move to the second, more phenomenological, part of the paper.
The centerpiece of this section is the determination of NLO PDF sets
with MHOU, presented  in Sect.~\ref{sec:fitstherr}.
%
We first only include deep-inelastic
scattering data (DIS-only fit), and then adopt a global data set, which is
compared to PDFs without MHOU, and validated against NNLO PDFs.
%
For the DIS-only PDF determination, we  also
determine a NNLO PDF set including MHOU.
%
In Sect.~\ref{sec:pheno} we present initial studies of the phenomenological impact of the inclusion of MHOUs
in PDFs for representative LHC processes.
%
Finally in Sect.~\ref{sec:usage} we provide guidelines for the usage of PDFs
with MHOU, in particular concerning the combination of the PDF uncertainties
with the MHOU on the hard matrix element, and present the delivery of the
PDF sets produced in this work.

Two appendices contain further studies and technical details.
%
In Appendix~\ref{sec:diagonalization} we provide
additional details concerning the procedure adopted
to diagonalise  the theory covariance matrix.
%
Then in Appendix~\ref{sec:fitsscalesvar} we study another possible validation
of the results of Sect.~\ref{sec:fitstherr}, by comparing PDFs with MHOUs to
the PDFs obtained by adopting different choices of 
renormalization and factorization scales in the PDF determination.
Families of fits which
only differ in choices of scale have never been carried
out before and will be presented here for the first time.
Whereas they do  not necessarily give a fair estimate of the
MHOU on PDFs, they surely do provide an indication of the expected
impact of scale variation on PDFs, and the pattern of MHOU correlations.

A concise discussion of the main results of this work was
presented in Ref.~\cite{AbdulKhalek:2019bux}, of
which this paper represents the extended companion.

\section{A theoretical covariance matrix}
\label{sec:thcovmat}

\newcommand\True{{\cal T}}

Parton distribution functions are determined from a set of $N_{\rm dat}$
experimental data points, which we represent by an $N_{\rm dat}$-dimensional
vector $D_i$, $i=1,\ldots,N_{\rm dat}$.
%
These data points have experimental
uncertainties that may be correlated with each other, and this
information is encoded
in an experimental covariance matrix $C_{ij}$.
%
This covariance matrix may be
block-diagonal if some sets of data are uncorrelated.
Each experimental data point has associated with it a
``true'' value $\True_i$ --- the value given by Nature ---  whose
determination is the goal of the experiment. Since the 
experimental measurements are imperfect, they cannot determine $\True$ 
exactly, but they can be used to estimate the Bayesian probability 
of a given hypothesis for $\True$. Assuming that the
 experimental results are Gaussianly distributed about this hypothetical true
 value, the conditional probability for the true values $\True$ given
 the measured cross-sections
$D$ is
\begin{equation}\label{eq:PDT}
P(\True|D)=P(D|\True) \propto \exp\big(-\half (\True_i-D_i)C_{ij}^{-1}(\True_j-D_j)\big),
\end{equation}
up to an overall normalization constant. Note that this tacitly assumes equal priors for both $D$ and $\True$.

Of course the true values $\True_i$ are unknown.
%
However we can
calculate theoretical predictions for each data point $D_i$, which we
denote by $T_i$.
%
These predictions are computed using a theory framework which is
generally incomplete: for example because it is based on the
fixed-order truncation of a perturbative expansion, or because it excludes 
higher-twist effects, or nuclear effects, or some other effect that 
is difficult to calculate precisely.
%
Furthermore, these theory predictions $T_i$ depend on PDFs,
evolved to a suitable scale also using incomplete theory.
%
While the theory predictions
may correspond to a variety of different observables and processes, 
they all depend on the same underlying (universal) PDFs.

We now
assume, in the same spirit as when estimating experimental
systematics, that the true values $\True_i$ are centered on the theory
predictions $T_i$, and Gaussianly distributed
about the theory predictions, with which they would coincide 
if the theory were exact and the PDFs were known with certainty.
%
The conditional probability for the
true values $\True$ given theoretical predictions $T$  is then
\begin{equation}\label{eq:PT}
P(\True|T)=P(T|\True) \propto \exp\big(-\half (\True_i-T_i)S_{ij}^{-1}(\True_j-T_j)\big),
\end{equation}
again up to a normalization constant, where $S_{ij}$ is a ``theory
covariance matrix'', to be estimated in due course. 

PDFs are determined by  maximizing the probability of the theory given
the data $P(T|D)$, marginalised over the true values $\True$ which of
course remain unknown.
%
Now using Bayes' theorem 
\begin{equation}
  \label{eq:Bayes}
P(\True|DT)P(D|T)=P(D|\True T)P(\True|T) \, .
\end{equation}
Moreover, since the experimental data do not depend on 
the theorists' calculations $T$, but only on the `truth' $\True$,              
\begin{equation}\label{eq:indy}
P(D|\True T)=P(D|\True).
\end{equation} 
Then because by construction $\int \!D^{N}\True\, P(\True|TD)=1$,
\begin{equation}\label{eq:margin}
P(D|T) = \int \!D^{N}\True\, P(\True|D)P(\True|T) \, ,
\end{equation}
where the $N$-dimensional integral is over all of the possible values
of $\True_i$. The probability of the experimental data $D$ is now conditional 
on the theory $T$ because we have marginalised over the underlying `truth' 
$\True$, which is common to both.

Writing the difference between the true $\True_i$ and the actual $T_i$ values
of the theory prediction as
\be
\label{eq:shiftsTheory}
\Delta_i \equiv {\cal T}_i-T_i \, ,
\ee
we can change variables of integration
to convert the integral over $\True_i$ into an
integral over the shifts $\Delta_i$: using the Gaussian hypotheses 
Eqns.~(\ref{eq:PDT}) and~(\ref{eq:PT}), Eq.~(\ref{eq:margin}) becomes 
%
 that
\begin{equation}\label{eq:gauss}
  P(D|T) \propto \int \!D^{N}\Delta\, \exp\big(-\half  \lp D_i-T_i-\Delta_i\rp C_{ij}^{-1} \lp
  D_j-T_j-\Delta_j\rp -\half\Delta_i S_{ij}^{-1}\Delta_j\big).
\end{equation}
The Gaussian integrals can now be performed explicitly.
Adopting a vector notation in order to make the algebra more
transparent, we rewrite the exponent as 
\bea
  &&  (D - T - \Delta)^T C^{-1} (D - T - \Delta) + \Delta^T S^{-1} \Delta \qquad \qquad \qquad \\  \nonumber &=& \Delta^T (C^{-1} + S^{-1})\Delta - \Delta^T C^{-1} (D - T) - (D - T)^T C^{-1} \Delta + (D - T)^T C^{-1} (D - T) \\ \nonumber &=& (\Delta - (C^{-1} + S^{-1})^{-1} C^{-1} (D - T))^T (C^{-1} + S^{-1}) (\Delta - (C^{-1} + S^{-1})^{-1} C^{-1} (D - T)) \\ \nonumber &-& (D - T)^T C^{-1} (C^{-1} + S^{-1})^{-1} C^{-1} (D - T) + (D - T)^T C^{-1} (D - T),
\label{eq:square}
\eea
%
where we used the fact that both $C$ and $S$ are symmetric matrices, and in
the last line we completed the square. Integrating over $\Delta$,
ignoring the normalization, Eq.~(\ref{eq:gauss}) then becomes 
%
\begin{equation}
	P(T|D)=P(D|T) \propto \exp\big(- \half (D - T)^T (C^{-1} - C^{-1} (C^{-1} + S^{-1})^{-1} C^{-1}) (D - T)\big)\,.
	\label{eq:PDx}
\end{equation}
%
However
\begin{equation}
    (C^{-1} + S^{-1})^{-1} = (C^{-1} (C + S) S^{-1})^{-1} = S (C + S)^{-1} C,
\end{equation}
%
so that
%
\begin{align}
\begin{split}
    C^{-1} &- C^{-1} (C^{-1} + S^{-1})^{-1} C^{-1} = C^{-1} - C^{-1} S (C + S)^{-1} \\ &= (C^{-1} (C + S) - C^{-1} S) (C + S)^{-1} = (C + S)^{-1}.
\end{split}
\end{align}
%
Restoring the indices, we thus find the simple result
%
\begin{equation}
	P(T|D) \propto \exp\big(- \half (D_i - T_i) (C + S)_{ij}^{-1} (D_j - T_j)\big).
\label{eq:PDCS}
\end{equation}
%

Comparison of Eq.~(\ref{eq:PDCS}) with Eq.~(\ref{eq:PDT}) indicates that
when replacing the true $\True_i$ by the theoretical predictions
$T_i$ in the expression of the  $\chi^2$ of the data, the
theoretical covariance matrix $S_{ij}$ should simply be added
to the experimental covariance matrix $C_{ij}$ \cite{Ball:2018odr}.
%
In effect this implies that, at least within this
Gaussian approximation, when determining PDFs theoretical uncertainties 
can be treated simply as
another form of experimental systematic: it is an additional
uncertainty to be taken into account when trying to find the truth
from the data on the basis of a specific theoretical prediction.
%
The experimental and theoretical uncertainties are added in quadrature
because they are in principle uncorrelated. 

In the case for which theoretical uncertainties can be neglected, 
i.e. if $S_{ij}\to0$,
then $P(\True|T)$ in Eq.~(\ref{eq:PT}) becomes proportional
to $\delta^N(\True_i-T_i)$.
%
As  a result, in this case Eq.~(\ref{eq:PDCS}) reduces
 to Eq.~(\ref{eq:PDT}) with $\True_i$ replaced by the
predictions $T_i$. This shows that Eq.~(\ref{eq:PDCS})
remains true even if $S_{ij}$ has zero eigenvalues and is thus not
invertible.
%
Note however
that by construction $C_{ij}$ is positive definite, since any
experimental measurement always
has uncorrelated statistical uncertainties due to the finite number of events,
so $(C+S)_{ij}$ will always be invertible. 
 
The question remains of how to estimate the theory covariance matrix,
$S_{ij}$.
%
The Gaussian hypothesis Eq.~(\ref{eq:PT}) implies that
\begin{equation}
            S_{ij} = \big\langle(\True_i - T_i)(\True_j - T_j)\big\rangle=\big\langle\Delta_i\Delta_j\big\rangle,\label{eq:sdef}
      \end{equation}
where the average is taken over the true theory values $\True$ using the probability
distribution $P(\True|T)$, and 
$\langle\Delta_i\rangle=0$ consistent with the assumption that the probability 
distribution of the truth $\True$ is centred on the theoretical calculation $T$.
%
In practice however the formal definition
Eq.~(\ref{eq:sdef}) is not very helpful: we need some way to
estimate the shifts $\Delta_i$ --- `nuisance parameters', in the
language of systematic error determination --- in a way that takes into
account the theoretical correlations between different kinematic points
within the same dataset, between different datasets measuring
the same physical process, and between datasets corresponding to different
processes (with initial state hadrons).
%
Note that theory correlations will always be present even for entirely 
different processes, through the universal parton distributions: the only processes with truly independent theoretical uncertainties are those with only leptons in the initial state, which are of course irrelevant for PDF determination.

The most commonly used method of estimating the theory
corrections due to MHOUs, which can naturally incorporate all these
theoretical correlations, is scale variation.
%
This method is reviewed in Sect.~\ref{sec:scalevarn} in general terms and 
then used in Sect.~\ref{sec:prescriptions} in order to formulate
specific prescriptions for constructing the theory covariance matrix $S_{ij}$.
%
Other approaches which have been
discussed in the literature involve estimating MHOUs based on the
behaviour of the known perturbative
orders~\cite{Cacciari:2011ze,David:2013gaa,Bagnaschi:2014wea};
however, at least at present, these do not appear to provide a
formalism which is sufficiently well-established, and of appropriately
general applicability.
%
We emphasize however that the formalism presented in this section is independent of the specific method
adopted to estimate the correlated theory shifts $\Delta_i$ that enter Eq.~(\ref{eq:sdef}).
\section{MHOUs from scale variations}
\label{sec:scalevarn}

The variation of the renormalization and factorization scales is the most popular 
approach for estimating missing higher order uncertainties (MHOUs) in
QCD perturbative calculations.
%
It has a number of 
advantages: it naturally incorporates renormalization group (RG) invariance, 
thereby ensuring that as the perturbative order increases, estimates of MHOU 
decrease; the same procedure can be used for any perturbative process, since 
the scale dependence of the strong coupling $\as(\mu^2)$ and of PDFs
is universal; the 
estimates of MHOU it produces are smooth functions of the kinematics, and 
thereby correctly incorporate the strong correlations in nearby regions of 
phase space; and correlations between different processes due to universal ingredients 
such as PDFs can be easily incorporated.
%
Its drawbacks are also well known: 
there is no unique principle to determine the specific range of the scale variation (nor 
even the precise central scale to be adopted); and it misses uncertainties 
associated with new singularities or color structures present at higher orders but 
missing at lower orders.
%
The former problem may be dealt with, at least 
qualitatively, by validating a given range in situations where the next order 
corrections are known.
%
We will attempt such a validation in this paper.
%
The  latter problem is more challenging, requiring resummation in the case of 
unresummed logarithms, or other methods of estimating new types of
corrections, and it is unclear whether or not it admits a general solution.

While scale variation has been discussed many times in a variety of
contexts, there is no standard, commonly accepted formulation of it,
and specifically none that can be applied to both electroproduction
and hadroproduction processes, as we need to do if we wish to use
scale variation in the context of global PDF analyses.
%
In fact, it
turns out that the most commonly adopted approaches to scale variation
differ, typically according to the nature of the process which is
being considered, though also as a function of time, with different
prescriptions being favored in the past than those in common use 
at the present.
%
Moreover, even the terminology is not uniform: it has  evolved over time, 
resulting in the same names being used for what are essentially different 
scale variations.

To formulate prescriptions for the general use of scale
variation for MHOU estimation which can be applied to any process
included in present or future PDF determinations, it is thus necessary
to first review the underpinnings of scale variation, and to then use
them in order to set up a generally applicable formalism.
%
This
will be done in the current section, by specifically discussing the cases of
electroproduction and hadroproduction.
%
In particular, we will show that
for factorized processes MHOUs on  the partonic cross-sections and on
perturbative evolution are independent and can be
estimated through independent scale variations. We will then discuss 
how they can be combined, first with a single process and then for 
several processes, both correlated and uncorrelated. 

\subsection{Renormalization group invariance}
\label{rgi_sec}

The basic principle of scale variation is based
on the observation that scale-dependent
contributions to a perturbative prediction are fixed by
RG invariance, and therefore scale variation can be
used to generate higher order contributions, which are then taken as a
proxy for the whole missing higher orders.

More explicitly, consider
a generic theoretical prediction (typically a perturbative
cross-section) of the form $\overline{T}(\alpha_s(\mu^2), \mu^2/Q^2)$,
where $\mu^2$ is the renormalization scale and $Q^2$ is some physical
scale in the process. Thus $\overline{T}$ indicates the theory prediction 
$T$ when it is evaluated at some renormalization scale $\mu^2$ instead
of being evaluated at the physical scale $Q^2$: if we instead set 
$\mu^2=Q^2$, then
\begin{equation}
\label{xseccent}
T(Q^2) \equiv \overline{T} \lp \alpha_s(Q^2), 1 \rp \, .
\end{equation} 
The QCD running coupling $\alpha_s(\mu^2)$ satisfies the RG
equation 
%
\begin{equation} \label{1.1}
	\mu^2 \frac{d}{d \mu^2} \alpha_s(\mu^2) = \beta(\alpha_s(\mu^2)) \, ,
\end{equation}
%
where the QCD beta function 
has the following perturbative expansion:
\be
\label{eq:betafunctionQCD}
\beta(\alpha_s) = \beta_0 \alpha_s^2 + \beta_1 \alpha_s^3 
+ \beta_2 \alpha_s^4 + \ldots \, .
\ee 
RG invariance is the statement that
the all-order prediction is independent of the renormalization
scale: 
%
\begin{equation} \label{1.2}
  \mu^2 \frac{d}{d \mu^2} \overline{T} \lp
  \alpha_s(\mu^2), \mu^2/Q^2\rp  = 0 .
\end{equation}
%

It will be useful in what follows to define the variables
\begin{equation}\label{notn}
\mu^2 = k Q^2,\qquad t = \ln (Q^2 / \Lambda^2), \qquad \kappa = \ln k = \ln \mu^2/Q^2,
\end{equation}
so $\alpha_s(\mu^2)$ is a function of $\ln \mu^2/\Lambda^2 = t +
\kappa$.
%
We can then write  the RG equation (\ref{1.2})  as
%
\bea \label{1.3}
	0 & =& \frac{d}{d \kappa} \overline{T}(\alpha_s(t + \kappa), \kappa) \nonumber\\
	& =& \frac{d} {d \kappa} \alpha_s(t + \kappa) \frac{\partial}{\partial \alpha_s} \overline{T}(\alpha_s(t + \kappa), \kappa) \bigg|_\kappa + \frac{\partial}{\partial \kappa} \overline{T}(\alpha_s(t + \kappa), \kappa) \bigg|_{\alpha_s}\nonumber \\
	& =& \frac{\partial}{\partial t} \overline{T}(\alpha_s(t + \kappa), \kappa) \bigg|_\kappa + \frac{\partial}{\partial \kappa} \overline{T}(\alpha_s(t + \kappa), \kappa) \bigg|_{\alpha_s} \, ,
\eea
%
where in the second line we assume that $\overline{T}$ is analytic in
$\alpha_s$ and $\kappa$, and in the third we use 
%
\begin{equation} \label{1.4}
	\frac{d}{d \kappa} \alpha_s(t + \kappa) = \frac{d}{dt} \alpha_s(t + \kappa) = \beta(\alpha_s(t + \kappa) ) \, .
\end{equation}
%
Taylor expanding $\overline{T}(\alpha_s, \kappa)$ in $\kappa$ about $\kappa=0$ (i.e. $k=1$, $\mu^2=Q^2$) at fixed coupling $\alpha_s$,
%
\bea
  \label{1.5}
  \overline{T}(\alpha_s(t + \kappa), \kappa) &=& \overline{T}(\alpha_s(t + \kappa), 0)\nonumber\\&&\qquad\qquad +\kappa \frac{\partial}{\partial \kappa} \overline{T}(\alpha_s(t + \kappa), 0) \bigg|_{\alpha_s} + \half \kappa^2 \frac{\partial^2}{\partial \kappa^2} \overline{T}(\alpha_s(t + \kappa, 0)\bigg|_{\alpha_s} + \ldots \qquad \nonumber \\
	&=& \overline{T}(\alpha_s(t + \kappa), 0) - \kappa \frac{\partial}{\partial t} \overline{T}(\alpha_s(t + \kappa), 0) \bigg|_\kappa + \half \kappa^2  \frac{\partial^2}{\partial t^2} \overline{T}(\alpha_s(t + \kappa), 0)\bigg|_\kappa + \ldots\, ,
\eea
%
where in the second line we use the RG invariance condition,
Eq.~(\ref{1.3}), to replace $\frac{\partial}{\partial \kappa}$ with
$-\frac{\partial}{\partial t}$.
%
We can thus determine the $\kappa$
dependence of $\overline{T}(\alpha_s, \kappa)$ using the dependence of
$T(t)=\overline{T}(\alpha_s(t), 0)$ on $t$:
%
\begin{equation} \label{1.6}
	\overline{T}(\alpha_s(t + \kappa), \kappa) = T(t + \kappa) - \kappa \frac{d}{dt} T(t + \kappa) + \half \kappa^2  \frac{d^2}{dt^2} T(t + \kappa)+\ldots\>.
\end{equation}
%

Now since
\begin{equation} \label{1.7}
	\frac{d}{dt} T(t) = \frac{d \alpha_s(t)}{dt} \frac{\partial}{\partial \alpha_s} \overline{T}(\alpha_s(t), 0) = \beta(\alpha_s(t)) \frac{\partial}{\partial \alpha_s} \overline{T}(\alpha_s(t), 0),
\end{equation}
%
and $\beta(\alpha_s) = \mathcal{O}(\as^2)$, we see that 
$\frac{1}{T} \frac{dT}{dt}
= \mathcal{O}(\alpha_s)$, while $\frac{1}{T} \frac{d^2T}{dt^2} =
\mathcal{O}(\alpha_s^2)$ etc.: derivatives with respect to $t$ always
add one power of $\alpha_s$. It follows that in Eq.~(\ref{1.6}), the term
$\mathcal{O}(\kappa)$ is $\mathcal{O}(\alpha_s)$ with respect to the
leading term, and the term $\mathcal{O}(\kappa^2)$ is
$\mathcal{O}(\alpha_s^2)$ with respect to the leading term, and so
on.
We thus see explicitly that
the scale-dependent terms (those that depend on $\kappa$), 
at a given order in perturbation theory, are
determined by derivatives of the cross-section lower down the
perturbation series.  

This implies that if we know the cross-section $T(t)$ as a function of the central 
scale $Q^2$ to a given order in perturbation theory, we can then use 
Eq.~(\ref{1.6}) to determine the scale-dependent 
$\kappa$ terms directly from $T(t)$ at any given order,  by 
differentiating terms lower down the perturbative expansion.
%
For instance, truncating at LO, NLO, or NNLO, one has
%
\begin{align} \label{1.8}
\begin{split}
	\overline{T}_{\text{LO}}(\alpha_s(t + \kappa), \kappa) & = T_{\text{LO}}(t + \kappa), \\
	\overline{T}_{\text{NLO}}(\alpha_s(t + \kappa), \kappa) & = T_{\text{NLO}}(t + \kappa) - \kappa\smallfrac{d}{dt}{T}_{\text{LO}}(t + \kappa), \\
	\overline{T}_{\text{NNLO}}(\alpha_s(t + \kappa), \kappa) & = T_{\text{NNLO}}(t + \kappa) - \kappa\smallfrac{d}{dt}{T}_{\text{NLO}}(t + \kappa) + \half\kappa^2  \smallfrac{d^2}{dt^2}{T}_{\text{LO}}(t + \kappa).
\end{split}
\end{align}
%
The differentiation may be performed analytically,
which is trivial for a fixed 
order expansion, or numerically, which can be useful in a resummed expression
where the dependence on $\as(t)$ can be
nontrivial~\cite{Altarelli:2008aj}.
%
Note that when the renormalization scale coincides
with the physical scale of the process, $\mu^2=Q^2$, then $\kappa=0$
and $\overline{T}=T$ at every order in the perturbative expansion.

The MHOU can now be estimated as the difference between the scale
varied cross-section and the cross-section evaluated at the central
scale, namely
\begin{equation}\label{1.9}
\Delta(t,\kappa) = \overline{T}(\alpha_s(t + \kappa), \kappa) - T(t) \, .
\end{equation}
Thus at LO, NLO and NNLO we have, using Eq.~(\ref{1.8}), that the theory nuisance
parameters are given by
\begin{align}
  \label{1.10}
\begin{split}
\Delta_{\text{LO}}(t,\kappa) & = T_{\text{LO}}(t + \kappa)-T_{\text{LO}}(t), \\
{\Delta}_{\text{NLO}}(t,\kappa) & = (T_{\text{NLO}}(t + \kappa) - \kappa\smallfrac{d}{dt}{T}_{\text{LO}}(t + \kappa))-T_{\text{NLO}}(t), \\
{\Delta}_{\text{NNLO}}(t, \kappa) & = (T_{\text{NNLO}}(t + \kappa) - \kappa\smallfrac{d}{dt}{T}_{\text{NLO}}(t + \kappa) + \half\kappa^2  \smallfrac{d^2}{dt^2}{T}_{\text{LO}}(t + \kappa))-T_{\text{NNLO}}(t) \, .
\end{split}
\end{align}
One finds that while at LO the theory uncertainty is entirely due to the scale chosen
for $\as$, at NLO the dependence on scale is milder since the leading
dependence is subtracted off by the $O(\kappa)$ term.  At NNLO it
is milder still, since the $O(\kappa)$ term subtracts the leading
dependence in the first term, and the $O(\kappa^2)$ removes the
subleading dependence in the first two terms.
%
RG
invariance then guarantees that the terms generated by scale variation
are always subleading, so if the perturbation series is well
behaved, the theory shifts $\Delta$ becomes smaller and smaller as the order of the
expansion is increased. 

Clearly the size of the MHOU, estimated in this way, will depend on
the size of the scale variation, and thus on the value chosen for
$\kappa$. Typically one varies the renormalization scale by a factor of two in each
direction, i.e. $\kappa\in[-\ln 4,\ln4]$, since this range is
empirically found to yield sensible results for many processes.
%
However, in principle, one should treat $\kappa$ as a free parameter,
whose magnitude needs to be validated whenever possible by comparing
to known higher order results.

In the present work, we are specifically interested in the application of this
method to processes
with one or more hadrons in the initial state, i.e. to
cross-sections factorized into a  hard
cross-section convoluted with a PDF or a parton luminosity.
%
There are then two independent sources of MHOU: the perturbative
expansion of the hard partonic cross-section, and the perturbative expansion of
the anomalous dimensions that determine the perturbative evolution of the
parton distributions.
%
It is convenient to obtain each of these from an independent scale
variation, and this can be done by writing separate RG
equations for the hard cross-section and for the PDF, as we will
demonstrate below.
%
This approach is completely equivalent to the perhaps more familiar point
of view in which MHOUs on perturbative evolution are instead obtained
by varying the scale at which the PDF is evaluated in the factorized
expression, as we will also show.

We will begin
by considering the MHOU in the hard-scattering
partonic cross-sections; we will then turn to a discussion of
MHOUs in the PDF evolution, and show that the latter can be obtained
by several equivalent procedures.
%
We will then discuss how both scale variations can be obtained
from double scale variation of the hard cross-section, and how this
fact also offers the possibility of performing scale variation in
alternative ways whereby these two sources of MHOU are mixed.
We will discuss these for completeness, since in the past scale 
variations were often performed in this way.
%
Finally, we will address scale
variations and their correlations when several processes are considered at once.

\subsection{Scale variation for partonic cross-sections}
\label{hard_xsec_sec}

We start by considering scale variation in hard-scattering
partonic cross-sections, first in the case of electroproduction
(that is, for lepton-proton deep-inelastic scattering, DIS), and then for the case of
hadroproduction (proton-proton or proton-antiproton collisions).

\subsubsection{Electroproduction}

Consider first an electroproduction process, such as DIS, with an associated structure function given by
%
\begin{equation} 
    {F}(Q^2) = {C}(\as(Q^2))\otimes f(Q^2) \, ,
\label{2.4}
\end{equation}
%
where $\otimes$ is the convolution in the momentum fraction $x$ between the perturbative
coefficient function $C(x,\as)$ and the PDF $f(x,Q^2)$, and where the sum over parton
flavors is left implicit.
%
In Eq.~(\ref{2.4}) both $\as$ and the PDF
are evaluated at the physical scale of the process, so nothing depends
on unphysical renormalization or factorization scales.
%
We
can determine the MHOU associated with the structure function $F$ due to the truncation of the
perturbative expansion of the coefficient function by fixing the
factorization scheme and keeping fixed the scale
at which the PDF is evaluated (usually referred to as factorization
scale), but varying the renormalization scale used in the computation
of the coefficient function itself.

The scale-dependent structure function $\overline{F}$ will then be given by
%─.,
\begin{equation}
    \overline{F}(Q^2, \mu^2) = \overline{C}(\alpha_s(\mu^2), \mu^2/Q^2)\otimes f(Q^2)\, ,
\label{2.5}
\end{equation}
%
where $\mu^2$ is the renormalization scale used in the computation of the coefficient function, or equivalently by 
%
\begin{equation}
    \overline{F}(t, \kappa) = \overline{C}(\alpha_s(t + \kappa), \kappa)\otimes f(t),
\label{2.5a}
\end{equation}
%
where as in Eq.~(\ref{notn}) we are using
the notation $t=\ln Q^2/\Lambda^2$ and $\kappa = \ln \mu^2/Q^2$.
%
Note that in Eq.~(\ref{2.5}) the structure function is written as a
function of $\mu^2$ in the sense of the RG equation~(\ref{1.2}): the
dependence on $\mu^2$ cancels order by order, and the residual
dependence can be used to estimate the MHOU.

In phenomenological applications, it
is more customary to  write $F(Q^2)$, i.e.  {\it not} to write the
dependence of $F$ on $\mu^2$, thereby emphasizing the renormalization
scale independence of the physical observable, and just to indicate
the scale dependence of the hard coefficient function
$\overline{C}(\alpha_s(\mu^2), \mu^2/Q^2)$. Here and in the sequel we
will stick to the  notation used in RG equations
since we wish to emphasize that, as the
scale is varied, we are
dealing with a one-parameter family of theory predictions for the
physical (RG invariant) observable, which all coincide to the accuracy
at which they are calculated but which differ by higher order terms.

Now, the RG invariance of physical cross-sections, and therefore
of the structure function $F$, requires RG
invariance of the coefficient function. This is because we are not varying the
factorization scheme, so the PDF is independent of the renormalization scale $\mu$.
%
It follows that, as in Eq.~(\ref{1.8}),
%
\begin{equation}
  \label{2.6}
	\overline{C}(\alpha_s(t + \kappa), \kappa) = C(t + \kappa) - \kappa \smallfrac{d}{dt} C(t + \kappa) + \half \kappa^2  \smallfrac{d^2}{dt^2} C(t + \kappa)+\ldots,
\end{equation}
where $C(t) = \overline{C}(\as(t),0)$ is the coefficient function evaluated at 
$\mu^2=Q^2$, and thus $\kappa=0$.
%
Then, given the perturbative expansion of the coefficient function,
%
\begin{equation}
C(t) = c_0 + \alpha_s(t) c_1 + \alpha_s^2(t) c_2 + \alpha_s^3(t) c_3 +\ldots, 
\label{2.7}
\end{equation}
%
its derivatives can be easily evaluated using the beta function expansion
Eq.~(\ref{eq:betafunctionQCD}), 
\begin{equation}
  \label{2.2}
\begin{split}
\smallfrac{d}{dt}{C}(t) & = \alpha_s^2(t) \beta_0 c_1+ \alpha_s^3(t) (\beta_1c_1+2\beta_0c_2) + \ldots,\\
\smallfrac{d^2}{dt^2}{C}(t) & = 2\alpha_s^3(t) \beta_0^2 c_1+ \ldots,
\end{split}
\end{equation}
%
and we find that the renormalization scale variation of the
coefficient function is 
%
\begin{equation} \label{2.8}
\begin{split}
\overline{C}(\alpha_s(t + \kappa), \kappa) = c_0 &+ \alpha_s(t + \kappa) c_1 + \alpha_s^2(t + \kappa) (c_2 - \kappa \beta_0 c_1)\\ 
&+\alpha_s^3(t + \kappa)\big(c_3-\kappa (\beta_1c_1+2\beta_0c_2)+ \kappa^2 \beta_0^2 c_1\big) + \ldots \, .
\end{split}
\end{equation}
Again, note that in the case where $\mu^2=Q^2$, and so $\kappa=0$, one recovers
the standard perturbative expansion Eq.~(\ref{2.7}).
%
We can now find the scale-dependent structure function,
\begin{equation}
 \label{2.9}
\begin{split}
\overline{F}(t, \kappa) = c_0\otimes f(t) &+ \alpha_s(t + \kappa) c_1\otimes f(t) + \alpha_s^2(t + \kappa)  \lp c_2 - \kappa \beta_0 c_1 \rp \otimes f(t)\\ 
&+\alpha_s^3(t + \kappa) \lp c_3-\kappa (\beta_1c_1+2\beta_0c_2)+ \kappa^2 \beta_0^2 c_1 \rp \otimes f(t) + \ldots\>. 
\end{split}
\end{equation}

Note that evaluating these expressions is numerically very
straightforward, in that the scale-varied expression
Eq.~(\ref{2.9}) has the same form, involving the same
convolutions of $c_i$ with $f$, as the
convolution with the PDFs to the given order at the central scale
Eqs.~(\ref{2.4}) and~(\ref{2.7}),  only with rescaled coefficients.
%
This means there is no need to recompute NNLO corrections, $K$-factors, etc.: all
that is necessary is to change the coefficients in the perturbative expansion at
the central scale according to Eq.~(\ref{2.9}).  

\subsubsection{Hadronic processes}

MHOUs in the partonic hard cross-sections of
hadronic processes can be computed  in the same way as for DIS.
%
The only additional
 complication is that the physical observable -- typically, a
cross-section $\Sigma$ -- now depends on the convolution of two PDFs:
\begin{equation}\label{H.1}
    \Sigma(t) = H(t)\otimes( {f}(t)\otimes  {f}(t)) \, ,
\end{equation}
 where again the physical scale is $t = \ln (Q^2 / \Lambda^2)$, $H(t)$
 is the partonic hard-scattering cross-section,  the PDFs are convoluted
 together into a parton luminosity $\mathcal{L}=f\otimes f$, and  the sum
 over parton flavors is left implicit.
%
 Then, varying the
 renormalization scale $\kappa = \ln \mu^2/Q^2$ in the hard
 cross-section, we have 
\begin{equation}\label{H.2}
  \overline{\Sigma}(t,\kappa) = \overline{H} (\as(t+\kappa), \kappa)\otimes(f(t)\otimes f(t)).
\end{equation}
where, just as for electroproduction, for PDFs evaluated at a fixed scale $T$, the
RG invariance tells us that $\overline{H} (\as(t),
\kappa)$ is given in terms of $H(t)$ by Eq.~(\ref{1.6}):  
%
\begin{equation} \label{1.6a}
	\overline{H}(\alpha_s(t), \kappa) = H(t) - \kappa \smallfrac{d}{dt} H(t) + \half \kappa^2  \smallfrac{d^2}{dt^2} H(t)+\ldots\>.
\end{equation}

If the partonic process begins at $O(\alpha_s^n)$,
with $n=0,1,2,\ldots$, then one can expand the hard cross-section as
follows
\begin{equation} \label{H.3} 
H(t) = \alpha_s^n(t)h_0 + \alpha_s^{n+1}(t)h_1 + \alpha_s^{n+2}(t)h_2+ \ldots\>.
\end{equation}
%
Then, as in the case of electroproduction, using Eq.~(\ref{eq:betafunctionQCD}) we
can readily evaluate these derivatives,
\begin{equation} \label{H.4}
\begin{split}
\smallfrac{d}{dt}{H}(t) & = n\alpha_s^{n-1}(t)\beta(\alpha_s) h_0 + (n+1)\alpha_s^n(t)\beta(\alpha_s) h_1 + \ldots \\
&= \alpha_s^{n+1} n \beta_0 h_0 + \alpha_s^{n+2} (n \beta_1 h_0 + (n+1) \beta_0 h_1) + \ldots\\
\smallfrac{d^2}{dt^2}{H}(t) & = \alpha_s^{n+2} n(n+1) \beta_0^2 h_0 + \ldots
\end{split}
\end{equation}
%
so that, putting everything together, the expression for the scale-varied
partonic cross-section to be used to evaluate the scale-varied
hadronic cross-section $\overline{\Sigma}$, Eq.~(\ref{H.2}), will be given by
%
\bea \label{H.5}
    \overline{H}(\alpha_s, \kappa) &=& \alpha_s^n h_0 + \alpha_s^{n+1} (h_1 - \kappa n \beta_0 h_0) \nonumber\\ &&\qquad+\alpha_s^{n+2} (h_2 - \kappa(n \beta_1 h_0 + (n+1) \beta_0 h_1) + \half \kappa^2 n(n+1) \beta_0^2 h_1) + \ldots .
\eea
%
This is rather more involved than Eq.~(\ref{2.9}), but
shares the same advantages: the convolutions to be evaluated in
Eq.~(\ref{H.2}) have the same structure as those in Eq.~(\ref{H.1}), so
all that is required to vary the renormalization scale is to modify
their coefficients. 

\subsection{Scale variation for PDF evolution}
\label{ren_pdfs_sec}

The renormalization scale variation described in the previous section
can be used to estimate the MHOU in any partonic cross-section of an
electroproduction or hadroproduction
process evaluated to a fixed order in perturbation theory.
%
However, when computing  factorized observables
of the form  Eqs.~(\ref{2.4}, \ref{H.1}), an entirely independent source
of MHOU arises from the truncation of the perturbative expansion of the
splitting functions
(or anomalous dimensions in Mellin space) that govern the PDF evolution equations.
%
We now show that this MHOU
can again be estimated by scale variation; we will also show that
this scale variation can be performed in different ways:
either at the level of the anomalous dimension; or at the level of the
PDFs themselves; or finally at the level of the
hard-scattering partonic coefficient functions, by exploiting the fact that physical
results cannot depend on the scale at which the PDF is evaluated, and
so one may trade the effect of scale variation between the PDF and
the hard coefficient function.

Consider a PDF $f(\mu^2)$, where $\mu$ is  the scale at which the
PDF is evaluated. For simplicity, in this section all the argument is 
presented implicitly assuming a Mellin space formalism, so that 
convolutions are replaced by ordinary products.
%
Also, indices labeling different PDFs are left implicit,
so our argument applies directly to the
nonsinglet case but can be straightforwardly generalized to the singlet
evolution and to other flavor combinations.

The scale dependence of $f(\mu^2)$ is fixed by the evolution equation
%
\begin{equation} \label{3.1}
	\mu^2 \frac{d}{d \mu^2} f(\mu^2) = \gamma(\alpha_s(\mu^2)) f(\mu^2)\, ,
\end{equation}
which applies also to the general singlet case assuming that a
sum over parton flavors is left implicit.
%
The anomalous dimension admits a perturbative expansion of the form
\begin{equation}\label{3.3a} 
\gamma(t) =  \alpha_s(t) \gamma_0 + \alpha_s^2(t) \gamma_1^2  + \alpha_s^3(t) \gamma_2^3 + \cdots .
\end{equation}
Eq.~(\ref{3.1}) can be integrated to give
%
\begin{equation} \label{3.2}
	f(\mu^2) = \text{exp}\bigg(\int^{\mu^2} \frac{d \mu^{'2}}{\mu^{'2}} \gamma(\alpha_s(\mu^{'2}))\bigg) f_0 \, ,
\end{equation}
%
where $f_0$ indicates the PDF at the initial scale $\mu_0$.
%
Of course, the left-hand
side of the equation  is
independent of this initial scale $\mu_0$, so  the dependence  can be left
implicit also on the right-hand side, by not specifying the lower
limit on the integral. In practice, if the PDF $f_0$ were extracted from
data, any change in this scale would be entirely reabsorbed by the fitting
procedure.

We now observe the well-known fact that the anomalous dimension in Eq.~(\ref{3.1})
is a RG invariant quantity, and
therefore the scale on which it depends is physical.
%
However, this
physical scale can in general be different from the renormalization
scale used to determine the anomalous dimension itself
(e.g. if it were determined through the renormalization 
of a twist-two operator).
%
We let $\mu^2 = k Q^2$, where as in the
general argument of Sect.~\ref{rgi_sec}, $\mu^2$ is an arbitrary
renormalization scale and $Q^2$ is a physical scale.
We can make $\gamma$ independent of the renormalization
scale order by order in perturbation theory if we define its scale-varied
counterpart in the same way as before
%
\begin{equation} \label{3.3}
	\overline{\gamma}(\alpha_s(t), \kappa) = \gamma(t) - \kappa
        \smallfrac{d}{dt}{\gamma}(t) + \half \kappa^2
        \smallfrac{d^2}{dt^2}{\gamma}(t) + \cdots ,
\end{equation}
%
with $\kappa$ given by Eq.~(\ref{notn}) and
$\gamma(t)= \overline{\gamma}(\alpha_s(t), 0)$, so that given
the perturbative expansion Eq.~(\ref{3.3a}) one has that
%
\bea
  \label{3.4}
    \overline{\gamma}(\alpha_s(t + \kappa), \kappa) &=& \alpha_s(t+\kappa) \gamma_0 + \alpha_s^2(t+\kappa) (\gamma_1 - \kappa \beta_0 \gamma_0) \nonumber\\&&\qquad+ \alpha_s^3(t+\kappa) (\gamma_2 - \kappa (\beta_1 \gamma_0 + 2 \beta_0 \gamma_1) + \kappa^2 \beta_0^2 \gamma_0) + \cdots
\eea
%
is independent of $\kappa$ up to higher orders terms, order by order.
Note that Eq.~(\ref{3.4}) has the same form as
Eqs.~(\ref{H.3}-\ref{H.5}) (with $n=1$).

We have shown that
variation of the scale on which the anomalous dimension depends
can be used, in the usual way, to generate higher order terms which estimate
MHOUs in the expansion of the anomalous dimension itself. We now show how the
same result can be obtained by scale variation at the PDF level.
%
Inserting the result Eq.~(\ref{3.4})  in the solution
of the evolution equations for the PDFs, Eq.~(\ref{3.2}), one finds that the evolution
factor can be expressed as
%
\bea 
  &&\exp\lp \int^{t} dt' \overline{\gamma}(\alpha_s(t' + \kappa), \kappa)\rp =
  \exp \lp \int^{t + \kappa} dt' \overline{\gamma}(\alpha_s(t'), \kappa)\rp \nonumber\\
  &=& \exp\lp \lc \int^{t + \kappa} dt' \gamma(t')\rc  - \kappa  \gamma(t + \kappa) + \half \kappa^2 \frac{d}{dt} {\gamma}(t + \kappa) + \ldots \rp \nonumber\\
 &=& \lc 1 - \kappa \gamma(t + \kappa) + \half \kappa^2
    (\gamma^2(t + \kappa)+\frac{d}{dt}{\gamma}(t + \kappa)) + \ldots
    \rc \exp\lp \int^{t + \kappa} dt' \gamma(t')\rp \ , \label{3.5}
\eea
%
where in the first line we changed integration variable (ignoring any change in the lower limit of integration), in the second
we used Eq.~(\ref{3.3}), and in the third we expanded the exponential 
perturbatively.
%
We can now use this result to
determine renormalization scale variation in the evolution directly
from the scale dependence of the PDF, as in
Ref.~\cite{Altarelli:2008aj}.
%
Defining a scale-varied PDF as
%
\begin{equation} \label{3.6}
	\overline{f}(\as(t + \kappa), \kappa) = \text{exp}\bigg(\int^t dt' \overline{\gamma}(\alpha_s(t' + \kappa), \kappa)\bigg) f_0 \, ,
\end{equation}
%
that is, as the PDF obtained by varying the renormalization scale in the
anomalous dimension, then $f(t) = \overline{f}(\as(t), 0)$, and using
Eq.~(\ref{3.5}) we find that
\begin{equation} \label{3.6a}
	\overline{f}(\as(t + \kappa), \kappa) = \lc 1 - \kappa \gamma(t + \kappa) + \half \kappa^2  (\gamma^2(t + \kappa)+\smallfrac{d}{dt}{\gamma}(t + \kappa)) + \ldots \rc\,f(t+\kappa)\, ,
\end{equation}
provided only that any variation of the initial scale $\mu_0$
due to changes in $\kappa$ has been
reabsorbed into the initial PDF $f_0$. 

Eq.~(\ref{3.6a}) is the same as the result obtained from 
varying the scale $\mu^2$ at which the PDF is evaluated about the 
physical scale $Q^2$: just as
in the derivation of Eq.~(\ref{1.6a}), this gives
%
\begin{equation} \label{3.7}
\begin{split}
	\overline{f}(\as(t + \kappa), \kappa) & = f(t + \kappa) - \kappa\smallfrac{d}{dt} {f}(t + \kappa) + \half \kappa^2  \smallfrac{d^2}{dt^2}{f}(t + \kappa) + ... \\
	& = f(t + \kappa) - \kappa \gamma f(t + \kappa) + \half \kappa^2  \big(\gamma^2 + \smallfrac{d}{dt}\gamma\big) f(t + \kappa) + ..., 
\end{split}
\end{equation}
%
where in the second line we used the PDF evolution equation,
Eq.~(\ref{3.1}).
%
Thus there is little point in varying the renormalization scale of the anomalous dimension and the scale at which the PDF is evaluated independently: provided we absorb changes in the initial scale in the initial PDF, and use the linearised solution of the evolution equation, the result (Eq.~(\ref{3.6a}) or Eq.~(\ref{3.7})) is precisely the same.
%
This is essentially because the PDF $f(t)$ depends on only a single scale. 

Equation~(\ref{3.6a}) indicates that the $\kappa$ dependence can be factorized
out of the PDF.
%
We can use this property to factor it into the hard-scattering
coefficient
function.
%
Consider for example electroproduction, whose factorized
structure function is given by Eq.~(\ref{2.4}):
%
\bea\label{3.7a}
    \widehat{F}(t, \kappa) &=& {C}(t) \overline{f}(\as(t+\kappa),\kappa)\nonumber\\
    &=& {C}(t) \lc
    1 - \kappa \gamma(t + \kappa) + \half \kappa^2  (\gamma^2(t + \kappa)+\smallfrac{d}{dt}{\gamma}(t + \kappa)) + \ldots \rc f(t+\kappa)\nonumber\\
    &\equiv& \widehat{C}(t, \kappa) f(t+\kappa) \, ,
\eea
%
where in the second line we used the expansion Eq.~(\ref{3.6a}),
and the third line
should be viewed as the  definition of
the scale-varied coefficient function $\widehat{C}(t+\kappa, \kappa)$.
%
Moreover, given the relation
\be
\frac{d}{dt}\gamma(\alpha_s) = \beta(\alpha_s) \frac{d\gamma}{d\alpha_s} \, ,
\ee
and then using the perturbative expansions of
the beta function $\beta$, the anomalous dimension $\gamma$, and the coefficient function
$C$, Eqs.~(\ref{eq:betafunctionQCD}),~(\ref{3.3a}), and~(\ref{2.7}),
respectively, one finds
\begin{equation}
  \label{3.7c}
	\widehat{C}(t, \kappa) 
	 = c_0 - \alpha_s(t) \kappa (c_1+\gamma_0) + \alpha_s^2(t)  \lp c_2- \kappa \gamma_1 + \half \kappa^2  (\gamma_0^2 + \beta_0 \gamma_0)\rp + \ldots \, .
\end{equation}

Note that this result for $\widehat{C}(t, \kappa)$ is not the same as $\overline{C}(t + \kappa, \kappa)$,
Eq.~(\ref{2.8}).
%
The reason is that 
$\overline{C}(t + \kappa, \kappa)$ is obtained from the
variation of the renormalization scale of the hard coefficient
function, and can be used to estimate the MHOU in the perturbative
expansion of the coefficient function, while $\widehat{C}(t, \kappa)$
is obtained from the variation of the renormalization scale of the
anomalous dimension, and can be used to estimate the MHOU in the
perturbative evolution of the PDF.
%
We have obtained the former from
RG invariance of the hard cross-section, and the
latter from RG invariance of the anomalous dimension.
%
However,
Eq.~(\ref{3.7a}) can be equivalently viewed as expressing the fact
that the physically observable structure function cannot depend on the
scale at which the PDF is evaluated in the factorized expression,
usually referred to as factorization scale: provided we absorb changes
in the initial scale in 
the initial PDF, varying the scale of the anomalous dimension is
identical to
varying the scale of the  PDF.

It is customary to refer to the  scale variation which
estimates MHOU in the coefficient function as renormalization scale
variation: this corresponds to evaluating $\overline{C}(t +\kappa, \kappa)$ in
Eq.~(\ref{2.8}).
%
The scale variation
which estimates MHOU in the
anomalous dimension, and corresponds to $\widehat{C}(t +
\kappa, \kappa)$ in Eq.~(\ref{3.7c}), is usually called instead
factorization scale variation.
%
This terminology
is used for example by the Higgs Cross-Section working group~\cite{deFlorian:2016spz} and more generally within the context of LHC physics; in the older DIS literature
the same terminology has a somewhat different meaning, as we shall
discuss in Sect.~\ref{double_var_sec} below. 

The previous discussion entails that in practice there are
(at least) three different ways of estimating the MHOU associated
to the PDF evolution in terms of the anomalous dimension at fixed order in
perturbation theory by means of scale variations: 
\begin{description}
\item{(A)} The renormalization scale of the anomalous dimension can be
  varied directly, using Eq.~(\ref{3.4}).
  %
  This approach works well provided that the
  initial PDF $f_0$ is refitted, but
  if it is held fixed care must be taken to absorb scale variations of
  the initial scale into the initial PDF.
  %
  This method was used for DIS
  renormalization scale variations in many older papers, see
  e.g. Refs.~\cite{Martin:1990fq,Virchaux:1991jc,Ridolfi:1999vr}).
  %
  It has the
  disadvantage that it requires refitting the PDF as the scale is varied,
  which is cumbersome for most applications.
  
\item{(B)} The scale at which the PDF is evaluated can be varied,
  either analytically or numerically, using Eq.~(\ref{3.7}). This is
  in many ways the simplest method, as the initial PDF remains
  unchanged, while only the PDF is involved so the result is
  manifestly universal.
%
  Furthermore it is easily adapted to a variable
  flavor number scheme (VFNS),
  since the MHOUs in the PDFs with different numbers of active
  flavors can each be estimated separately. The numerical method was
  employed in~\cite{Altarelli:2008aj}, in the context of small $x$
  resummation.
%
  It has the disadvantage that if one wishes to estimate
  the impact on a given physical observable one needs to first generate 
  the scale-varied PDF, before combining it with the hard coefficient function. 
\item{(C)} The scale at which the PDF is evaluated is varied, but the
  compensating scale-dependent terms are factorized into the
  coefficient function using for example Eq.~(\ref{3.7c}).
%
  This
  factorization scale variation is most commonly used when evaluating
  a new process using an established PDF set, e.g. in studies of LHC
  processes (as in Ref.~\cite{deFlorian:2016spz})
  since it has the
  advantage that it can be implemented directly using an external
  interpolated PDF set (such as provided by
  LHAPDF~\cite{Buckley:2014ana}).
  %
  It has the conceptual disadvantage that the
  universality of the variation is obscured, since the scale dependent
  terms are mixed in the expansion of the coefficient function (this
  is particularly complicated  in a VFNS, where the coefficient functions
  also depend on heavy quark masses), and the practical disadvantage
  that it requires the evaluation of new contributions to the
  coefficient function involving additional convolutions. Also, it can be
  impractical in situations where higher order corrections are difficult 
  to evaluate precisely due to numerical issues.  
\end{description}

Note that whereas these methods are in principle completely
equivalent, they can differ by subleading terms according to the
convention used to truncate the
perturbation expansion.
%
Indeed, in method (A)
the expansion of the anomalous dimension is truncated, but higher
order terms in the exponentiation may be retained depending on the
form of the solution to the evolution equations adopted; in method (B)
the exponential has been expanded (see Eq.~(\ref{3.5})) so the result
is the same as would be obtained with a linearized solution of the
evolution equation; while in method (C) cross-terms between the
expansion of linearized evolution and coefficient function expansion
have also been dropped (compare Eq.~(\ref{3.7a}) with
Eq.~(\ref{3.7c})).
%
However, since the differences always involve higher
order terms, each method can be regarded as giving an equally valid
estimate of the MHOU in the perturbative evolution: differences
between methods should be viewed as the uncertainty on the MHOU itself
when estimated by scale variation.

\subsection{Double scale variations} \label{double_var_sec}

We now discuss the combination of the  two independent scale
variations of Sects.~\ref{hard_xsec_sec} and~\ref{ren_pdfs_sec},
respectively estimating MHOUs in the hard cross-section and in
perturbative evolution, thereby deriving master formulae for scale
variation up to NNLO which will then be used in the subsequent sections.
%
For completeness, we will also discuss
different options for scale variation which have been considered in
the literature, and clarify some terminological mismatches, especially
between the older studies of DIS and the more recent applications to
LHC processes.

\subsubsection{Electroproduction} \label{double_var_sec_DIS}

Consider first
the more general factorization of an electroproduction cross-section,
such as a DIS structure function:
\begin{equation}
  \overline{F}(Q^2, \mu_f^2, \mu_r^2) = \overline{C} \lp
  \alpha_s(\mu_r^2),\ \mu_r^2/Q^2 \rp \otimes \overline{f} \lp
  \alpha_s(\mu_f^2), \mu_f^2/Q^2\rp \, ,
    \label{5.1}
\end{equation}
where here and in the following we adopt the (standard)
terminology  that
we introduced in Sect.~\ref{ren_pdfs_sec}, and the viewpoint which
corresponds to option (B) of that section: $\mu_r$ denotes the
renormalization scale, whose dependence is entirely contained in the
hard coefficient function $\overline{C}$ (as in Eq.~(\ref{2.5})),
and whose variation estimates MHOUs in its expansion; while $\mu_f$ denotes the
factorization scale, whose dependence is entirely contained in the PDF
(as in Eq.~(\ref{3.6})), and whose variation estimates MHOUs in the
expansion of the anomalous dimension (or equivalently the
splitting functions).
%
In the following, as in Sect.~\ref{ren_pdfs_sec}, we will omit the
convolution as well as the parton indices.

Note that again, as in Eq.~(\ref{2.5}), and then in
Eqs.~(\ref{H.2}),~(\ref{3.3}), and~(\ref{3.7}), the dependence on the scales
$\mu_f$ and $\mu_r$ should be understood in the sense of the RG equation: the structure
function does not depend on them, but as the scales are varied there
remains a subleading dependence which estimates the MHOU.
%
As
already mentioned, this notation, while standard in the context of RG
equations, is somewhat unusual in the context of  factorization, where
instead it is more customary to omit the scale dependence of the
physical observable.

Given that the structure function $\overline{F}(Q^2, \mu_f^2, \mu_r^2)$ factorizes into
the hard coefficient function and the PDF,
the factorization and renormalization
scales $\mu_f$ and $\mu_r$ can be chosen completely independently; the
scale dependence will also factorize.
%
Explicitly, we define
\be\label{eq:scaledef} \mu_f^2 =
k_fQ^2 \, , \quad  \mu_r^2 = k_rQ^2\, , \quad {\rm with} \quad  t_f = t + \kappa_f \, , \quad
t_r = t +
\kappa_r \, ,
\ee
and then $\kappa_f=\ln k_f$, $\kappa_r=\ln k_r$.
%
In terms of these variables, the factorized structure function will be given by
\begin{equation}
    \overline{F}(t, \kappa_f, \kappa_r) = \overline{C}(t_r, \kappa_r)
    \overline{f}(t_f, \kappa_f), 
\end{equation}
where, as in Sects.~\ref{hard_xsec_sec} and \ref{ren_pdfs_sec}, the scale-varied PDF and coefficient
functions are
\begin{equation}
\begin{split}
    &\overline{f} (t_f, \kappa_f) = f(t_f) - \kappa_f
  \smallfrac{d}{dt}{f}(t_f) + \half \kappa_f^2
  \smallfrac{d^2}{dt^2}{f}(t_f) + ... \, , \\ 
    &\overline{C} (t_r, \kappa_r) = C(t_r) - \kappa_r
  \smallfrac{d}{dt}{C}(t_r) + \half \kappa_r^2
  \smallfrac{d^2}{dt^2}{C}(t_r) + ...   \, ,
\end{split}    
\label{5.4}
\end{equation}
where $f(t_f) \equiv \overline{f}(t_f, 0)$ and $C(t_r) \equiv
\overline{C}(t_r, 0)$ stand for the PDF and the coefficient function evaluated
at the central scale, $\mu_f^2=Q^2$ and $\mu_r^2=Q^2$, respectively.
%
Recalling that $\smallfrac{\partial}{\partial
  t} \sim \mathcal{O}(\alpha_s)$, the structure function is therefore given by
\bea
    \overline{F}(t, \kappa_f, \kappa_r) 
    &=& C(t_r)f(t_f) - \lp \kappa_r \smallfrac{d}{dt}{C}(t_r) f(t_f) +
    \kappa_f C(t_r) \smallfrac{d}{dt}{f} (t_f)\rp  
    + \half\Big( \kappa_r^2 \smallfrac{d^2}{dt^2}{C}(t_r)f(t_f) \nonumber\\
    &&\qquad+ 2\kappa_r \kappa_f
    \smallfrac{d}{dt}{C}(t_r)\smallfrac{d}{dt}{f}(t_f) + \kappa_f^2
    C(t_r) \smallfrac{d^2}{dt^2} f(t_f) \Big) +
    \mathcal{O}(\alpha_s^3) \, .
\label{5.5}    
\eea
From this expression, it follows that
scale variations with respect to $\kappa_f$ can be determined by
taking derivatives with respect to $t_f$ while holding $t_r$ fixed and vice-versa, so one has
\bea
    \overline{F}(t, \kappa_f, \kappa_r)  &=& F(t_f,t_r) - \bigg( \kappa_f\ \frac{\partial F}{\partial t_f}\bigg|_{t_r} + \kappa_r\ \frac{\partial F}{\partial t_r}\bigg|_{t_f} \bigg) \nonumber\\
    &&\qquad+ \half \bigg( \kappa_f^2 \frac{\partial^2 F}{\partial t_f^2}\bigg|_{t_r} +  2 \kappa_f \kappa_r \frac{\partial^2 F}{\partial t_f \partial t_r} +  \kappa_r^2 \frac{\partial^2 F}{\partial t_r^2}\bigg|_{t_f} \bigg) + \cdots \, .    
\eea
In other words, we can think of the two variations as being generated by $\kappa_f
\smallfrac{\partial}{\partial t_f}$ and $\kappa_r
\smallfrac{\partial}{\partial t_r}$ respectively.

We can equivalently treat the factorization scale variation using
method (C) of the previous subsection, and thus
factorize both scale variations into the coefficient function, as done in
Eq.~(\ref{3.7c}).
%
In the case of
electroproduction, inserting the expansions of Eq.~(\ref{2.7}) in Eq.~(\ref{5.5}) one obtains
\begin{equation}
    \overline{F}(t,\kappa_f, \kappa_r) = \widehat{\overline{C}}(\alpha_s(t_r), \kappa_f, \kappa_r) f(t_f) \, ,
    \label{5.7}
\end{equation}
with now all dependence on $\kappa_r$ and $\kappa_f$ encoded into a redefined coefficient function:
\bea
    \widehat{\overline{C}}(\alpha_s(t_r), \kappa_f, \kappa_r) &\equiv& c_0 +
    \alpha_s(t_r) c_1 - \alpha_s(t_f) \kappa_f\ c_0 \gamma_0  \nonumber\\
   &&\qquad+ \alpha_s(t_r)^2 (c_2 - \kappa_r \ \beta_0c_1) - \alpha_s(t_r)
    \alpha_s(t_f) \kappa_f \ c_1 \gamma_0 \nonumber\\ 
    &&\qquad + \alpha_s^2(t_f)(-\kappa_f \ c_0\gamma_1 + \half
    \kappa_f^2 c_0 \gamma_0(\beta_0 + \gamma_0)) + \cdots\nonumber\\ 
    &=& c_0 + \alpha_s(t_r)(c_1 -\kappa_f \ c_0 \gamma_0) +
    \alpha_s^2(t_r) \big(c_2 - \kappa_r \ \beta_0 c_1 -
    \kappa_f\ (c_1\gamma_0 + c_0\gamma_1) \nonumber\\ 
    &&\qquad + \half
    \kappa_f^2 c_0\gamma_0(\gamma_0 - \beta_0) + \kappa_f \kappa_r
    \beta_0 c_0 \gamma_0\big) + \cdots \label{5.8} 
\eea
up to terms of $\mathcal{O}(\alpha_s^3(t_r))$, given that one can change the scale
that enters the coupling using
\be
\alpha_s(t_f)=\alpha_s(t_r)
+(\kappa_f-\kappa_r)\beta_0\alpha_s^2(t_r)+\ldots \, .
\ee
Note that in the expression for $ \widehat{\overline{C}}$ the coupling constant
is always evaluated at the renormalization scale $\mu_r$, and that for
$\kappa_r=\kappa_f=0$ one gets back the original
perturbative expansion Eq.~(\ref{2.7}).

However, especially in the context of PDF determinations, as opposed to the
situation in which a pre-computed PDF set is being used, it is rather
more convenient
to use either of methods (A) or (B) from Sect.~\ref{ren_pdfs_sec}
when estimating the MHOU in the scale
dependence of the PDF, since this can be done without reference to
any particular process.
%
We can then determine the universal $\mu_f$
variation by varying the scale in the PDF evolution, as done
for instance in
Eq.~(\ref{3.4}) or Eq.~(\ref{3.7}), while instead the process-dependent $\mu_r$
variation is estimated by varying the renormalization scale in the coefficient
function, as done in Eq.~(\ref{2.8}), or Eq.~(\ref{H.5}) in the case of hadronic
processes. 

Note that since all scale-varied terms ultimately derive from the
scale dependence of the universal QCD coupling $\as(\mu^2)$, it is
reasonable to treat the
independent scale variations of $\mu_f$ and $\mu_r$ symmetrically,
e.g. by varying in the range $|\kappa_f|, |\kappa_r| 
\leq \ln 4$.
%
Indeed, this symmetry is an advantage  of the
method: we use the same variation for estimating all MHOUs.
%
Since
$\mu_f$ and $\mu_r$ can each be varied independently, a simple option
is to perform the double scale variations by considering the five  scale choices
$(\kappa_f,\kappa_r)= (0,0),(\pm 
\ln 4,0),(0,\pm \ln 4)$.
%
We will refer to this as 5-point scale
variation; alternative schemes will be considered in the
next section.

Note finally that if we set the renormalization and factorization
 scales in Eq.~(\ref{5.1}) to be equal to each other, $\mu_f^2=\mu_r^2
= \tilde{\mu}^2$, we have the factorization 
%
\begin{equation} 
    \widetilde{F}(Q^2, \tilde\mu^2) = \widetilde{C}(\alpha_s(\tilde\mu^2), \tilde\mu^2/Q^2)\ f(\tilde\mu^2) \, .
\label{4.1}
\end{equation}
%
In most of the earlier papers, mainly concerned
with DIS structure functions,
e.g. \cite{Altarelli:1988qr,Nason:1987xz,Close:1987ay,Martin:1990fq,Virchaux:1991jc},
the scale
$\tilde\mu^2$ was termed the factorization scale:
this  originates in the earliest papers on the OPE. However, in our current
terminology it corresponds to both renormalization and factorization
scales taken equal to each other.
%
Likewise, in the earlier papers what here we call the factorization scale 
$\mu_f$ was referred to as the renormalization scale.
Here, to avoid
 confusion, we will call $\tilde\mu^2$ in Eq.~(\ref{4.1})  the scale
 of the process.
 %
 For clarity the different nomenclatures for the various scales used in 
the earlier papers, and in more modern work (and in this paper), are 
 summarized in Table~\ref{tab:scale_nomenclature}. 

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t!]
	\centering
	\renewcommand*{\arraystretch}{1.8}
	\begin{tabular}{|c|c|c|c|}
          \toprule
Scale & MHOU &`Traditional' name\cite{Altarelli:1988qr,Nason:1987xz,Close:1987ay,Martin:1990fq,Virchaux:1991jc} & `Modern' name \cite{vanNeerven:2000uj},[PDG]  \\
\midrule
    $\mu_r$& in hard xsec & --- & renormalization scale \\
    $\mu_f$ & in PDF evolution &renormalization scale & factorization scale  \\
      $\widetilde\mu$ & in physical xsec& factorization scale & scale of the process\\
\bottomrule
        \end{tabular}
        \vspace{0.3cm}
	\caption{\small Nomenclatures for the different scale variations used in 
some of the earlier papers (mainly in the context of DIS), and in more recent work (mainly in the context of hadronic processes), as discussed in detail in the text. The `modern' terminology is adopted throughout this paper.}
	\label{tab:scale_nomenclature}
\end{table}
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Consider now the effect on the structure function of varying the scale of the process.
%
As before, we define $\tilde\kappa = \ln\tilde{\mu}^2/Q^2$ and write
%
\begin{equation}
    \widetilde{F}(t + \tilde\kappa, \tilde\kappa) = \widetilde{C}(\alpha_s(t + \tilde\kappa), \tilde\kappa)\ f(t+ \tilde\kappa) \, .
\label{4.2}
\end{equation}
%
Now the renormalization group invariance of the cross-section [i.e. Eq.~(\ref{1.2})] requires a cancellation between scale variations in the coefficient function and the PDF: with $F(t) \equiv \widetilde{F}(t, 0)$,
%
\begin{equation}
\begin{split}
     \widetilde{F}(t + \tilde\kappa, \tilde\kappa) &= F(t + \tilde\kappa) - \tilde\kappa \smallfrac{d}{dt}{F}(t+\tilde\kappa) +\half \tilde\kappa^2  \smallfrac{d^2}{dt^2}{F}(t + \tilde\kappa) + ... \\
     &= Cf - \tilde\kappa(\smallfrac{d}{dt} C + \gamma C)f + \half \tilde\kappa^2  \big(\smallfrac{d^2}{dt^2}{C} + 2\gamma\smallfrac{d}{dt}{C} + C\smallfrac{d}{dt}{\gamma} + C\gamma^2\big)f + ...
\end{split}
\label{4.3}
\end{equation}
%
where the first line is the same as Eq.~(5.8) in
Ref.~\cite{Altarelli:2008aj} while in the second line we used
Eq.~(\ref{3.7}) for scale variation of the PDF. Then, expanding in the
usual way, we find that 
%
\begin{equation}
\begin{split}
    \overline{C}(t + \tilde\kappa, \kappa) &= c_0 + \alpha_s(t+ \tilde\kappa)(c_1 -\tilde\kappa c_0 \gamma_0) \\
    &+ \alpha_s^2 ( t + \tilde\kappa)\big(c_2 - \tilde\kappa(\beta_0 c_1 + c_1 \gamma_0 + c_0 \gamma_1) + \half \tilde\kappa^2 \ c_0 \gamma_0 (\beta_0 + \gamma_0)\big)+\cdots
\end{split}
\label{4.6}
\end{equation}
%
which indeed coincides with the expression for what is referred to
as factorization scale  
variation in this earlier literature: see
e.g. Ref.~\cite{vanNeerven:2000uj}, Eq.~(2.17).
%
Therefore, varying  
the scale of the process mixes together the scale dependence in the 
coefficient function and the scale dependence in the PDF: indeed, if
in Eq.~(\ref{5.8}) we set
$\kappa_f=\kappa_r=\tilde\kappa$, it reduces to
Eq.~(\ref{4.6}). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[b!]
\centering
\begin{tikzpicture}
\draw[->,>=stealth,black] (0,0) -> (2,0);
\draw[->,>=stealth,black] (0,0) -> (-2,0);
\draw[->,>=stealth,black] (0,0) -> (0,2);
\draw[->,>=stealth,black] (0,0) -> (0,-2);
%\filldraw[black] (-1,-1) circle (2pt);
%\filldraw[black] (1,1) circle (2pt);
\draw[->,>=stealth, red] (0,0) -> (1.5,1.5);
\draw[->,>=stealth,red] (0,0) -> (-1.5,-1.5);
%\draw[->,>=stealth,green] (1,1) -> (2,1);
%\draw[->,>=stealth,green] (1,1) -> (0,1);
\node at (0.5,2) {$\kappa_r$};
\node at (2.4,0) {$\kappa_f$};
%\node at (3,2.4) {renormalisation scale $\mu_f$};
%\draw[->,>=stealth,green] (5,2.4) -> (6,2.4);
\node at (1.75,1.75) {$\tilde{\kappa}$};
%\draw[->,>=stealth,red] (5,2) -> (6,2);
\end{tikzpicture}
\caption{The two-dimensional space of scale variations for a single
  process: $\kappa_r$ is the renormalization scale (giving the MHOU in
  the hard cross-section), $\kappa_f$ is the factorization scale
  (giving the MHOU in the evolution of the PDF) and $\tilde\kappa$ is
  the variation of the scale of the process (called factorization
  scale variation in the earlier literature), obtained by setting
  $\kappa_f=\kappa_r$. \label{fig:DoubleScaleVar1}} 
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Clearly, variations of $\tilde\mu^2$ are not independent of the
variations of $\mu_f^2$ or $\mu_r^2$: rather they are generated by
$\tilde\kappa\ (\smallfrac{\partial}{\partial t_f} +
\smallfrac{\partial}{\partial t _r})$, so they correspond to directions along
the diagonal in the space of $\kappa_f$ and $\kappa_r$, see Fig.~\ref{fig:DoubleScaleVar1}.
%
In the earlier literature, MHOUs were estimated by combining
renormalization scale variation with this latter variation, namely by
varying $\tilde\mu^2$ and
$\mu_f^2$: see e.g.
Refs.~\cite{Martin:1990fq,Virchaux:1991jc}. This however has the
disadvantage of generating large scale ratios:
performing variations of
$\tilde\mu^2$ and $\mu_f^2$ sequentially we can obtain $\kappa_f = 2
\ln 4$, because
\be
\tilde\kappa
\lp \frac{\partial}{\partial t_f} + \frac{\partial}{\partial t
  _r} \rp + \kappa_f\ \frac{\partial}{\partial t_f} =
(\tilde\kappa+\kappa_f)\ \frac{\partial}{\partial t_f} +
\tilde\kappa \ \frac{\partial}{\partial t _r} \, .
\ee
A way of
avoiding these large ratios was constructed in
Ref.~\cite{vanNeerven:2000uj}: first do the  scale
variation of Eq.~(\ref{4.6}), but then substitute
\begin{equation}
    c_2  \to c_2 - (\kappa_r - \kappa_f) \beta_f c_1 = c_2 - (\ln \mu_f^2/\mu_r^2) \beta_0 c_1 \, ,
    \label{5.9}
 \end{equation}
where care must  be taken to use the correct argument of $\alpha_s$ in
each term.
%
Indeed, this procedure then agrees with Eq.~(\ref{5.7}) given that
\be
\kappa_f\ \frac{\partial}{\partial t_f} +
\kappa_r\ \frac{\partial}{\partial t _r} = \kappa_f
 \lp \frac{\partial}{\partial t_f} + \frac{\partial}{\partial t
  _r}\rp + (\kappa_r  -  \kappa_f)\frac{\partial}{\partial t _r} \, .
\ee

 

\subsubsection{Hadronic processes} \label{double_var_sec_hadr}

Consider now the case of  hadronic process as in  Eq.~(\ref{H.1}).
%
For these processes, the factorization  has the general form
%
\begin{equation}
	\overline{\Sigma}(t_f, t_r, \kappa_f, \kappa_r) = \overline{H}(\as(t_r), \kappa_r)\otimes  \lp \overline{f}(t_f, \kappa_f)\otimes\overline{f}(t_f, \kappa_f) \rp \, .
\end{equation}
%
The hard coefficient function will have the same expansion as
Eq.~(\ref{H.5}). Just as for electroproduction, it is 
possible to factorize variations of $\kappa_f$ into the hard
coefficient functions: then  
%
\begin{equation}
	\overline{\Sigma}(t_f, t_r, \kappa_f, \kappa_r) = \widehat{\overline{H}}(\as(t_r), \kappa_r,\kappa_f)\otimes ({f}(t_f)\otimes{f}(t_f)),
\end{equation}
%
where (using as above  Mellin space, to avoid the convolutions), one finds
\bea
    \widehat{\overline{H}} &=& ~\alpha_s^n(t_r) h_0 +
    \alpha_s^{n+1}(t_r)(h_1 - \kappa_r \ \beta_0 h_0) -
    2\alpha_s^n(t_r)\alpha_s(t_f) \kappa_0 \ h_0 \gamma_0 \nonumber\\ 
    &&\qquad + \alpha_s^{n+2}(t_r)\big(h_2 - \kappa_2(n\beta_1h_0 +
    (n+1)\beta_0 h_1) + \half \kappa_2^2 n(n+1) \beta_0^2 h_1\big) \nonumber\\ 
    &&\qquad - \alpha_s^{n+1}(t_r)\alpha_s(t_f)\big(\kappa_0 (h_1 -
    \kappa_2 \beta_0 h_0)2 \gamma_0\big)\nonumber\\ 
    &&\qquad +\alpha_s^n(t_r)\alpha_s^2(t_f)\big(- \kappa_0 h_0
    2\gamma_1 + \half \kappa_0^2h_02 \gamma_0 (\beta_0 +
    2\gamma_0)\big) + \ldots \, .    
\label{6.3}
\eea
%
However these expressions are even more cumbersome than in the case of
electroproduction,  thereby demonstrating the greater clarity of methods (A) or
(B) in determining the dependence on the scale $\mu_f$.
%
By adopting one of these two methods,
%
we can determine the MHOU in a hadronic process
through independent variations of the factorization scale $\mu_f$ and
the renormalization scale $\mu_r$ in just the same way as we estimated
the MHOU in the deep inelastic structure function in the previous section.

\subsection{Multiple scale variations} \label{multiple_var_sec}

We finally consider simultaneous scale variation in a pair of
processes: for instance the electroproduction
process of Sect.~\ref{double_var_sec_DIS} and a hadronic
process as in Sect.~\ref{double_var_sec_hadr}.
%
Clearly, the
PDF is universal, but the coefficient functions are
process-dependent.
%
It follows that scale variation $\kappa_f$ of the
PDF will be totally correlated between these two processes,
while the scale variations of 
$\kappa_r$ in the two coefficient functions will be totally independent.  


Now, considering both processes together, we have three
independent scales to vary, $\mu_f$, $\mu_{r_1}$, and $\mu_{r_2}$, where
$\mu_{r_1}$ is the renormalization scale for the deep inelastic process,
and $\mu_{r_2}$ is the renormalization scale for the hadronic process. The
relation of the
factorization scale $\mu_f$ to the physical scale of each process
(whatever that is) is the same for both processes, since the PDFs
are universal.
%
Thus if we vary all scales independently
by a factor two about their central value we end up with seven
scale choices.
%
We can think of the additional renormalization scale as an
extra dimension in the space of possible scale variations.

By trivial
generalization for $p$ independent processes $\pi_a$, $a=1,\ldots,p$,
we will have $p+1$ independent scale parameters
$\mu_f,\mu_{r_1},\ldots\mu_{r_p}$ corresponding to a total of 3+2$p$ scale variations.
%
Writing
$\kappa_{r_a} = \ln \mu_{r_a}^2/Q^2$ with $a= 1,\ldots,p$, the traditional range
of variation of $\kappa_f, \kappa_{r_1}, ..., \kappa_{r_p}$ would then be  defined by
\[
|\kappa_f| \leq \ln 4,\qquad |\kappa_{r_a}| \leq \ln 4,\qquad a=1,\ldots p \, .\label{eq:range}
\] 
Clearly all prescriptions constructed in this way will be symmetrical
in the different scales. 

We now see why, for the determination of MHOUs in PDFs, it is advantageous 
to work with 
the independent scales $\kappa_f$, $\kappa_{r_a}$, $a = 1,\ldots,p$ rather
than with  the traditional factorization scales $\tilde\kappa$ used in the
older treatments of scale variation: while the scale $\kappa_f$ used
to estimate MHOUs in the PDF evolution is universal, the scales
$\kappa_{r_a}$ used to estimate MHOUs in the hard cross-sections are instead
process-dependent.
%
We can therefore only define process scales $\tilde\kappa$ by
either introducing artificial correlations between the scales of the
hard cross-sections for different processes (which would result in
underestimated MHOU in the hard cross-sections), or else by sacrificing
universality of the PDFs, with uncorrelated evolution uncertainties
for different processes (which would result in overestimated MHOU from
PDF evolution). Neither of these options is very satisfactory, though
we consider the latter briefly in Sect.~\ref{sec_asym}
below, where it gives rise
to asymmetric scale-variation prescriptions. 

\section{Scale variation prescriptions for the theory covariance matrix}
\label{sec:prescriptions}

Having set out a general formalism for the inclusion of MHOUs
through a theory covariance matrix, based on assuming a
distribution of shifts between a  theory calculation at finite
perturbative order and the true all--order value (Sect.~\ref{sec:thcovmat}), and having discussed
how scale variation can be used to produce estimates for such shifts (Sect.~\ref{sec:scalevarn}), we
now provide an explicit prescription for the construction of a theory covariance
matrix from scale variation.
%
Because of the intrinsic arbitrariness involved in
the procedure, we actually propose several alternative prescriptions,
which will be then validated in the next section
by studying cases in which the next
perturbative order is in fact known.
%
We will also assess the impact at the PDF fit level of varying the prescription
used for constructing the theory covariance matrix.

We consider a situation in which we have $p$ different types of
processes $\pi_a =\{i_a\}$, where $i_a$ labels the data points
belonging to the $a$-th process and $a = 1,\ldots,p$.
%
Each of the $p$ processes is characterized  by a factorization scale
$\mu_f$ (associated with the PDFs) and a renormalization 
scale $\mu_{r_a}$ (associated with the hard coefficient functions), to be
understood in the sense of the `modern'
terminology in
Table~\ref{tab:scale_nomenclature}.
%
We will perform scale variation of both scales
following Sect.~\ref{double_var_sec}, by taking them as independent, as
discussed in that section.
%
When considering a pair of different processes, as
explained in Sect.~\ref{multiple_var_sec}, we assume the variations of
$\mu_{r_a}$ to be uncorrelated among them, while those of $\mu_f$ are taken to be fully
correlated.

The theory covariance matrix is then constructed by averaging outer products of the shifts
with respect to the central scales, given for the $a$-th process as
\begin{equation} \label{P.1}
  \Delta_{i_a} (\kappa_f, \kappa_{r_a} ) \equiv
  T_{i_a}(\kappa_f, \kappa_{r_a}) - T_{i_a}(0,0) \, ,
\end{equation}
over points in the space of scales.
%
Here, as before, we have defined 
$\kappa_{r_a}=\ln k_{r_a} = \ln \mu_{r_a}^2/Q^2$
and
$\kappa_{f}=\ln k_{f} = \ln \mu_{f}^2/Q^2$.
%
In Eq.~(\ref{P.1}),
$T_{i_a}(\kappa_f, \kappa_{r_a})$ indicates
the theoretical prediction evaluated at these scales with
$T_{i_a}(0,0)$ being the central theory prediction, and the index
$i_a$ running over all data points corresponding to process $a$.

We assume here that all scale variations correspond to the same range
\[
|\kappa_f| \leq w,\qquad |\kappa_{r_a}| \leq w,\qquad a=1,\ldots, p, \label{eq:rangew}
\] 
for some $w$ (typically $w = \ln 4$, as in Eq.~(\ref{eq:range})).
%
In practice, in each  prescription  the three points
$\kappa= 0, \pm w$ are sampled for each scale.
%
The theory covariance matrix is then
\begin{equation} \label{P.2}
  S_{ij} = n_m \sum_{V_m} \Delta_{i_a} (\kappa_f, \kappa_r) \Delta_{i_b} (\kappa_f, \kappa_s)
\end{equation}
where $i_a\ \in\ \pi_a$ and $i_b\ \in\ \pi_b$ indicate two data points,
possibly corresponding to different processes $\pi_a$ and $\pi_b$,
$m$ labels the
prescription, $V_m$ is the set of scale points to be summed over in
the given prescription, and $n_m$ is a normalization factor, both to
be determined.
%
Different prescriptions to construct the theory covariance matrix $S_{ij}$
vary in the set of  combination of scales which
are summed over in Eq.~(\ref{P.2}), as we will discuss below.

Because Eq.~(\ref{P.2}) is a sum of outer products of shifts, the theory
covariance matrix $S_{ij}$ is positive semi-definite by construction.
%
To demonstrate this, consider a real vector $e_i$: then it follows that 
 \begin{equation} \label{P.2pos}
 \sum_{ij} e_iS_{ij}e_j = N_m \sum_{V_m}  \lp \sum_i e_i\Delta_{i}\rp^2 \geq 0.
\end{equation}
Note however that because the number of elements of $V_m$ is finite,
$S_{ij}$ will generally be singular, since for any vector $z_j$ which
is orthogonal to the space $S$ spanned by the set of vectors
$\{\Delta_{i_a}(\kappa_f, \kappa_{r_a}): \kappa_f, \kappa_{r_a} \in V_m\}$,
$S_{ij}z_j=0$.
%
This property will be important when we come to validate the
covariance matrix in the following section.

We now consider various prescriptions.
%
Because $S_{ij}$ will in general span the full set of data points, we must
consider both the case in which points $i,\>j$ in Eq.~(\ref{P.2})
belong to the same process (``single process prescription'') and the
case in which they belong to two different processes  (``multiple
process prescription'').
%
We first discuss the case of symmetric scale
variation, in which the two scales are varied independently, and then
the case in  which the two scales are varied in a correlated way, the latter scenario being equivalent to varying the ``scale of the process" (in the sense of Table~\ref{tab:scale_nomenclature}), thereby
leading to asymmetric prescriptions as already mentioned in Sect.~\ref{multiple_var_sec}.
 
\subsection{Symmetric prescriptions for individual processes}
\label{sec:sympres}

We  consider first the prescriptions for when there is just a
single process, that is, $p=1$.
%
In this case, there are at most two
independent scales, the factorization and renormalization scales $\kappa_f$ and $\kappa_r$. The theory covariance matrix is then constructed as
\begin{equation}
  \label{P.3}
  S_{ij} = n_{m} \sum_{v_{m}} \Delta_{i} (\kappa_f, \kappa_r)\Delta_{j} (\kappa_f, \kappa_r)\, ,
\end{equation}
where again $v_m$ represents the set of points to be summed over in the given
prescription, limited here to points in the space of the two scales
$\kappa_f$ and $\kappa_r$, and $n_m$ is the normalization factor.
%
Let $s$ be
the number of independent scales being varied (so $s=1$ or $s=2$), and
$m$ be the number of points in the variation (so $m$ is the number of
elements of $v_m$): a given scheme is then usually described as an
`$(m+1)$-point scheme'.
%
Note that we do not include in $v_m$ trivial points
for which $\Delta_{i}$ vanishes (which in practice means the single
point $\kappa_f=\kappa_r=0$), since these do not contribute to the
sum. 

The normalization factor $n_m$ in Eq.~(\ref{P.3})
is determined by averaging over the number of
points associated with the variation of each scale,  and adding the
contributions from variation of independent scales. This means that  
\begin{equation}
  \label{P.4}
n_m = s/m.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
\centering
{\begin{tikzpicture}
\draw[->] (-1.5,0) -- (1.5,0);
\draw[->] (0,-1.5) -- (0,1.5);
\filldraw[black] (0,0) circle (2pt);
\filldraw[black] (-1,0) circle (2pt);
\filldraw[black] (0,-1) circle (2pt);
\filldraw[black] (1,0) circle (2pt);
\filldraw[black] (0,1) circle (2pt);
\node at (0.5,1.5) {$\kappa_r$};
\node at (1.9,0) {$\kappa_f$};
\end{tikzpicture}}\qquad
{\begin{tikzpicture}
\draw[->] (-1.5,0) -- (1.5,0);
\draw[->] (0,-1.5) -- (0,1.5);
\filldraw[black] (0,0) circle (2pt);
\filldraw[black] (-1,-1) circle (2pt);
\filldraw[black] (1,1) circle (2pt);
\filldraw[black] (1,-1) circle (2pt);
\filldraw[black] (-1,1) circle (2pt);
\node at (0.5,1.5) {$\kappa_r$};
\node at (1.9,0) {$\kappa_f$};
\end{tikzpicture}}\qquad
{\begin{tikzpicture}
\draw[->] (-1.5,0) -- (1.5,0);
\draw[->] (0,-1.5) -- (0,1.5);
\filldraw[black] (0,0) circle (2pt);
\filldraw[black] (-1,0) circle (2pt);
\filldraw[black] (0,-1) circle (2pt);
\filldraw[black] (1,0) circle (2pt);
\filldraw[black] (0,1) circle (2pt);
\filldraw[black] (-1,-1) circle (2pt);
\filldraw[black] (1,-1) circle (2pt);
\filldraw[black] (-1,1) circle (2pt);
\filldraw[black] (1,1) circle (2pt);
\node at (0.5,1.5) {$\kappa_r$};
\node at (1.9,0) {$\kappa_f$};
\end{tikzpicture}}
\begin{caption}{Symmetric prescriptions for a single process, indicating
    the sampled values for the factorization scale $\kappa_f$ and 
    renormalization scale $\kappa_r$ in each case.
    %
    The origin of coordinates corresponds to the
    central scales $\kappa_f=\kappa_r= 0$.
    %
    We show the three prescriptions 
    $5$-point (left), $\bar{5}$-point (center) and $9$-point (right).
\label{fig:symmetricPrescriptions}
  }
\end{caption}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We consider three different prescriptions, represented schematically
in Fig.~\ref{fig:symmetricPrescriptions}.
\begin{itemize}
%
\item \textbf{5-point}: we vary $\kappa_f$ keeping $\kappa_r = 0$ and vice versa, so 
$v_4 = \{(\pm;0), (0; \pm) \}$, where the pairs denote the values of
  the two independent scales $(\kappa_f; \kappa_r)$. Then $s=2$,
  $m=4$, and the normalisation is $n_4 = 1/2$.
%
  This definition implies that we can average over the two nontrivial values
  of the each scale in turn, and add the results: 
\begin{equation}\label{5S}
    S^{\rm (5pt)}_{ij} = \smallfrac{1}{2}\big\{ \Delta_i^{+0}\Delta_j^{+0} + \Delta_i^{-0} \Delta_j^{-0} + \Delta_i^{0+} \Delta_j^{0+} + \Delta_i^{0-} \Delta_j^{0-}  \big\} \, ,
\end{equation}
where 
we have adopted the abbreviated notation $\Delta_i^{+0}=\Delta_i(+w,0)$, $\Delta_i^{0-}=\Delta_i(0,-w)$, etc. for the shifts. 

Note that the variations of $\kappa_f$ and $\kappa_r$ are added in quadrature since they are
  independent: this is why it is important to make sure that the
  variations are indeed independent, as is the case for
  renormalization and factorization scales, as discussed in Sect.~\ref{double_var_sec}. 

\item \textbf{$\overline{5}$-point}: this is an alternative 5-point
  prescription, which is basically the complement of 5-point:
  $\overline{v}_4 = \{(\pm; \pm) \}$, where $(\pm;\pm)$ are assumed
  uncorrelated, i.e. 4 independent points.
  %
  The counting is the same
  as for 5-point: $s=2$, $m=4$ and again $\overline{n}_4 = 1/2$:  
\begin{equation}\label{5bS}
    S^{(\rm \overline{5}pt)}_{ij} = \smallfrac{1}{2}\big\{ \Delta_i^{++}\Delta_j^{++} + \Delta_i^{--}\Delta_j^{--} + \Delta_i^{+-}\Delta_j^{+-} + \Delta_i^{-+} \Delta_j^{-+}\big\} \, .
\end{equation}
As before, the two scales are varied in a manifestly independent way.

\item \textbf{9-point}: here we vary $\kappa_f$ and $\kappa_r$
  completely independently, giving the union of the 5-point and
  $\overline{5}$-point prescriptions: $v_8=v_4\oplus \overline{v}_4$.  Now $s=2$, $m=8$ and $n_8=1/4$, and
  the theory covariance matrix is given by
\begin{equation}\label{9S}
\begin{split}
    S^{(\rm 9pt)}_{ij} = \smallfrac{1}{4}\big\{ &\Delta_i^{+0} \Delta_j^{+0} + \Delta_i^{-0}\Delta_j^{-0}
                            + \Delta_i^{0+} \Delta_j^{0+} + \Delta_i^{0-}\Delta_j^{0-} \\
                            + &\Delta_i^{++}\Delta_j^{++} + \Delta_i^{+-} \Delta_j^{+-}
                            + \Delta_i^{-+}\Delta_j^{-+} + \Delta_i^{--} \Delta_j^{--} \big\} \, .
\end{split}                            
\end{equation}
\end{itemize}

\subsection{Symmetric prescriptions for multiple processes}
\label{sec:sympresmul}


Now we consider multiple processes, i.e. $p>1$, with scale variations
either uncorrelated or partially correlated.
%
In Eq.~(\ref{P.2}), the set $V_m$ now involves possible variations
of the $p+1$ scales $\kappa_f$, $\kappa_{r_1},\ldots\kappa_{r_p}$, where $\kappa_{r_a}$ indicates
the renormalization
scale for process $a=1,\ldots,p$.
%
This implies that now
  $V_m$ is a much bigger set than $v_m$.
%
  However any given element of $S_{ij}$
in Eq.~(\ref{P.2}) can involve at most two different processes, $\pi_a$
and $\pi_b$, so to compute this element we can simply ignore the other
processes.
%
Consequently, it is sufficient to consider $p=2$, since
generalization to $p>2$ will then be straightforward.  

For a given pair of processes, say $\pi_1$ and $ \pi_2$, the
covariance matrix has
diagonal elements $S_{i_1j_1}, S_{i_2j_2}$ and off-diagonals
$S_{i_1j_2} = S_{j_2i_1}$, where as above the extra subscript indicates the
process: $i_1,j_1\in\pi_1$, $i_2,j_2\in\pi_2$.
%
Thus one can write
\begin{equation}
  \label{P.2.2}
  S_{ij} = \left(\begin{array}{cc}
S_{i_1j_1}&S_{i_1j_2}\\ 
S_{i_2j_1}&S_{i_2j_2}\end{array}\right)\, .
\end{equation} 
Consider first the diagonal blocks $S_{i_1j_1}$ and
$S_{i_2j_2}$.
%
Adding process $\pi_2$ cannot change the theoretical
uncertainty in process $\pi_1$, although the two uncertainties may be
correlated.
%
Consequently $S_{i_1j_1}$ and $S_{i_2j_2}$ are each given
by the same expression as in the single-process case, Eq.~(\ref{P.3}), so we must have 
 \begin{equation} \label{P.2.3}
S_{i_1j_1}= N_m \sum_{V_m} \Delta_{i_1} (\kappa_f, \kappa_{r_1}) \Delta_{j_1} (\kappa_f, \kappa_{r_1})=
n_{m} \sum_{v_{m}} \Delta_{i_1} (\kappa_f, \kappa_{r_1})\Delta_{j_1} (\kappa_f, \kappa_{r_1}) \, .
\end{equation}
 This can only be true if the set of points $v_m$ in
 Eq.~(\ref{P.3}) is a
subset of the set $V_m$ in Eq.~(\ref{P.2}): so when for example computing
$S_{i_1j_1}$, $\Delta_{i_1}$ and $\Delta_{j_1}$ depend only on the
scales $\kappa_f$ and $\kappa_{r_1}$ associated with $\pi_1$, and are
independent of the scale $\kappa_{r_2}$ associated with $\pi_2$.
%
Consequently, when we sum over $V_m$ in Eq.(\ref{P.2}), performing the
trivial sum over $\kappa_{r_2}$ must reduce $V_m$ to its subset $v_m$, up
to a degeneracy factor $d_m$ which counts the number of copies of
elements of $v_m$ contained in $V_m$.
%
This fixes the overall
normalization factor $N_m$: 
\begin{equation} \label{P.5}
N_m = n_m/d_m \, .
\end{equation}

It remains to determine $V_m$ for a given $(m+1)$-point prescription. It is
easy to see that in each case we obtain a unique result, which is
in a sense a direct product of $p$ copies of $v_m$, taking into account the common scale $\kappa_f$.
%
The points in the $(\kappa_f,\kappa_{r_1},\kappa_{r_2})$ space that are being
sampled in each prescription when there are two processes are shown in Fig.~\ref{fig:symmetricPrescriptions2proc} (corresponding to the single-process prescriptions shown in 
Fig.~\ref{fig:symmetricPrescriptions}). 

To show how this works, we consider each prescription 
in turn, starting with the $\overline{5}$-point prescription which is easier to construct than $5$-point.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\begin{figure}[t]
\centering
\includegraphics[scale=0.39]{mhous/plots//5pt_3D.png}
\includegraphics[scale=0.39]{mhous/plots//5barpt_3D.png}
\includegraphics[scale=0.39]{mhous/plots//9pt_3D.png}
\begin{caption}{\small Same as Fig.~\ref{fig:symmetricPrescriptions}, now
    for the case of two different processes $\pi_1$ and $\pi_2$
    with a common factorization scale $\kappa_f$ and different renormalization scales $\kappa_{r_1}$
    and $\kappa_{r_2}$, so the diagrams are now in three dimensions. The origin 
of coordinates is associated to the central scale, $\kappa_f=\kappa_{r_1}=\kappa_{r_2}=0$
    %
    We again show the three prescriptions $5$-point (left), $\bar{5}$-point (center) and $9$-point (right).}
  \label{fig:symmetricPrescriptions2proc}
\end{caption}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}

\item \textbf{$\overline{5}$-point}: for two processes, $\pi_1$ and 
$\pi_2$ say, we now have 
three scales, $\kappa_f, \kappa_{r_1}, \kappa_{r_2}$ which can each be varied
independently.
%
For the $\overline{5}$-point prescription we only consider variations in
which none of the scales is at the central value: $\overline{v}_4 =
\{(\pm;\pm)\}$,  where 
the $\pm$ variations are performed independently.
%
It follows that  
$\overline{V}_4 = \{(\pm;\pm,\pm)\}$, where the triples denote the
three independent scales, $(\kappa_f; \kappa_{r_1},\kappa_{r_2})$, varied
independently.

The set $\overline{V}_4$ thus has eight points in total.
%
For each element of $\overline{v}_4$, there are two elements of
$\overline{V}_4$, so $\overline{d}_4=2$, and since
$\overline{n}_4=1/2$, $\overline{N}_4=1/4$.
%
The result for the
off-diagonal blocks of the theory covariance matrix in this prescription is thus
given by
\begin{equation}
  \label{5bM}
    S^{(\rm \overline{5}pt)}_{i_1j_2} = \smallfrac{1}{4}\big\{ \big(\Delta_{i_1}^{++} + \Delta_{i_1}^{+-}\big) \big(\Delta_{j_2}^{++} + \Delta_{j_2}^{+-} \big) 
    + \big(\Delta_{i_1}^{-+} + \Delta_{i_1}^{--}\big) \big(\Delta_{j_2}^{-+} + \Delta_{j_2}^{--} \big) \big\} \, .
\end{equation}
From this expression it is clear that while the scale $\kappa_f$ is
varied coherently between the two processes, the scales $\kappa_{r_1}$ and
$\kappa_{r_2}$ are varied incoherently, as required. 

It is straightforward to generalize this procedure to three processes:
then $\overline{V}_4 = \{(\pm;\pm,\pm,\pm)\}$, so $\overline{d}_4=4$,
and since $\overline{n}_4=1/2$, $\overline{N}_4=1/8$.  However
Eq.~(\ref{5bM}) remains unchanged, in the sense that it can be used to
evaluate all three off-diagonal blocks $s_{i_1j_2}$, $s_{i_2j_3}$,
$s_{i_3j_1}$: this must always be the case, since each term in the sum
Eq.~(\ref{P.2}) involves at most three scales.
%
For $p$ processes, it is
easy to see that the number of distinct elements of $V_4$ is
$2^{p+1}$. 

\item \textbf{5-point}: again for two processes we have three
  scales, but now one varies each holding the other fixed to its central 
value: $v_4 =  \{(\pm;0),(0;\pm)\}$, so  
$V_4 = \{2(\pm;0,0), (0;\pm,\pm)\}$, where the two in front of the
  first element indicates that there are two copies of it, so $V_4$
  has eight elements in total.
%
  Then for each element of $v_4$, there are
  precisely two elements of $V_4$, so $d_4=2$, and since $n_4=1/2$,
  $N_4=1/4$.
  %
  The result for the off-diagonal entries of the theory covariance matrix
  in this prescription is thus  given by
\begin{equation}\label{5M}
    S^{(\rm 5pt)}_{i_1j_2} = \smallfrac{1}{4}\big\{ 2\Delta_{i_1}^{+0}\Delta_{j_2}^{+0} + 2\Delta_{i_1}^{-0}\Delta_{j_2}^{-0}  
            + \big(\Delta_{i_1}^{0+} + \Delta_{i_1}^{0-} \big)\big(\Delta_{j_2}^{0+} + \Delta_{j_2}^{0-}\big)\big\}.
\end{equation}
Note that also in this expression the variations of  $\kappa_f$ are
manifestly correlated between the two processes, whereas the
variations of $\kappa_{r_1}, \kappa_{r_2}$ are not.  

When there are three processes, it is easy to see that 
$V_4 = \{4(\pm;0,0,0), (0;\pm,\pm,\pm)\}$, i.e. it has 16 elements,
though only 10 are distinct: the other six are simply copies,
necessary to obtain the correct coefficients in Eq.~(\ref{5S}) and
Eq.~(\ref{5M}).
%
There are now four elements of $V_4$ for each element of
$v_4$, so now $d_4=4$, and $N_4=1/8$.
%
Again Eq.~(\ref{5M}) can be used
to calculate all three off-diagonal blocks. For $p$ processes, it is
easy to see that $V_4$ has $2^{p+1}$ elements, but that only  
$2+2^p$ of these are actually distinct.   

\item \textbf{9-point}: here we vary the three scales completely
  independently: $v_8 = v_4 \oplus \overline{v}_4$. Constructing
  $V_{8}$ is now somewhat more involved, since while terms with $\kappa_f=0$
  have degeneracy 2, terms where $\kappa_f=0$ is varied have
  degeneracy 3, so we need three copies of the former and two of the
  latter to take the overall degeneracy to 6.
%
  The solution is thus 
$V_8= \{3(0;\pm,\pm), 2(\pm;\pmz,\pmz)\}$, where  
$\pmz$ means either $+$, $-$ or $0$. Thus $V_8$ has $48$ elements, of 
  which only $22$ are actually distinct.
%
  Since the first term of $V_8$
has a degeneracy of $2$, while the last has a degeneracy of $3$, the
overall degeneracy is $d_8=6$, and since $n_8=1/4$, $N_8=1/24$.
%
It follows that the off-diagonal blocks of the theory covariance matrix
in this prescription are
\begin{equation}\label{9M}
\begin{split}
    S^{(\rm 9pt)}_{i_1j_2} =
    \smallfrac{1}{24}\big\{&2\big(\Delta_{i_1}^{+0}+\Delta_{i_1}^{++}
    + \Delta_{i_1}^{+-}\big) \big(\Delta_{j_2}^{+0} +
    \Delta_{j_2}^{++} + \Delta_{j_2}^{+-} \big) \\ 
            + &2\big(\Delta_{i_1}^{-0} + \Delta_{i_1}^{-+} +
            \Delta_{i_1}^{--}\big)\big(\Delta_{j_2}^{-0} +
            \Delta_{j_2}^{-+} + \Delta_{j_2}^{--} \big) \big\}\\ 
            + &3\big(\Delta_{i_1}^{0+}+ \Delta_{i_1}^{0-}\big)\big(\Delta_{j_2}^{0+} + \Delta_{j_2}^{0-} \big)\big\}.
\end{split}            
\end{equation}
The pattern of correlations in the variation of the three scales in this expression should be clear from the way it is written.

When there are  three processes, $V_8= \{9(0;\pm,\pm,\pm),
4(\pm;\pmz,\pmz,\pmz)\}$, whence $d_8=36$, and since $n_8=1/4$,
$N_8=1/144$.
%
Again, Eq.~(\ref{9M}) can be used to calculate all three
off-diagonal blocks. $V_8$ now has $288$ elements, of which $62$ are
distinct. For $p$ processes, there are $2^p+2\cdot3^p$ distinct elements.  

\end{itemize}

\subsection{Asymmetric prescriptions}\label{sec_asym}
\label{sec:asympres}


It is sometimes argued that since only the cross-section is actually physical, 
a single process has only one scale, namely the scale of the process in the
sense of Table~\ref{tab:scale_nomenclature} and
Eq.~(\ref{4.1}).
%
Therefore,  in order to estimate the MHOUs, only this single scale should be varied.
%
Alternatively, one may consider the
variation of the scale of the process {\it on top} of the variation of
the renormalization and factorization scales considered
previously.

The logic of the first alternative (variation of the scale of the
process only) is that after all
there is only one scale in the factorised expressions, for example those given by the Wilson expansion applied to DIS.
%
The logic of the second alternative (variation of the scale of the process, the
renormalization scale, and the factorization scale) is that each of
these estimates a different source of MHOU:
varying the scale of the
process generates terms related to missing higher order contributions to the 
hard cross-section which are proportional to collinear logarithms, the
renormalization scales to missing higher order contributions to  the hard
cross-section which are proportional to the beta function, and finally
the factorization scale to missing higher order contributions to the anomalous
dimension.

On the other hand, both alternatives might be criticized on the grounds that they suppress correlations between the uncertainties in PDF evolution across
different processes, and thus seriously overestimate uncertainties (the first worse than the second). Ultimately, however, they can 
be considered as possible options to be tested in a situation
in which the true answer is known. Such a validation will be performed in the next section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
\centering
{\begin{tikzpicture}
\draw[->] (-1.5,0) -- (1.5,0);
\draw[->] (0,-1.5) -- (0,1.5);
\filldraw[black] (0,0) circle (2pt);
\filldraw[black] (-1,-1) circle (2pt);
\filldraw[black] (1,1) circle (2pt);
\node at (0.5,1.5) {$\kappa_{r_1}$};
\node at (1.9,0) {$\kappa_f$};
\end{tikzpicture}}\qquad
{\begin{tikzpicture}
\draw[->] (-1.5,0) -- (1.5,0);
\draw[->] (0,-1.5) -- (0,1.5);
\filldraw[black] (0,0) circle (2pt);
\filldraw[black] (-1,0) circle (2pt);
\filldraw[black] (0,-1) circle (2pt);
\filldraw[black] (1,0) circle (2pt);
\filldraw[black] (0,1) circle (2pt);
\filldraw[black] (-1,-1) circle (2pt);
\filldraw[black] (1,1) circle (2pt);
\node at (0.5,1.5) {$\kappa_{r_1}$};
\node at (1.9,0) {$\kappa_f$};
\end{tikzpicture}}
\begin{caption}{Same as Fig.~\ref{fig:symmetricPrescriptions},
    now in the case of the asymmetric prescriptions for a single process
    with factorization scale $\kappa_f$ and renormalization scale $\kappa_r$.
    %
    We display the 
    $3$-point (left) and $7$-point (right) prescriptions, defined in the text.}
  \label{fig:AsymmetricPrescriptions1proc}
\end{caption}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now consider these two options in turn, both for the single-process
case, which is represented schematically
in Fig.~\ref{fig:AsymmetricPrescriptions1proc}, and for multiple-processes.

\begin{itemize}

\item \textbf{3-point}: For a single process,
  we set $\kappa_f = \kappa_r$  and only vary the single resulting scale. Then $v_2 = \{\pm\}$
  in an obvious notation, and $s =1$, $m=2$ and $n_2 = 1/2$, i.e. we
  simply average over the two nontrivial values of the single
  scale.
  %
  For a single process we thus find that
\begin{equation}\label{3S}
    S^{(\rm 3pt)}_{ij} = \smallfrac{1}{2}\big\{ \Delta_i^{++}\Delta_j^{++}  + \Delta_i^{--}\Delta_j^{--}\big\} \, ,
\end{equation}
%
whenever $i,j\in \pi$.

Likewise, for two different processes $\pi_1$ and $\pi_2$, we set $\kappa_f = \kappa_{r_1}$ 
for $\pi_1$, set $\kappa_f = \kappa_{r_2}$ for $\pi_2$, and then vary
$\kappa_{r_1}$ and $\kappa_{r_2}$ independently.
%
This procedure necessarily
ignores the correlations in  
the variation of $\kappa_f$ between $\pi_1$ and $\pi_2$. Since $v_2 =
\{\pm\}$, $V_2 = v_2 \otimes v_2 = \{\pm, \pm \}$, where the ordered
pairs denote the two independent scales $(\kappa_{r_1},\kappa_{r_2})$.
%
Clearly,
for each element of $v_2$ there are two elements of $V_2$, so $d_2 =2$, 
Eq.~(\ref{P.5}) gives $N_2 = 1/4$, and the off-diagonal
entries of the theory covariance matrix are
\begin{equation}
    S^{(\rm 3pt)}_{i_1j_2} = \smallfrac{1}{4}\big\{\big(\Delta_{i_1}^{++} + \Delta_{i_1}^{--} \big) \big(\Delta_{j_2}^{++} + \Delta_{j_2}^{--} \big) \big\}\, .
\end{equation}
It can be seen from this factorised expression that the
variations for each process are entirely uncorrelated. Generalization
to more than two processes is straightforward: for $p$ processes $V_2$
has $2^p$ elements, all of them distinct. 

Because in this prescription we ignore correlations in the PDF evolution uncertainties, we expect this prescription to significantly overestimate the MHOUs.
%
Note that a fully correlated 3-point prescription in which we set
$\kappa_f = \kappa_{r_1} = \kappa_{r_2}$ would instead significantly underestimate
the MHOUs, which is why we do not consider it.

\item \textbf{7-point}:  We now  combine the variation of the scale
  of the process to the variation of renormalization and factorization scales.
As we saw in Sect.~\ref{double_var_sec}, a change in the scale
of the process is generated by $\tilde\kappa (\partial_{t_r} +
\partial_{t_f})$, so it moves diagonally in the
$(\kappa_f,\kappa_{r})$ plane.
%
Thus for a single process, varying the
scale of the process just corresponds to a new point-prescription,
symmetric only about the line $\kappa_f=\kappa_r$, but
asymmetric about the $\kappa_f$ and $\kappa_r$ axes.
%
However, because
variations of the scale of the process are assumed uncorrelated across
different processes, while $\mu_f$ variations are correlated, such a
scheme can give reduced correlations when there several processes. 

For a single process, variation of the scale of the process just gives
two extra points $(+;+),(-;-)$ (in the same notation as before,
i.e. variations in the $\kappa_f=\kappa_r$ plane), so $v_4 =\{(\pm;0),(0;\pm)\}$ becomes $v_6 = \{(\pm;0),(0;\pm),(+;+),(-;-)\} =\{(\pm;0),(0;\pm),(\overline{\pm;\pm})\}$, where $(\overline{\pm;\pm})$ simply means that the variation is fully correlated (so there are only 2 terms, not 4).

We then have $v_6 = \{(\pm;0),(0;\pm),(\overline{\pm;\pm})\}$, $s=2$ (note we still have only two independent scales), $m=6$ and $n_6 = 1/3$, and thus for a single process
\begin{equation}\label{7S}
    S^{(\rm 7pt)}_{ij} = \smallfrac{1}{3}\big\{ \Delta_i^{+0}\Delta_j^{+0} + \Delta_i^{-0}\Delta_j^{-0} + \Delta_i^{0+}\Delta_j^{0+}  + \Delta_i^{0-}\Delta_j^{0-}  
        + \Delta_i^{++}\Delta_j^{++} + \Delta_i^{--}\Delta_j^{--}  \big\} \, .
\end{equation}
%

When there is more than one process, we have to remember that
variations of the scale of the process are uncorrelated between
different processes, so they can decorrelate the allowed variations of
$\mu_f$.
%
This means the allowed variations for two processes are in a space
of four dimensions rather than three: call these say
($\kappa_{f_1},\kappa_{r_1};\kappa_{f_2},\kappa_{r_2})$. The extension of $v_6$ is then  
$V_6=\{2(+,0;+,0),2(-,0;-,0),(0,\pm;0,\pm),(\overline{\pm,\pm};\overline{\pm,\pm})\}$, where $(\overline{\pm,\pm};\overline{\pm,\pm})=\{(+,+;+,+),(+,+;-,-),(-,-;+,+),(-,-;-,-)\}$, and thus $d_6=2$, so $N_6=1/6$, and the off-diagonal theory covariance matrix reads
\begin{equation}\label{7M}
  \begin{split}
    S^{(\rm 7pt)}_{i_1j_2} =& \smallfrac{1}{6}\big\{ 2\Delta_{i_1}^{+0} \Delta_{j_2}^{+0}  + 2\Delta_{i_1}^{-0} \Delta_{j_2}^{-0} 
             + \big(\Delta_{i_1}^{0+}+\Delta_{i_1}^{0-}\big)\big(\Delta_{j_2}^{0+} + \Delta_{j_2}^{0-} \big)
            \\&+\big(\Delta_{i_1}^{++}+\Delta_{i_1}^{--}\big) \big(\Delta_{j_2}^{++} + \Delta_{j_2}^{--} \big) \big\} \, .
            \end{split}
\end{equation} 
This prescription gives smaller correlations than the 
symmetric prescriptions
since the variation of the two
factorisation scales $\mu_{f_1}$ and $\mu_{f_2}$ is now entirely
uncorrelated. 

Generalization to $p$ processes is again straightforward: since the
variations of the scale of the process are in effect independent of
the separate variations of $\mu_f$ and $\mu_r$, $V_6=V_4\oplus V_2$
for any number of processes, so there are in total $2+2^{p+1}$
distinct elements. 

\end{itemize}

\section{Validation of the theory covariance matrix}
\label{sec:results}

In this section we determine the theory covariance matrix $S_{ij}$ at NLO
using the different prescriptions formulated in
Sect.~\ref{sec:prescriptions}, we introduce a method for the
validation of the theory covariance matrix when the next-order result
is known, and we use it to validate the theory covariance matrices
that we computed against the known NNLO results.
%
This validation is performed on a global dataset based on the same processes
as those used in the NNPDF3.1 PDF determination.
%
This dataset will then be used to produce fits incorporating MHOUs using 
the theory covariance matrix (Sect.~\ref{sec:fitstherr}), and also,
for comparison,  
fits using scale-varied theories (Appendix~\ref{sec:fitsscalesvar}).
 
\subsection{Input data and process categorization}
\label{sec:inputdata}

The validation of the theory covariance matrix and the PDF
determination to be discussed in the next section are performed using
a set of theory predictions for a dataset which is very similar to 
that used in the NNPDF3.1 PDF determination~\cite{Ball:2017nwa}, but
differs from it in some details, as we now discuss.

%
The input dataset used here
includes fixed-target~\cite{Arneodo:1996kd,Arneodo:1996qe,
Whitlow:1991uw,bcdms1,bcdms2,Goncharov:2001qe,MasonPhD,Onengut:2005kv} 
and HERA~\cite{Abramowicz:2015mha} deep-inelastic inclusive structure functions;
charm cross-sections from HERA~\cite{Abramowicz:1900rp};
gauge boson production from the Tevatron~\cite{Aaltonen:2010zza,Abazov:2007jy,
D0:2014kma,Abazov:2013rja}; and electroweak boson production, 
inclusive jet, $Z$ $p_T$ distributions, and $t\bar{t}$ total and differential
cross-sections from ATLAS~\cite{Aad:2011dm,Aaboud:2016btc,Aad:2014qja,
Aad:2013iua,Aad:2015auj,Aad:2011fc,Aad:2014kva,Aaboud:2016pbd,Aad:2015mbv},
CMS~\cite{Chatrchyan:2013tia,Chatrchyan:2012xt,Chatrchyan:2013mza,
Khachatryan:2016pev,Khachatryan:2015oaa,Chatrchyan:2012bja,Khachatryan:2016mqs, 
Khachatryan:2015uqb,Khachatryan:2015oqa} 
and LHCb~\cite{Aaij:2012vn,Aaij:2012mda,Aaij:2015gna,Aaij:2015zlq} 
at $\sqrt{s}=7$ and 8 TeV (two data points for the ATLAS and 
CMS total $t\bar{t}$ cross-sections are at 13 TeV).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp!]
  \centering
  \input{mhous/tables/datasets_process_categorisation.tex}
  \caption{\small The categorization of the input datasets into different processes
    adopted
    in this work.
    %
    Each dataset is assigned to one of five categories:
    neutral-current DIS (DIS NC),
    charged-current DIS (DIS CC), Drell-Yan (DY), jet production (JET) and top quark
    pair production (TOP).
    %
    For each dataset, we also provide the corresponding publication reference
    and the number of data points after cuts.
%
We also show the total number of points in each of the five
categories of process.
    \label{tab:datasets_process_categorisation}}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This input dataset differs in many small respects from that used in the
NNPDF3.1 baseline.
%
Firstly, the fixed-target Drell-Yan (DY)
cross-sections~\cite{Webb:2003ps,Webb:2003bj,Towell:2001nh,Moreno:1990sf} are
excluded from the fit  since {\tt APFEL} currently does
not allow the calculation of scale-varied fixed-target DY cross-sections.
%
Secondly, the value of the lower kinematic
cut has been increased from
$Q_{\rm min}^2=2.69$~GeV$^2$ to
$13.96$~GeV$^2$ in order to ensure the validity of the
perturbative QCD expansion when scales 
are varied downwards.
%
Thirdly, we include only jet data for which the exact NNLO calculations
are available, as discussed in~\cite{Ball:2018iqk}, namely the
ATLAS and CMS inclusive jet cross-sections at 7 TeV
from the 2011 dataset.
%
Finally, we exclude the  bottom structure
function $F_2^b$ measurements, for which the implementation
of scale variations is complicated by the crossing of the heavy quark
thresholds.

Also, in original NNPDF3.1 determination
somewhat different cuts were applied to data at
NLO and NNLO (essentially in order to remove from the NLO fit data
which are subject to large NNLO corrections). Here we wish to have
exactly the same dataset at NLO and NNLO, in order to make sure that 
the differences between NLO and NNLO are due purely to differences in 
the theoretical calculations, and not in the input datasets. Therefore, the
baseline kinematic cuts of NNPDF3.1 have been slightly
modified so that the data points excluded at NLO are also excluded at NNLO
and vice-versa.

Taking into account all these modifications,  in total
the input dataset includes $N_{\rm dat}=2819$ datapoints.

Because the prescriptions in
Sect.~\ref{sec:prescriptions} assume that
renormalization scale variation is fully correlated within a given
process, but uncorrelated between different processes, it is necessary
to define what it is meant by ``process'', i.e., to classify
datasets into processes. This requires an educated
guess as to which theory computations share the same higher order
corrections. For example, it is necessary to decide whether
charged-current (CC) and neutral-current (NC) DIS are the
same process or not, and whether the transverse momentum
and rapidity distributions for one observable (such as, say, $Z$
production) should be grouped together.
Our categorization is summarized in Table~\ref{tab:datasets_process_categorisation}.
%
Specifically, we group the data into five distinct categories: DIS NC, DIS CC, Drell-Yan (DY), inclusive jet
production (JET), and top quark pair production (TOP). More refined
categorizations will be considered elsewhere, but we consider this to
be sufficient for a first study. 

All calculations are performed using 
the same settings as in~\cite{Ball:2017nwa}:
%
PDF evolution and the calculation of DIS structure functions up to NNLO
are carried out using the {\tt APFEL}~\cite{Bertone:2013vaa} program;
%
heavy quark mass effects are included by means of the FONLL general-mass variable
flavor number scheme~\cite{Forte:2010ta,Ball:2015dpa,Ball:2015tna}; 
the charm PDF is fitted alongside the light quark PDFs~\cite{Ball:2016neh}, 
rather than being generated from perturbative evolution of light 
partons; the charm quark pole mass is taken to be $m_c=1.51$~GeV,
%
and the strong coupling constant is fixed to be $\as(m_Z) = 0.118$, consistent
with the latest PDG average~\cite{Olive:2016xmw}.

In order to evaluate the theory covariance matrix $S_{ij}$, it is necessary
to be able to evaluate both DIS structure functions and hadronic
cross-sections for a range of values of the factorization
and renormalization scales, i.e., in the notation of Eq.~(\ref{eq:scaledef}), for $\kappa_f\ne 0$ and $\kappa_r\ne 0$.
%
In this case, the entries of the NLO theory covariance matrix have been 
constructed
by means of the {\tt ReportEngine} software~\cite{zahari_kassabov_2019_2571601}
taking the
scale-varied NLO theory cross-sections $T_i(k_f,k_r)$  as input.
%
These are provided 
by {\tt APFEL}~\cite{Bertone:2013vaa} for the DIS structure functions
and by {\tt APFELgrid}~\cite{Bertone:2016lga} combined with
{\tt APPLgrid}~\cite{Carli:2010rw} for the hadronic
cross-sections.
%
The evaluation of these scale-varied cross-sections has been validated
by means of independent programs, in particular with {\tt HOPPET}~\cite{Salam:2008qg}
and {\tt OpenQCDrad}~\cite{Alekhin:2012ig}
for the DIS structure functions, and with the built-in scale variation
functionalities of {\tt APPLgrid}. All these NLO cross-sections are evaluated using the central NLO PDF obtained by performing a NLO fit to the same dataset, for consistency.

\subsection{The theory covariance matrices at NLO}
\label{sec:nlothcov}

We now present results for the
theory covariance matrices, constructed using NLO calculations
and evaluated according to the prescriptions
introduced in Sect.~\ref{sec:prescriptions}, and discuss some of their
qualitative features.

In Fig.~\ref{fig:diag_covmats} we show the diagonal elements of 
the experimental and theory covariance matrices, or more specifically 
the experimental uncertainty normalised to the data, $(C_{ii})^{1/2}/D_i$, and 
the MHOU normalised to the data, $(S_{ii})^{1/2}/D_i$, for $i=1,\ldots,N_{rm dat}$, where $D_i$ is the $i$-th datapoint. 
The datapoints are grouped by process and, within a 
process by experiment, following 
Table~\ref{tab:datasets_process_categorisation}. The theory covariance matrix $S_{ij}$ is computed using the 9-point prescription (the one with the largest number of independent variations; recall
Sect.~\ref{sec:prescriptions}). Broadly speaking, the estimated NLO MHOU is roughly comparable to experimental uncertainties, as expected. 
However for some datapoints the 
experimental uncertainty is dominant (and thus the theory uncertainty
will have only a small effect), while for others the MHOU is
dominant. These latter datapoints will have relatively little weight
in a PDF fit with MHOU included, since the large theory uncertainty
makes them less useful for the extraction of PDFs. Some datasets have
datapoints in both these categories: the HERA NC DIS are particularly
striking, since at high $Q^2$ (where statistics are low) the dominant
uncertainty is experimental, while at low $Q^2$ (and thus small $x$,
where perturbation theory is less reliable) the dominant uncertainty
is due to MHO.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=1.0\linewidth]{mhous/plots/9pt_diagonal_elements.pdf}
    \caption{\small Comparison of the diagonal experimental uncertainties 
    (blue) and the diagonal theoretical uncertainties  
      (red), each normalised to the data, with the experimental uncertainties 
          evaluated using the 9-point
      prescription.
      %
      All entries are normalized to the central experimental value.
      %
  The data are grouped by process and, within a process, by experiment, following
  Table~\ref{tab:datasets_process_categorisation} 
        \label{fig:diag_covmats} }
  \end{center}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=0.49\linewidth]{mhous/plots/exp_covmat.pdf}
    \includegraphics[width=0.49\linewidth]{mhous/plots/th_covmat_9pt.pdf}
    \caption{\small Comparison of the  experimental $C_{ij}$ (left)
      and the theoretical  $S_{ij}$  
      (right) covariance matrices, the latter evaluated using the 9-point
      prescription.
      %
      All entries are normalized to the central  experimental value.
      %
  The data are grouped by process and, within a process, by experiment, following
  Table~\ref{tab:datasets_process_categorisation} 
        \label{fig:covmats} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In Fig.~\ref{fig:covmats} we compare the 
complete experimental covariance matrix $C_{ij}$ to the theory covariance
matrix $S_{ij}$, again computed using the 9-point prescription. Both covariance matrices are displayed
as heat maps, with each entry expressed as a fraction with respect to the
corresponding experimental central value; i.e. $C_{ij}/D_iD_j$ and
$S_{ij}/D_iD_j$. It is clear from Fig.~\ref{fig:covmats} that
the theory covariance matrix has, as expected, a 
richer structure of correlations than
its experimental counterpart: for example data from the same
process (such as DIS) are correlated even when the corresponding
experimental measurements are completely uncorrelated (such as HERA and
fixed target). Furthermore, correlation of the factorization scale variation 
between disparate processes, such as DIS processes and hadronic processes, 
results in nonzero entries in the theory covariance matrix even  
in these regions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htb!]
  \begin{center}
    \includegraphics[width=0.49\linewidth]{mhous/plots/exp_corrmat.pdf}
    \includegraphics[width=0.49\linewidth]{mhous/plots/expth_corrmat_5pt.pdf}
\vskip-0.5cm
    \includegraphics[width=0.49\linewidth]{mhous/plots/expth_corrmat_5barpt.pdf}
    \includegraphics[width=0.49\linewidth]{mhous/plots/expth_corrmat_9pt.pdf}
\vskip-0.5cm
\includegraphics[width=0.49\linewidth]{mhous/plots/expth_corrmat_3pt.pdf}
    \includegraphics[width=0.49\linewidth]{mhous/plots/expth_corrmat_7pt.pdf}
    \caption{\small Comparison of the experimental correlation matrix
      Eq.~(\ref{eq:expcorrmat}) (top left) and the
      the combined experimental and theoretical correlation matrices
      Eq.~(\ref{eq:expthcorrmat}) computed using the prescriptions described in Sect.~\ref{sec:prescriptions}: the symmetric prescriptions (5-pt top right, $\overline{5}$-pt centre left, 9-pt centre right), and asymmetric prescriptions (3-pt bottom left, 7-pt bottom right). The data are grouped by process and within a process by experiment, as in Fig.~\ref{fig:covmats}.
  \label{fig:corrmats} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The precise structure of these theory-induced correlations depends
on the 
choice of prescription adopted.
%
To illustrate this, 
Fig.~\ref{fig:corrmats} compares the experimental correlation matrix, given by
\be
\label{eq:expcorrmat}
\rho^{(C)}_{ij} = \frac{C_{ij}}{  \sqrt{C_{ii}}\sqrt{C_{jj}} } \, ,
\ee
with the corresponding combined experimental and theoretical correlation matrices, defined by
\be
\label{eq:expthcorrmat}
\rho^{(C+S)}_{ij} = \frac{( C+S)_{ij} }{ \sqrt{(C+S)_{ii}} \sqrt{(C+S)_{jj}}  } \, ,
\ee
for all the prescriptions defined in Sect.~\ref{sec:prescriptions}.
%
Specifically, from top left to bottom
right we have the experimental correlations $\rho^{(C)}$ followed by $\rho^{(C+S)}$ for the symmetric 5, $\bar{5}$, 9 point prescriptions, and the asymmetric 3 and 7 point prescriptions.
%
As in Fig.~\ref{fig:covmats},
the cross-sections are grouped by process type and, within that, by experiment.
%

Some qualitative features of the theory-induced correlations are apparent.
There are clearly large positive correlations within individual
experiments along the diagonal blocks, this being particularly evident for 
DIS NC and DY data, which have large numbers of points which are 
relatively close kinematically.
%
Off the diagonal, but still within the same process, there are 
large correlations between experiments for the DY, jets and top data points, and
large anticorrelations for the DIS NC data points (these mostly between fixed 
target and HERA). Correlations and
anticorrelations between different processes are also often present but are
somewhat weaker: for example the DY data points (from LHC) are quite 
correlated with the HERA NC DIS data points, but anticorrelated with 
fixed target NC DIS data points.  

When comparing different prescriptions, it is clear that the
3-point prescription leads to especially small correlations
between processes, which is expected because with this prescription the
factorization scale and renormalization scale variations are uncorrelated between processes. The correlations between processes are also weaker in
7-point than in 5-point, due to the fact that (as discussed in
Sect.~\ref{sec:asympres}) the correlated variation of the
factorization scale is combined with the uncorrelated variations of
the scale of the process for the pair of processes involved. It is worth
noting, however, that the pattern of correlations is similar 
for all the symmetric prescriptions.

In order to decide which prescriptions are best, and
more generally whether or not they produce a reliable estimate
of MHOUs, we must proceed to their validation.


\subsection{Construction of validation tests}
\label{sec:validconstruction}

We wish to construct a validation test for the NLO theory covariance
matrix, by comparing it to the known NNLO theoretical result. We do so by
viewing the set of experimental data as a vector with components
$D_i$, where $i=1, \ldots, N_{\rm dat}$. The vector lives in an
$N_{\rm dat}$-dimensional ``data" space D, on which the theory covariance matrix, $S_{ij}$ acts as a linear operator. $S_{ij}$ is symmetric and positive semi-definite, meaning that all of its non-zero eigenvalues are positive.
%
In a PDF fit, $S_{ij}$ always enters as an additive contribution to the experimental covariance matrix $C_{ij}$, and thus 
their sum is always invertible, owing to the non-zero statistical uncertainties on the data, which bound the eigenvalues from below.
 
$S_{ij}$ defines ellipsoids $E$ corresponding to a given confidence level 
in the data space, centered on the NLO theoretical 
prediction, $T^{\rm NLO}_i\equiv T^{\rm NLO}_i(0,0)$ evaluated using the central scale
choice.
%
In the context of MHOUs, we can take $T^{\rm NLO}_i$ to be the predictions
at NLO, with the one-sigma ellipsoid $E_{1\sigma}$
estimating a 68\% confidence level for the MHO correction.

We can validate whether $S_{ij}$
correctly predicts both the size and the correlation pattern of the
MHO terms by testing the extent to which the shift vector $\delta_i \sim T^{\rm NNLO}_i-T^{\rm NLO}_i$, i.e. the difference between the NNLO and NLO predictions 
for $T_i$, falls within a given ellipsoid $E$.
Note that the dimensionality of the subspace spanned by
the ellipsoid $E$ is much smaller than that of the data space $D$: in a 
global fit the data space has dimension
$\mathcal{O}(3000)$ (Table~\ref{tab:datasets_process_categorisation}), while 
even the most complex prescriptions in
Sect.~\ref{sec:prescriptions} have at $\mathcal{O}(30)$ independent
variations, not all of which correspond to independent eigenvectors, as
we will see shortly. So 
$E$ actually lives in a subspace $S$ of dimension $N_{\rm sub}$ of
the full space  $D$: $E \in S \in D$. For a single process we expect
$N_{\rm sub}$ to be of order a dozen or so at most. 
In fact, even for a single process
(see Table~\ref{tab:datasets_process_categorisation}) we always 
have $N_{\rm sub} \ll N_{\rm dat}$.
Hence, a nontrivial validation of the theory covariance matrix is if the component of the shift vector $\delta_i$ lying outside $E$ is small, i.e. if the angle
between $\delta_i$ and the projection of $\delta_i$ onto $S$ is small. 

Furthermore we expect the component of $\delta_i$ along each axis of the
ellipsoid $E$ to be of the same order as the typical one-sigma variation.
The physical interpretation of such a successful validation is that
the eigenvectors of $S_{ij}$ correctly estimate
the independent directions of uncertainty in theory space, with the
size of the shift estimated by the corresponding eigenvalue. The null
subspace of $E$, i.e. the directions of vanishing eigenvalues, would
then correspond to directions in $D$ for which the theory uncertainty
is so small that it cannot  be reliably estimated and so can be
safely neglected. These are highly nontrivial tests, given the huge 
discrepancy between the dimensionality of the space $D$, and the 
dimensionality of $S$.

Let us now see how this works in detail. First, we
need to identify
the spaces $E$ and $S$.
%
To do this, we normalize the NLO theory covariance matrix $S_{ij}$ to
the central NLO theory prediction $T_i$, so that all its elements 
are dimensionless, allowing a meaningful comparison: we define
\begin{equation}
\widehat{S}_{ij} = S_{ij}/(T^{\rm NLO}_iT^{\rm NLO}_j)\, .\label{eq:Snorm}
\end{equation}
Likewise, we define a normalized shift vector with components 
\begin{equation}
{\delta}_i = (T^{\rm NNLO}_i-T^{\rm NLO}_i)/T^{\rm NLO}_i \, .\label{eq:normshift}
\end{equation}
The NNLO prediction $T^{\rm NNLO}_i$ is computed using NNLO matrix elements 
and parton evolution, but with the same NLO PDF set used in the computation of 
$T^{\rm NLO}_i$ and $S_{ij}$. In this way the shift $\delta_i$ only takes 
account of the perturbative effects due to NNLO corrections, which are estimated by $S_{ij}$, and not the additional effect of refitting.

%
We then diagonalize $\widehat{S}_{ij}$, to give
eigenvectors, $e_i^\alpha$ (chosen to be orthonormal, i.e. $\sum_i
e_i^\alpha e_i^\beta = \delta^{\alpha\beta}$), with corresponding
non-zero eigenvalues, $\lambda^\alpha=(s^\alpha)^2$; $\alpha = 1,
\ldots, N_{\rm sub}$. All these eigenvalues are real and positive, see
Eq.~(\ref{P.2pos}). The eigenvectors span the subspace $S$.
%
There are also  $N_{\rm dat}-N_{\rm sub}$ zero eigenvalues. These are
degenerate, and their eigenvectors span the space $D/S$. Because of
the zero eigenvalues, the diagonalization of $\widehat{S}_{ij}$ is in
practice rather difficult: the procedure we use to identify the
subspace $S$ and its dimensionality $N_{\rm sub}$, and then
diagonalize the projection of $\widehat{S}_{ij}$ into $S$,  is 
described in some detail in Appendix~\ref{sec:diagonalization}.  

Next we project the shift vector $\delta_i$ onto the eigenvectors,
\begin{equation}\label{eq:deltaproj}
\delta^\alpha = \sum_{i=1}^{N_{\rm dat}} \delta_i e_i^\alpha \, .
\end{equation} 
These projections $\delta^\alpha$ should be of the same order as the size 
of the ellipse in this direction, i.e. the $s^\alpha$: more specifically in an ideal world 68\% of the $\delta^\alpha/s^\alpha$ would be less than one.
%
This is all the meaningful statistical information that is contained
in $\widehat{S}_{ij}$.

Finally, we can now resolve the shift vector $\delta_i$ into its component 
lying within $S$
\begin{equation}\label{eq:deltaS}
\delta_i^{S} = \sum_{\alpha=1,\ldots, N_{\rm sub}} \delta^\alpha e_i^\alpha, 
\end{equation}
and the complementary component within the remaining space $D/S$,
$\delta_i^{\rm miss} = \delta_i-\delta^S_i$.
%
For a successful test, we expect most of $\delta$ to lie within $S$,
so $|\delta_i^{\rm miss}|\ll |\delta_i|$, or equivalently
$|\delta_i^{S}|\approx |\delta_i|$.
%
By construction $\delta_i^S$ and $\delta_i^{\rm miss}$ are orthogonal
(since the subspaces $S$ and $D/S$ are orthogonal spaces), 
thus the three vectors $\delta_i^S$, $\delta_i^{\rm miss}$ and $\delta_i$ 
form a right-angled triangle, with $\delta_i$ being its hypotenuse.  The  
geometrical relation between the shift vector $\delta_i$, and
the component of the shift vector which lies in the subspace
$S$, $\delta^S_i$ is illustrated in Fig.~\ref{fig:subspace_diagram}.

With these definitions, the theory covariance matrix $S_{ij}$
provide a reasonable estimate of the MHOU if the angle
\begin{equation}
\theta = \arccos  \lp \frac{|\delta^S_i|}{|\delta_i|} \rp = \arcsin  \lp \frac{|\delta^{\rm miss}_i|}{|\delta_i|}\rp \, 
\label{eq:theta}
\end{equation}
between the shift $\delta_i$ and its component in the subspace
$S$, $\delta_i^S$ is reasonably small.
As mentioned above, for a global PDF fit
the typical situation that one encounters is that
$N_{\rm dat}\gg N_{\rm sub}$ (in the present case $N_{\rm dat}\sim\mathcal{O}(3000)$, while $N_{\rm sub}\sim\mathcal{O}(30)$).
So this validation test is highly nontrivial, since finding the
relatively small subspace $S$ in the huge space $D$ is rather hard:
for a random symmetric matrix $S_{ij}$, components of $\delta_i$ in
$D/S$ will generally be as large as those in $S$, and thus
$|\delta_i^{S}|\ll |\delta_i|$, and $\theta$ will be very close to a
right angle.  
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale=0.27]{mhous/plots/subspace_diag.png}
    \caption{\small Schematic representation of the geometric relation
      between the shift vector $\delta\in D$ (here drawn as a three dimensional space), and
      the component $\delta^S$ of the shift vector which lies in the 
subspace $S$ (here drawn as a two dimensional space, containing the ellipse E defined by the theory covariance matrix). The angle $\theta$ between $\delta$ and $\delta^S$ is also shown: the dotted line shows the other side of the triangle, $\delta^{\rm miss}\in D/S$.
    \label{fig:subspace_diagram} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Results of validation tests}
\label{sec:validresults}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=14cm, height=4.4cm]{mhous/plots/shift_diag_cov_comparison_5pt_global.pdf}
    \includegraphics[width=14cm, height=4.4cm]{mhous/plots/shift_diag_cov_comparison_5barpt_global.pdf}
    \includegraphics[width=14cm, height=4.4cm]{mhous/plots/shift_diag_cov_comparison_9pt_global.pdf}
    \caption{\small The diagonal uncertainties  $\sigma_i$ (red)
      symmetrized about zero,
      compared to the shift $\delta_i$ for each
      datapoint (black), for the symmetric prescriptions:  5-point (top),
      $\overline{5}$-point (middle), and 9-point (bottom). All values
      are shown as percentage of the central theory prediction.}
    \label{fig:diag_shift_validation_symmetric}
  \end{center}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\begin{figure}[htb!]
  \begin{center}
    \includegraphics[width=14cm, height=4.4cm]{mhous/plots/shift_diag_cov_comparison_3pt_global.pdf}
    \includegraphics[width=14cm, height=4.4cm]{mhous/plots/shift_diag_cov_comparison_7pt_global.pdf}
    \caption{\small Same as Fig.~\ref{fig:diag_shift_validation_symmetric} but for
    the asymmetric prescriptions: 3-point (top) and 7-point (bottom).}
    \label{fig:diag_shift_validation_asymmetric}
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


We now explicitly perform the validation tests discussed in
Sect.~\ref{sec:validconstruction}, with the NLO theory covariance matrices 
$\widehat{S}_{ij}$ (normalised to NLO theory, as in
Eq.~(\ref{eq:Snorm})) constructed from scale variations for all data
points in Table~\ref{tab:datasets_process_categorisation}, and for
each prescription of
Sect.~\ref{sec:prescriptions}. These are then validated using the shift vector $\delta_i$ constructed as the difference of NNLO and NLO theory, normalised to the latter, as in Eq.~(\ref{eq:normshift}).

A very first comparison can be done at the level of diagonal elements $\sigma_i$, where $\widehat{S}_{ii} = (\sigma_i)^2$, 
by comparing them directly to the normalised shifts
${\delta}_i$ Eq.~(\ref{eq:normshift}).
This already tells us
whether the overall size of the scale variation 
is of the right order of magnitude: one expects
the shifts $\delta_i$ and the uncertainties $\sigma_i$ to be of roughly the
same order.


These comparisons are shown in
Figs.~\ref{fig:diag_shift_validation_symmetric}-\ref{fig:diag_shift_validation_asymmetric}.
In each plot the data points are presented sequentially on the horizontal axis, organised by process as in Table~\ref{tab:datasets_process_categorisation}.
The shape of the estimated MHOU imitates the 
shape of the true shift rather faithfully, for each of the five
processes, and for each prescription. This shows that the theory
covariance matrix gives a qualitatively reliable estiamte of the true
MHOU, in the sense that the estimate is small when the MHOU is small,
large when it is large, and moreover correctly incorporates the
correlations in the HOU between nearby kinematic regions, responsible
for the shape. There is little discernible difference between all the
various point prescriptions, except is the overall size of the
estimates: for example comparing the symmetric prescriptions, we 
see that 5-point is the least conservative and $\overline{5}$-point is the most conservative, whilst 9-point lies somewhere between the two. This is particularly noticeable in the DY data. 

It is clear from these plots that the overall size of the estimated uncertainties, given by varying renormalization and factorization scales by a factor of two in either direction (i.e. as in 
Eq.~(\ref{eq:rangew}) with $w = \ln 4$) is roughly correct: if the range were significantly smaller, some of the uncertainties would have been underestimated, whereas if it were larger all uncertainties would have been overestimated. This said, for some data points the MHOU at NLO is clearly overesimated by scale variation: this is particularly true of the small-$x$ NC DIS data from HERA in the centre of the plot.
  
Overall, these plots demonstrate that since there are only small differences in the diagonal elements of each prescription, it is in the detailed correlations between data points where the differences in
performance between the prescriptions lies. To expose this, we need to diagonalise the theory covariance matrix (using the procedure in Appendix~\ref{sec:diagonalization}), so that we can see in detail which components of the shift vector are correctly estimated, and which are missed, as explained in Sect.~\ref{sec:validconstruction}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht!]
	\centering
	\input{mhous/tables/global_efficiencies.tex}
        \vspace{5mm}
	\caption{\small The angle $\theta$  Eq.~(\ref{eq:theta}) between this
          shift and its component $\delta_i^S$ lying within the
          subspace $S$ (see Fig.~\ref{fig:subspace_diagram})
          spanned by the theory covariance matrix for  different
          prescriptions. The dimension of the subspace $S$ in each case
          is also given.}
	\label{tab:global_efficiencies}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[ht!]
	\centering
	\small
	\input{mhous/tables/process_efficiencies.tex}
        \vspace{3mm}
	\caption{Same as Table~\ref{tab:global_efficiencies}
          for each process of Table~\ref{tab:datasets_process_categorisation}. The number of data points in each process is given directly below the name of the process.}
	\label{tab:process_efficiencies}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

As discussed in Sect.~\ref{sec:validconstruction}, once we have the eigenvectors corresponding to the nonzero eigenvalues of the theory covariance matrix, 
the first validation test consists of checking how much of the shift vector 
$\delta_i$ lies within the space spanned by these eigenvectors, $S$, and has thus been included in the estimation of MHOU provided by the theory 
covariance matrix.
%
The results of this test for the global dataset, described in Sect.~\ref{sec:inputdata}, are shown in  
Table~\ref{tab:global_efficiencies}: for each prescription we
give the dimension $N_{\rm sub}$
of $S$, i.e. the number of linearly independent eigenvectors
$e_i^\alpha$ of $S_{ij}$, and then the value of the angle $\theta$,
defined in Eq.~(\ref{eq:theta}),
between the shift $\delta_i$  and its component $\delta^S_i$, defined in Eq.~(\ref{eq:deltaS}), lying within 
the subspace $S$ spanned by $e_i^\alpha$. 
%
We note that all the angles are reasonably small, despite
the fact that $N_{\rm sub}$ is so much smaller that the dimension
$2819$ of the data space. 

The 9-point prescription performs best, with an angle of $\theta=26^{\rm o}$ between the shift $\delta_i$ and its projection $\delta_i^S$ in the subspace $S$: clearly the more complicated pattern of scale variations (compared to the other two symmetric prescriptions) improves the estimation of the MHOU.
%
The 3-point prescription performs worst, suggesting that lack of
correlation in the factorization scale between processes in this prescription 
means that much of the correlation in the MHOU due to universal PDF evolution has been missed.
%
The 7-point prescription is however only a little worse than 9-point, presumably due to the dilution of the correlation in factorization scale variation which is a feature of this prescription. Note that since these results for $\theta$ are geometrical, they are largely independent of the range of the scale variation Eq.~(\ref{eq:rangew}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht!]
  \begin{center}
    \includegraphics[width=0.99\textwidth]{mhous/plots/deltamiss_plot.pdf}
    \caption{The NNLO-NLO shift $\delta_i$ (black) compared to its 
component $\delta_{\rm miss}$ (blue) which lies outside the subspace $S$, computed using the 9-point prescription.}
    \label{fig:deltamiss}
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht!]
  \begin{center}
    \includegraphics[scale=0.6]{mhous/plots/projector_eigenvalue_ratio_5pt_global.pdf}
    \includegraphics[scale=0.6]{mhous/plots/projector_eigenvalue_ratio_5barpt_global.pdf}
    \includegraphics[scale=0.6]{mhous/plots/projector_eigenvalue_ratio_9pt_global.pdf}
    \caption{\small The projection $\delta^\alpha$ Eq.~(\ref{eq:deltaproj}) of the normalized shift vector
      $\delta_i$ Eq.~(\ref{eq:normshift}) along each eigenvector $e^\alpha_i$ of the normalized theory covariance
      matrix Eq.~(\ref{eq:Snorm}), compared to the corresponding eigenvalue 
    $s^\alpha$, ordered
      by the size of the projections (from largest to
      smallest). In each case results are shown as absolute (upper) and
      as ratios $\delta^\alpha/s^\alpha$ (lower), the horizontal line indicating when this ratio is one.  The length of the 
        component of 
       $\delta_i$ that is not captured at all by the theory covariance 
    matrix, $|\delta^{\rm miss}_i|$ is also shown (blue star).
      Results are shown for the symmetric prescriptions: 5-point (top left),
    $\overline{5}$-point (top right), and 9-point (bottom).}
    \label{fig:evals_all_prescriptions_symmetric}
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



It is interesting to ask whether all processes are equally well
described, and whether there are significant differences in
correlations between processes or within a process. 
To this purpose, in Table~\ref{tab:process_efficiencies} we list the angle 
$\theta$ computed for each individual process using the various prescriptions.
Three conclusions emerge from inspection of this table. First, when each process is taken individually, the results seen in Table~\ref{tab:global_efficiencies} for the relative merits of each prescription are replicated process by process: again 3-point is worst, and 9-point is best.
%
Secondly, processes with large numbers of data points are much harder to describe than those with only a few data points (i.e. $\theta$ is smallest for smaller datasets): this is hardly surprising, since the larger datasets cover a wider kinematic range and thus have more structure to predict. Finally, the quality of the description of the global
dataset for each prescription is in each case dominated by the process (DIS NC) which is described worst, however the global dataset is actually described a little better (for each prescription) than the dataset for this process, particularly for 9-point, less so for 3-point.
%
This suggests that correlations across 
processes are actually described reasonably well, and are anyway less critical than correlations within processes.

We next look in more detail at the part of $\delta_i$ which falls outside the subspace $S$, $\delta^{\rm miss}_i = \delta_i-\delta^S_i$. This is shown for the 9-point prescription in Fig.~\ref{fig:deltamiss}. While this is generally uniformly small, of order a few percent, across the full range of processes, it also has nonzero components in all datasets, and all processes. This may suggest that much of it is due to poor estimation of the MHOU in PDF evolution, rather than poor estimation of MHOU in hard cross-sections which can vary substantially between different processes (and indeed different kinematics). A more sophisticated treatment of the factorization scale variation may help improve this.

Having established that most of the NNLO-NLO shift $\delta_i$ lies within $S$, we now proceed to examine what fraction of $\delta^S_i$ lies with the error ellipse $E$ specified by the theory covariance matrix. To that end, the 
eigenvalues $\lambda^\alpha = (s^\alpha)^2$ of the theory covariance 
matrix of the global dataset are shown in
Fig.~\ref{fig:evals_all_prescriptions_symmetric} for symmetric
prescriptions, and in
Fig.~\ref{fig:evals_all_prescriptions_asymmetric} for the asymmetric
ones: these define the length of the semi-axes of $E$. Since there are five distinct processes, there are $8$, $12$ and $28$ positive eigenvalues for the symmetric $5$-point, $\overline{5}$-point and $9$-point prescriptions respectively, and $6$, $14$ positive eigenvalues for the asymmetric $3$-point and $7$-point prescriptions, as explained in Appendix~\ref{sec:diagonalization}. Also shown are the projections $\delta^\alpha$ of the 
normalized shift vector $\delta$ Eq.~(\ref{eq:normshift}) along each 
corresponding eigenvector $e^\alpha_i$, Eq.~(\ref{eq:deltaproj}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht!]
  \begin{center}
    \includegraphics[scale=0.6]{mhous/plots/projector_eigenvalue_ratio_3pt_global.pdf}
    \includegraphics[scale=0.6]{mhous/plots/projector_eigenvalue_ratio_7pt_global.pdf}
    \caption{\small Same as Fig.~\ref{fig:evals_all_prescriptions_symmetric} but for
    the asymmetric prescriptions: 3-point (left) and 7-point (right).}
    \label{fig:evals_all_prescriptions_asymmetric}
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht!]
  \begin{center}
    \includegraphics[width=0.95\textwidth]{mhous/plots/eigenvector_plot_10.pdf}\\
    \caption{\small The components  $e^\alpha_i$ (green) of the eigenvectors, corresponding
      to the five largest eigenvalues for the 9-point theory covariance matrix, shown in the same format as Fig.~\ref{fig:diag_shift_validation_symmetric}. The NNLO-NLO shift, $\delta_i$ (black), is shown for comparison.
    \label{fig:evecs1} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Inspection of these plots confirms that all the prescriptions seem to 
perform reasonably well, with the
eigenvalues of comparable size to the shifts, the size of the eigenvalues generally falling as the projected shifts get smaller. As expected, the 3-point prescription clearly overestimates uncertainties, since $\delta^\alpha < s^\alpha$ for all the eigenvalues. The same is true, but to a lesser extent, for both 5-point and $\overline{5}$-point. For the more complicated 7-point and 9-point 
prescriptions the largest projections (corresponding to the first seven or eight eigenvalues) are estimated rather well, though still perhaps a little conservatively, but for the smaller projections the scatter increases significantly, with some projected shifts hardly predicted at all. This is perhaps not surprising: when varying just six independent scales, we can only expect to obtain only a limited amount of information on the MHO terms. However the correct estimation of the largest projected shifts shows that the theory covariance matrix is giving a reasonable estimation of the MHOU, especially when implemented through the more complicated prescriptions.

On each of these plots, we also show the length of the component 
$\delta^{\rm miss}_i$ that is orthogonal to $S$, and thus completely outside $E$. For the symmetric prescriptions, $|\delta^{\rm miss}_i|$ is always less than the largest component of $\delta$ in $S$, while for the asymmetric prescriptions it is greater, very significantly so for the 3-point prescription. This is another indication that the symmetric prescriptions give a better account of the correlations in theoretical uncertainties. 

A more detailed understanding of the physical meaning of each
eigenvector can be acquired by inspecting its components $e_i^\alpha$ in the data space. These are shown in Fig.~\ref{fig:evecs1} for the
eigenvectors corresponding to the five largest eigenvalues in the
9-point prescription: the shift vector $\delta_i$ is also shown for comparison.
%
It is clear that there is a close correspondence between eigenvectors
and MHO contributions to individual processes. For instance the first
eigenvector contributes mostly to DIS NC, the second to both DIS NC and DIS CC, the third to DY, the fourth mainly to DIS CC, and the fifth mainly to JETS. Clearly the ordering of these larger eigenvalues is related to the number of data points for the respective processes: the more datapoints, the larger the eigenvalue of the (correlated) uncertainty estimate. Even relatively small eigenvalues can give an important contribution, though to processes with fewer datapoints: for example the ninth eigenvector (not shown) clearly dominates TOP.

In summary, from these validation tests it is apparent that the 9-point
prescription gives a reasonable estimate of most of the MHOU, both for individual processes and for the global dataset, with the 7-point being just slightly
worse. Based on this, we will therefore adopt 9-point as a default prescription
for the theory covariance matrix in the PDF determination to be discussed in 
the next section.

\section{PDFs with missing higher order uncertainties}
\label{sec:fitstherr}

We can now present the main results of this work: the
first determination of the parton distributions of the proton
which systematically accounts for the MHOUs affecting the theory
calculations of the input processes for the fit.
%
First  we present the results for PDFs obtained by 
fitting only DIS data. This provides us with an initial test case, which we
will study both at NLO and NNLO by comparing PDFs obtained including
the combined experimental and theoretical covariance matrix to
the corresponding baseline fit in which only experimental
uncertainties are included.

We then turn to the  global PDF determination,
which offers a nontrivial validation of our methodology,
specifically by comparing NLO PDFs, with and without MHOUs,
to NNLO PDFs. 
%
For global fits, we also study the stability of the results to
changes in the prescription used for the computation of the theory
covariance matrix: specifically, we compare
PDFs obtained with the  9-point
prescription  (which is our default)
to those based on the  7- and 3-point ones.
%
We  also study PDFs determined by only partially including the
theory covariance matrix, either only in the data generation or only in the
fitting. As discussed in the introduction, this provides us with a way of
disentangling the impact of the theory covariance matrix on the
central value of the PDFs or on the PDF uncertainty.

As discussed in Sect.~\ref{sec:thcovmat}, the theory uncertainties are included by simply replacing the experimental covariance
matrix $C_{ij}$ with the sum $(C+S)_{ij}$ of the experimental and theory
covariance matrices in the expression for the likelihood of the true
value given the data.
%
The NNPDF methodology, as used specifically in
the determination of the most recent NNPDF3.1 PDF
set~\cite{Ball:2017nwa}, is otherwise unchanged.
%
Within this methodology, the covariance matrix is used to generate
$ N_{\rm rep}$ pseudodata replicas $D^{(k)}_i$ for each datapoint $i$, with
$k=1,\dots, N_{\rm rep}$, whose distribution must reproduce the covariance
of any two data points. This means that with theory uncertainties
included,
\be
\label{eq:dgen}
\lim_{N_{\rm rep}\to\infty}\frac{1}{N_{\rm rep}(N_{\rm rep}-1)}\sum_{k=1}^{N_{\rm rep}} \left(D_i^{(k)}-\langle
  D_i\rangle \right)
  \left(D_j^{(k)}-\langle D_j\rangle \right)= C_{ij}+S_{ij},
  \ee
  with $\langle D_i\rangle= \frac{1}{N_{\rm rep}}\sum_{k=1}^{N_{\rm rep}}  D_i^{(k)}$ 
denoting the average over Monte Carlo replicas.

A PDF replica is then fitted to each pseudodata replica $D_i^{(k)}$ by
minimizing a figure of merit, which in the presence of theory
uncertainties becomes
\be
\label{eq:chi2_v3}
\chi^{2}=\frac{1}{N_{\rm dat}}\sum_{i,j=1}^{N_{\rm dat}}\lp  D_i-T_i^{(0)}\rp
\lp C+S \rp^{-1}_{ij} \lp D_j-T_j^{(0)}\rp ,
\ee
where $T_i\equiv T_i (0,0)$ is the theory prediction evaluated
with the central scale choice $\kappa_f=\kappa_r=0$, and with the 
theory covariance matrix $S_{ij}$ computed using one of the prescriptions 
presented in Sect.~\ref{sec:prescriptions}. 

It is thus clear that the inclusion of a theory-induced contribution
in the covariance matrix affects only two steps of the procedure: the
pseudodata generation, and the minimization. Everything else is
unchanged, and is identical to the default NNPDF methodology.
%
Note
that in particular the experimental covariance matrix $C$ used in 
the fitting is determined, as in NNPDF3.1 and previous NNPDF releases using the
so-called $t_0$ method for the treatment of multiplicative
uncertainties, in order to 
avoid d'Agostini bias (see Refs.~\cite{Ball:2009qv,Ball:2012wy} for a
detailed discussion).
%
As in previous NNPDF releases, minimization is thus
performed using the $t_0$ definition of the $\chi^2$, but all $\chi^2$
values shown are computed using the covariance matrix as published by
the respective experiments.

All the PDF sets which have been produced and which will be discussed in this
section are listed in Table~\ref{tab:thcovmatFits}.
%
For each of the fits, 
we indicate its label, the input dataset,
   the  perturbative order and the covariance matrix used.
   %
   For the fits that include a theory covariance matrix, we also indicate the prescription
   with which it has been constructed. 
   In the remainder of this section we discuss the main features
   of these PDF sets.
  
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{mhous/tables/list-fits-thcovmat.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{DIS-only PDFs}

We first discuss PDF sets based on DIS data only.
Fit quality indicators are collected in
Table~\ref{table:chi2table_covth_dis}. The theory covariance matrix is always
constructed using the 9-point prescription. 
We show the value of 
$\chi^2/N_{\rm dat}$ and the $\phi$ estimator, defined
in Ref.~\cite{Ball:2014uwa}. This estimator is a measure of the size of the
uncertainty on the prediction: for an uncorrelated covariance
matrix, it reduces to  the 
ratio of the uncertainty in the predictions using
the output PDFs to that in the original data, which is then
generalized to the correlated case. Results are shown
for both the total dataset and for the  individual DIS experiments of Table~\ref{tab:datasets_process_categorisation}.
%
Note that the total $\chi^2$ is no longer
just the weighted sum of the individual $\chi^2$s, because it now also includes
correlations between experiments.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{mhous/tables/chi2table_covth_dis.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

It is apparent from Table~\ref{table:chi2table_covth_dis} that in
all cases the $\chi^2$ improves when including the theory covariance
matrix, both for individual experiments and for the total dataset.
Specifically, the $\chi^2$ decreases by about 2-3\% for the NLO and
NNLO fits
when including theory a
covariance matrix $S^{\rm (9pt)}$ 
evaluated with the 9-point prescription.
Furthermore the value of $\phi$ also slightly decreases 
upon inclusion of the theory covariance matrix,
both for the total dataset and experiment by experiment.

The decrease in the $\chi^2$ value when including an extra
contribution to the covariance matrix is to be expected, so this is 
essentially a consistency check. However, if the
$\chi^2$ reduction was simply a consequence of having increased
uncertainties, one would also expect a corresponding increase in
uncertainty in the theory predictions, i.e. an increase in $\phi$.
The fact that both $\chi^2$ and $\phi$ decrease suggests that the
inclusion of MHOUs resolves some tensions in the fit which are present
when only the the experimental covariance matrix is included. It is 
interesting that for DIS data these theoretical tensions are greater 
in the NNLO fit than at NLO.

Next we compare PDFs: in Fig.~\ref{fig:DISonly-NLO-CovMatTH} we compare
the gluon and the  total quark singlet PDF   at $Q=10$ GeV at
NLO and NNLO with and without MHOUs in the covariance matrix, determined 
using the 9-point prescription.
      %
      The NLO results are also compared with the central
      value of the NNLO fit based on the experimental covariance
      matrix only. Note that in these comparison plots the PDF
      uncertainty band is always computed using standard NNPDF
      methodology, i.e., as the standard deviation over the PDF
      replica sample. Therefore, this uncertainty band has a different
      meaning dependent on whether or not the theory covariance matrix is
      included: when it is not included, the band represents
       the conventional
      ``PDF uncertainty'', reflecting the uncertainties from the data
      (and methodology), while when it is included, the band provides the
      combined ``PDF'' and MHO uncertainty.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale=0.39]{mhous/plots/xg-DISonly-NLO-CovMatTH-EXP-vsTH.pdf}
     \includegraphics[scale=0.39]{mhous/plots/xg-DISonly-NNLO-CovMatTH-EXP-vsTH.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsinglet-DISonly-NLO-CovMatTH-EXP-vsTH.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsinglet-DISonly-NNLO-CovMatTH-EXP-vsTH.pdf}
    \caption{\small Comparison of DIS-only PDFs determined 
      with and without MHOUs in the covariance matrix.
      %
      The gluon (top) and quark singlet (bottom) at $Q=10$ GeV
      at NLO (left) and NNLO (right) are shown.
      %
      The theory covariance matrix $S$ has been constructed using
      the 9-point prescription.
      %
      In the NLO plots the central value of the NNLO determined
      without MHOU is also shown. All results are shown as a ratio to
    the central value of the set with theory covariance
    matrix not included. Note that the uncertainty band has
      a different meaning according to whether the theory covariance
      matrix is included or not: if not it is the standard PDF 
      uncertainty coming from data, while if it is included, then it is the total uncertainty including the MHOU.
    \label{fig:DISonly-NLO-CovMatTH} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The comparison shows that for PDFs which are strongly constrained by
data, such as the quark singlet PDF for $x\gsim 10^{-3}$, the
uncertainty does not increase upon inclusion
of the theory covariance matrix, in fact it even decreases. This is consistent with the previous
observation that the uncertainty on the theory predictions themselves decreases somewhat. 
In the case of the gluon PDF, which is only loosely constrained by the
DIS data, the uncertainty increases substantially with
MHOUs, particularly in the NNLO fit. This is of course consistent with the fact
that, in the absence of stringent experimental constraints, an extra
contribution to the covariance matrix will lead to increased
uncertainties in the best fit. So this indirectly supports the
conclusion that in the regions where data are abundant the decrease in
uncertainty is due to the fact that the theory contribution to the
covariance matrix helps to resolve tensions in the fit.

Comparison to the NNLO best fit shows that its value is clearly
compatible with the total uncertainty band.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5

\subsection{Global PDFs}
\label{sec:globmhou}

We now discuss PDFs determined from the global dataset presented in
Sect.~\ref{sec:inputdata}. Only NLO PDFs will be discussed here, with 
global NNLO PDFs left for future work. %
The $\chi^2$ values and $\phi$ values are shown in
Tables~\ref{table:chi2table_covth_global_nlo}
and~\ref{table:phitable_covth_global_nlo} 
respectively, both for the total dataset and for the  individual
processes of Table~\ref{tab:datasets_process_categorisation}.
In comparison to the DIS-only case of
Table~\ref{table:chi2table_covth_dis} we now also show results
obtained using the 7-point and 3-point prescriptions, and also for the
default 9-point prescription but where the results were obtained by 
including the theory
covariance matrix either only in the $\chi^2$ definition Eq.~(\ref{eq:chi2_v3}), or only in the data generation Eq.~(\ref{eq:dgen}), in order to understand better the two distinct effects.

As in the case of the DIS-only fit, on adding the MHOU 
we find a reduction of $\chi^2$
both for the global fit and for individual datasets, while the value of
$\phi$ is roughly unchanged. We again conclude that the
inclusion of the theory covariance matrix improves fit quality by
removing some tension which would be otherwise present between
datasets. Indeed the total $\chi^2$ for the NLO fit with MHOU 
(in 9-point prescription) is now comparable to that of the NNLO fit.
Comparing different prescriptions, results are  reasonably
stable, even when comparing to the 3-point prescription which, as
discussed in Sects.~\ref{sec:asympres}-\ref{sec:validconstruction},
spans a much smaller subspace of theory variations. However, the
9-point prescription appears to perform best in terms of $\chi^2$
quality with very little difference in $\phi$, in agreement
with the results of Sect.~\ref{sec:validresults}.

We finally turn to fits in which the theory covariance matrix is
included either in the $\chi^2$ 
  definition Eq.~(\ref{eq:chi2_v3}) but not
  in the data generation Eq.~(\ref{eq:dgen}), 
  or in the data generation Eq.~(\ref{eq:dgen}) but not in the $\chi^2$ 
  definition Eq.~(\ref{eq:chi2_v3}).   In the former case, we 
expect the MHOUs to affect mostly the central value (since the relative weighting of different data points is altered during the fitting according to the relative size of their MHOUs), and to a lesser extent the
uncertainties (since the data
replicas only fluctuate according to the experimental uncertainties). 
The results show that indeed including the MHOU in the $\chi^2$
definition alone  leads to a 
$\chi^2$ value which is very close to that found when the MHOU is fully
included, consistent with the expectation that it is the inclusion of
the theory covariance matrix in the $\chi^2$ which mostly drives the best
fit.
On the other hand, the $\phi$ value is somewhat reduced, due
to the relaxation of some of the tensions in the fit, now
uncompensated by the great fluctuation of the replicas.
In the latter case, we expect to obtain increased uncertainties but a worse fit,
since the data replica fluctuations are wider due to the MHOU, and this is 
not accounted for in the $\chi^2$. The results indeed 
show a significant deterioration of fit quality, as expected for an 
inconsistent fit: the $\chi^2$ goes up, and also the $\phi$ value 
goes up, showing the increase in
uncertainty due to the inclusion of MHOU in the sampling, now uncompensated 
by a rebalancing of the datasets through the inclusion of MHOU in the fit.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{mhous/tables/chi2table_covth_global_nlo.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{mhous/tables/chi2table_phi_global.tex}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now move on to discuss the corresponding
results at the PDF level, in analogy with
the comparisons presented for the DIS-only fits
in Fig.~\ref{fig:DISonly-NLO-CovMatTH}. Specifically, in 
Fig.~\ref{fig:Global-NLO-CovMatTH}.
we show the results of the NLO fits based on $C$ and $C+S^{\rm
(9pt)}$, as well as the central value of the NNLO fit based on $C$, 
for the gluon, the total quark singlet,
the anti-down quark, and the total strangeness PDFs.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale=0.39]{mhous/plots/xg-Global-NLO-CovMatTH-EXP-vsTH.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xsinglet-Global-NLO-CovMatTH-EXP-vsTH.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xdbar-Global-NLO-CovMatTH-EXP-vsTH.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsp-Global-NLO-CovMatTH-EXP-vsTH.pdf}
   \caption{\small Same as Fig.~\ref{fig:DISonly-NLO-CovMatTH}
     now for the NNPDF3.1 global fits.
     %
     We show the results of the NLO fits based on $C$ and $C+S^{\rm (9pt)}$ normalized
     to the former, as well as the central value of the NNLO fit based on $C$.
     %
     Results are shown at $Q=10$ GeV for the gluon, the total quark singlet,
     the anti-down quark, and the total strangeness PDFs.
    \label{fig:Global-NLO-CovMatTH} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We find that in the data region the PDF uncertainty is not substantially 
increased by the inclusion of the theory covariance matrix, while central values
can shift significantly, by up to one sigma.
This is consistent with the observation that the $\phi$ values in
Table~\ref{table:phitable_covth_global_nlo} do not increase upon
inclusion of the theory covariance matrix. This provides evidence that
in the data region the inclusion of the theory covariance matrix
resolves tensions which 
are otherwise present in the global dataset. In contrast, in regions where 
PDFs which are only loosely constrained by the data, and in particular in the extrapolation regions, the PDF uncertainty can increase significantly. 

An especially interesting comparison is with respect to the central NNLO
value: not only is this quite compatible with the uncertainty band,
but there is now clear evidence that upon inclusion of the NLO MHOU 
the central best fit moves towards the correct NNLO
answer. This is further evidence that indeed the theory covariance
matrix has resolved tensions due to MHOs.
This improved agreement of the central value of the NLO $C+S^{(\rm 9pt)}$
with the NNLO $C$ fits is  non-trivial: for instance, inclusion of the
theory covariance matrix leads to
a suppression of the gluon at large $x$ and an enhancement of
strangeness, both of which are indeed also observed at NNLO.

Next, in  Fig. \ref{fig:Global-NLO-CovMatTH-prescriptions} we 
compare PDFs obtained using different prescriptions.
The corresponding relative PDF uncertainties are compared
in Fig.~\ref{fig:Global-NLO-CovMatTH-prescriptions-uncertainties}.
In agreement with what we saw for the $\chi^2$ and $\phi$ values in
Tables~\ref{table:chi2table_covth_global_nlo},~\ref{table:phitable_covth_global_nlo}
results are quite stable with respect to the choice of prescription, though in the most extreme case of the  3-point prescription, where factorization scale variations are entirely uncorrelated between different processes, we observe 
somewhat smaller uncertainties, and a central value
which is closer to that when the MHOU is not included.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale=0.39]{mhous/plots/xg-Global-NLO-CovMatTH-prescriptions.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xsinglet-Global-NLO-CovMatTH-prescriptions.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xdbar-Global-NLO-CovMatTH-prescriptions.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsp-Global-NLO-CovMatTH-prescriptions.pdf}
   \caption{\small Same as Fig.~\ref{fig:Global-NLO-CovMatTH} now
     comparing the results of the NNPDF3.1 global fits with the theory covariance matrix
     constructed accordingly to the 3-, 7-, and 9-point prescriptions, normalized
     to the central value of the latter.
    \label{fig:Global-NLO-CovMatTH-prescriptions} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[scale=0.39]{mhous/plots/xg-ERR-Global-NLO-CovMatTH-prescriptions-uncertainties.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xsinglet-ERR-Global-NLO-CovMatTH-prescriptions-uncertainties.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xdbar-ERR-Global-NLO-CovMatTH-prescriptions-uncertainties.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsp-ERR-Global-NLO-CovMatTH-prescriptions-uncertainties.pdf}
   \caption{\small Same as
     Fig.~\ref{fig:Global-NLO-CovMatTH-prescriptions}, now showing
     relative PDF uncertainties, normalized to the central value of the baseline set.
     %
     Note that the $y$-axes ranges are different
     for each PDF combination.
    \label{fig:Global-NLO-CovMatTH-prescriptions-uncertainties} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



Finally, in Fig.~\ref{fig:Global-NLO-CovMatTH-tests} we compare PDFs
obtained including the theory covariance matrix
only in the $\chi^2$ definition Eq.~(\ref{eq:chi2_v3}) but not
in the data generation Eq.~(\ref{eq:dgen}) and conversely.
%
We see that when the theory covariance matrix is included in the
replica generation but not in the $\chi^2$, uncertainties increase
very significantly.
%
This result is in agreement with the observation from
Table~\ref{table:chi2table_covth_global_nlo} that in this case the
fit quality significantly deteriorates, which is because the fit
becomes inconsistent due to the $\chi^2$ not matching the
wider fluctuations in the data.
%
The effect is particularly visible for the
quark distributions.
%
On the other hand, including the theory
covariance matrix only in the $\chi^2$  singles out the effect of
the theory covariance matrix on central values, due to rebalancing of 
datapoints in the fit according to their relative MHOU.
%
Indeed in this case
the central value is very close to that obtained when including the MHOU 
is both data generation and fit. We also see that the change in
uncertainties in the data region is now very small, consistent with
Table~\ref{table:chi2table_covth_global_nlo}.
%
These results confirm our 
expectation that in the full fit, while the MHOU results in a substantial 
increase in the fluctuations of data replicas, this is compensated by 
a relaxation of tensions due to the inclusion of MHOU the fit, with 
the net result that while central values shift, overall uncertainties 
remain relatively unchanged.

\FloatBarrier

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[h]
  \begin{center}
    \includegraphics[scale=0.39]{mhous/plots/xg-Global-NLO-CovMatTH-tests.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xsinglet-Global-NLO-CovMatTH-tests.pdf}
    \includegraphics[scale=0.39]{mhous/plots/xdbar-Global-NLO-CovMatTH-tests.pdf}
   \includegraphics[scale=0.39]{mhous/plots/xsp-Global-NLO-CovMatTH-tests.pdf}
   \caption{\small Same as Fig.~\ref{fig:Global-NLO-CovMatTH}, now comparing
     the results of the baseline $C+S^{(\rm 9pt)}$ fit with those in which
     the theory covariance matrix $S$ is included either in the $\chi^2$
     definition or in the generation of Monte Carlo replicas, but not on both.
    \label{fig:Global-NLO-CovMatTH-tests} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Implications for phenomenology}
\label{sec:pheno}

Whereas a  full assessment of the impact of the inclusion of MHOU in
PDFs will be possible only once we have global NNLO sets with MHOU, 
it is worth performing a first phenomenological
investigation, by computing reference LHC standard candles with the
NLO PDF sets which include MHOUs presented in Sect.~\ref{sec:fitstherr}, 
and comparing to results with the corresponding NLO PDF sets in which 
no MHOU is included.

In this section we will specifically consider
Higgs boson production in gluon-fusion and in vector-boson fusion, 
top quark pair and $Z$ and $W$ electroweak gauge boson
production. Note that the latter processes are among those which have
been used for PDF determination, see
Tab.~\ref{tab:datasets_process_categorisation}. This raises the issue
of possible double counting of uncertainties between the MHOU in the
PDF and in the hard matrix element. This will be addressed in
Sect.~\ref{sec:combmhou} below.

As discussed in Sect.~\ref{sec:fitstherr}, once the MHOU is included
in the covariance matrix, the standard NNPDF methodology can be used,
but with the PDF uncertainties now also including a theory-induced
contribution. Specifically,
PDF uncertainties (which now include the MHOU uncertainty) are
obtained as standard deviations over the replica sample. The total
uncertainty on a physical prediction is then obtained by combining this
uncertainty with that on the hard cross-section for the given
process. The latter is conventionally obtained as the envelope of a 7-point
scale variation, see e.g. Ref.~\cite{deFlorian:2016spz}. Of course, an
alternative possibility is to compute the theory uncertainty on the
hard cross-sections in exactly the same way as we compute it when
performing PDF determination, i.e. using the theory covariance
matrix. In this case, the MHOU on any measurement is found as the
diagonal element of the covariance matrix, evaluated for the given
measurement. Here we will compute the theory uncertainty both using the theory
covariance matrix (with the 9-point prescription,
given in Eq.~\eqref{9S}), and as a 7-point envelope.
The MHOU uncertainty
on the hard cross-section  can then be combined with the total
uncertainty on the PDF (which includes both MHOU and data
uncertainties) in quadrature. A more detailed discussion of
prescriptions for the computation of the total uncertainty on a
physical observable, including explicit formulae,
will be given in Sect.~\ref{sec:combmhou} below.

The current state of the art for precision phenomenology is NNLO, and
thus NNLO PDFs would be needed for accurate predictions. However, as
discussed in Sect.~\ref{sec:fitstherr}, at present only NLO global PDFs with
MHOU are available. In principle, NNLO PDFs from a DIS only fit are
also available. However, also as discussed in
Sect.~\ref{sec:fitstherr}, some of these PDFs (specifically the gluon)
are affected by large uncertainties due to the lack of
experimental constraints. The comparison of PDFs with and without MHOU
for such sets would thus be rather misleading. Therefore, in this
section we will focus on NLO PDFs. It should of course be kept in mind
that NNLO PDFs with MHOU are likely to have smaller uncertainties.

\subsection{Higgs production}
\label{sec:higgs}

We first discuss Higgs production in gluon 
fusion (ggF) and in vector boson fusion (VBF).
%
These two processes are of direct relevance for the characterization
of the Higgs sector and are both currently 
known at N$^3$LO accuracy~\cite{Anastasiou:2015ema,Anastasiou:2016cez,
Mistlberger:2018etf,Dreyer:2016oyx}.
%
Note that  the perturbative behavior and leading partonic channels
for these processes are quite different. %
Higgs production in gluon fusion is
driven by the gluon-gluon luminosity and its perturbative expansion
converges  slowly, with manifest
convergence reached only at N$^3$LO.
%
Vector boson fusion is driven by the quark-antiquark luminosity and
it exhibits fast perturbative
 convergence.

In Table~\ref{tab:pheno-ggH} 
we present predictions for Higgs production in gluon fusion
at the LHC for $\sqrt{s}=13$ TeV.
%
We perform the calculation at NLO, NNLO and N$^3$LO in the rescaled effective theory approximation
using {\tt  ggHiggs}~\cite{Ball:2013bra,Bonvini:2014jma,Bonvini:2016frm,Ahmed:2016otz,Bonvini:2018ixe,Bonvini:2018iwt} with
$\mu_f=\mu_r=m_H/2$ as central scale, with the
NLO global sets obtained in this paper, with and without MHOUs, as 
input PDFs at all orders.
%
The results are 
displayed graphically in Fig.~\ref{fig:pheno-gghiggs}.
%

We find that for all perturbative orders the central values obtained with PDFs with and without MHOU are very similar, while the PDF uncertainty
is about 50\% larger when MHOU are included in the PDF fit.
%
This can be understood by noticing that for the intermediate values of
the momentum fraction,  $x\simeq 10^{-2}$, 
relevant for Higgs production in gluon fusion, the PDF uncertainty of
the gluon is increased in the $C+S^{(\rm 9pt)}$ fit 
as compared to the $C$-only fits, see  Fig.~\ref{fig:Global-NLO-CovMatTH}.

From Table~\ref{tab:pheno-ggH} one can also observe that the MHOU on
the hard matrix element uncertainty
$\sigma_{\mathcal{F}}^{\rm th}$ evaluated using the 9-point theory covariance matrix, Eq.~\eqref{9S},
is compatible with the canonical 7-point envelope
if the latter is symmetrised by taking the maximum value between the lower and upper uncertainties.
%
In particular, the theory covariance matrix estimate
is slightly larger than the  envelope prescription
at NLO and at NNLO, while it becomes a little smaller at N$^3$LO.
%
Even so, the NLO uncertainty band does not contain the NNLO
central value, which lies just above the edge of the band. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%5
\begin{table}[tbp]
	\centering
	\small
	\input{mhous/tables/pheno_ggHiggs.tex}
        \vspace*{3mm}
	\caption{\small The 
          total cross-sections for Higgs production in gluon fusion
	(in pb) obtained by  
          using NLO global PDFs based on either $C$ or
	$C+S^{{\rm (9pt)}}$, 
          see Table~\ref{tab:thcovmatFits}.
          %
          We quote the central prediction, the total PDF uncertainty (first) and
          the MHOU  uncertainty on the hard cross-section
	(second) expressed as a percentage of the central value. The latter is evaluated both using the theory
	covariance matrix (9-point prescription) or, in parenthesis, a
         (symmetrised) envelope of the 7-point scale variations (see
	Sect.~\ref{sec:combmhou}), obtained by taking the maximum value between the lower and upper uncertainties. }
	\label{tab:pheno-ggH}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
   \includegraphics[width=0.49\textwidth]{mhous/plots/ggHiggs.pdf}
  \includegraphics[width=0.49\textwidth]{mhous/plots/vbf.pdf}
\caption{\small Graphical
    representation of the results
    of Tables~\ref{tab:pheno-ggH} and~\ref{tab:pheno-VBF}.
At each perturbative order the pair of  uncertainty bands on the left
    (blue) is computed with PDFs
based on the  experimental covariance matrix $C$,
while the pair of  uncertainty
bands on the right (red) with  PDFs
based on the combined experimental and 
theoretical covariance matrix $C+S$ (9-point prescription).
%
The light-shaded bands represent the uncertainty on the hard cross-section 
(``scale uncertainty'') evaluated using the theory
covariance matrix (see text)
the dark bands represent the PDF uncertainty.
    \label{fig:pheno-gghiggs} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We conclude that using NLO PDFs in the N$^3$LO calculation, the
inclusion of MHOU in the PDFs translates into a few 
per-mille increase of the PDF uncertainty at the cross-section level.  
In Ref.~\cite{Anastasiou:2016cez} NNLO PDFs were used with the
N$^3$LO calculation in order to provide a state-of-the art result, and
a MHOU uncertainty on the NNLO PDF was estimated based on the
difference between results obtained using NLO and NNLO PDFs. Once NNLO
PDFs with MHOUs determined within our approach are available it
will be interesting to compare our results with this estimate.

We now turn  to Higgs production in vector boson fusion.
We perform the calculation at N$^3$LO accuracy
using {\tt proVBFH-inclusive}~\cite{Cacciari:2015jma,Dreyer:2016oyx}.
with central factorization and renormalization scales set equal
to the squared four-momentum of the vector boson. 
% 
Results are collected in Table~\ref{tab:pheno-VBF} and shown
in Fig.~\ref{fig:pheno-gghiggs}.  
The  MHOU corrections to the PDFs are very small, so 
PDF uncertainties with or without theory covariance matrix are very similar.
Also in this case, like for gluon fusion, the uncertainty on the hard
matrix element computed with the
9-point theory covariance matrix
is similar to the one obtained by symmetrizing the 7-point envelope. 

The smallness of the MHOU in the PDF follows from the fact that VBF 
Higgs production
is driven by the quark-antiquark luminosity, which in turn is
dominated by the quark PDF in the data region, whose uncertainties,
as we have seen
in Sect.~\ref{sec:globmhou}, are almost unaffected by the inclusion of
MHOU.
On the other hand, in Sect.~\ref{sec:globmhou} we have also seen that
MHOUs have the effect of moving the central value of the PDFs in the data
region towards the NNLO result, and indeed,
the shift in the central value of the VBF cross-section
due to the MHOU turns out to be significant, by an amount which is
comparable to the MHOU $\sigma_{\mathcal{F}}^{\rm th}$ on the
NLO matrix element, and indeed the shift when going from NLO to 
NNLO matrix elements, and thus much larger that the corresponding 
N$^3$LO correction.

We conclude that for VBF the main effect of including the MHOU in the PDF 
is a significant shift in the central value of the prediction. Also in this case
estimates of the MHOU on the NNLO PDF were presented in
Ref.~\cite{Dreyer:2016oyx}, and it will be interesting to compare them
to our approach once NNLO PDFs with MHOU determined within our
approach are available.
%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
	\centering
	\small
	\input{mhous/tables/pheno_VBF.tex}
        \vspace*{3mm}
	\caption{Same as Table~\ref{tab:pheno-ggH}, now for Higgs production in vector boson fusion.}
	\label{tab:pheno-VBF}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Top quark pair production}
\label{sec:top}

We now study the impact of the PDF-related MHOU on the
total top-quark pair production cross-section at the LHC for
different center-of-mass energies.
In Table~\ref{tab:pheno-ttbar} we collect, using the same
format as Table~\ref{tab:pheno-ggH}, the  predictions
for the top-quark pair-production cross-sections at $\sqrt{s}=7$, 8 and 13 TeV
obtained using the {\tt top++} code~\cite{Czakon:2011xx} and setting
the central scales to $\mu_f=\mu_r=m_t=172.5$ TeV.
%
The results in the case of 8 and 13 TeV are also displayed in Fig.~\ref{fig:pheno-ttbar}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
	\centering
	\small
	\input{mhous/tables/pheno_ttbar}
        \vspace*{3mm}
	\caption{\small
        Same as Table~\ref{tab:pheno-ggH}, now for
        top-quark pair-production at $\sqrt{s}=7,8$ and 13 TeV.}
	\label{tab:pheno-ttbar}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.49\textwidth]{mhous/plots/tt_8tev.pdf}
    \includegraphics[width=0.49\textwidth]{mhous/plots/tt_13tev.pdf}
    \caption{\small Same as Fig.~\ref{fig:pheno-gghiggs}
    for top-quark pair production at 8 and 13 TeV,
    see also Table~\ref{tab:pheno-ttbar}.
    \label{fig:pheno-ttbar} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Just as in the case of Higgs production via gluon-gluon fusion,
we find  that for top-quark pair production the central values obtained with 
PDFs with and without MHOU are rather similar, and well within the one-$\sigma$
PDF uncertainty.
%
We also observe that the PDF uncertainty at $\sqrt{s}=7$ and 8 TeV (13 TeV) 
is about 50\% (20\%) larger once MHOU are included in the determination of the PDFs. 
%
This is again compatible with the  corresponding behavior of the gluon PDF shown in 
Fig.~\ref{fig:Global-NLO-CovMatTH}, where it can be observed that, for $x\simeq 0.1$, 
relevant for top pair production at $\sqrt{s}=7$ and 8 TeV, the PDF uncertainty is increased
in the $C+S^{\rm (9pt)}$ fit as compared to the $C$-only fit, while
this increase is less marked for $x\sim 0.3$, relevant for top pair production at $\sqrt{s}=13$ TeV.
%
In addition, we note once again that the uncertainty on the hard
cross-section
$\sigma_{\mathcal{F}}^{\rm th}$
evaluated using the 9-point covariance matrix is rather
similar to that obtained from the  symmetrised 7-point envelope.
%
 In particular, the 9-point result is slightly larger (smaller) than the 7-point envelope at NNLO (NLO).
Finally, from Fig.~\ref{fig:pheno-ttbar} we notice that for this process
the  MHOU on the hard cross-section  
dominates the PDF uncertainty (with or without MHOU included), 
even with NLO PDFs.


\subsection{$Z$ and $W$ gauge boson production}
\label{sec:zw}
%
We finally turn to gauge boson production, for which we obtain predictions
using  the computational framework {\tt Matrix}~\cite{Grazzini:2017mhc}.
In this formalism, all tree-level and one-loop amplitudes are 
obtained from {\tt
OpenLoops}~\cite{Cascioli:2011va,Matsuura:1988sm,Denner:2016kdg}. 
For these theoretical predictions for  inclusive $W$ and $Z$ production cross sections at
$\sqrt{s}$ = 13 TeV, we adopt realistic kinematic cuts similar to those
applied by ATLAS and CMS.
%
The fiducial phase space for the $W^{\pm}$ cross-section is defined
by requiring $p_{l,T}\ge 25$ GeV and $\eta_{l} \le$ 2.5 for the charged lepton
transverse momentum and pseudo-rapidity and a missing energy
from the neutrino of $p_{\nu,T}\ge 25$ GeV.
%
In the case of $Z$ production, we require 
$p_{l,T}\ge$ 25 GeV and $|\eta_l|\le$ 2.5 for the charged leptons
transverse momentum and rapidity and 66 $\le m_{ll} \le$ 116 GeV for 
the di-lepton invariant mass.

In Table~\ref{tab:pheno-ZW} we display a similar
comparison as in Table~\ref{tab:pheno-ggH} now for
        $W$ and $Z$ gauge boson production at $\sqrt{s}=13$ TeV.
%
The corresponding graphical representation of the results is provided in
Fig.~\ref{fig:pheno-zw}, again using the same conventions as in
Fig.~\ref{fig:pheno-gghiggs}.

We find that when including the
 MHOU the PDF uncertainty
is increased by
$\simeq 70\%, 30\%$ and $75\%$ for $Z$, $W^+$, and $W^-$ production
 respectively. 
Given that $W$ and $Z$ production at ATLAS and CMS at $\sqrt{s}=13$ TeV
is sensitive to the light sea quarks down to $x\simeq 10^{-3}$, this increase
in the PDF uncertainty once MHOU are accounted for is consistent
with the corresponding increase reported in the case
of the singlet PDF in Fig.~\ref{fig:Global-NLO-CovMatTH-prescriptions-uncertainties}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
  \centering
  \small
  \input{mhous/tables/pheno_ZW.tex}
  \vspace{2mm}
  \caption{Same as Table~\ref{tab:pheno-ggH}, now for
        $W$ and $Z$ gauge boson production at $\sqrt{s}=13$ TeV. The cross-section 
         is given in nb.}
  \label{tab:pheno-ZW}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[t]
  \begin{center}
    \includegraphics[width=0.48\textwidth]{mhous/plots/z_13tev.pdf}
    \includegraphics[width=0.48\textwidth]{mhous/plots/wp_13tev.pdf}
    \includegraphics[width=0.48\textwidth]{mhous/plots/wm_13tev.pdf}
    \caption{\small Same as Fig.~\ref{fig:pheno-gghiggs}
    for $W^\pm$ and $Z$ gauge boson production
    at $\sqrt{s}=13$ TeV,
    see also Table~\ref{tab:pheno-ZW}.
    \label{fig:pheno-zw} }
  \end{center}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Similarly to  Higgs production in vector-boson-fusion, we find that
the inclusion of MHOU in the PDF shifts the central value of the prediction, 
by an amount
which is comparable to or larger than the data-driven PDF uncertainty.
%
We  conclude that for weak gauge boson production at
the LHC the impact of the MHOU associated to the PDFs is twofold: on
the one hand an overall 
increase in the PDF uncertainties that ranges between 30\% and 70\% depending on the process,
and on the other hand a shift in the central values which is comparable to that
of the PDF uncertainties of the fit without MHOU.


\section{Usage and delivery}
\label{sec:usage}

As mentioned previously, the PDF sets with MHOU presented in
Sect.~\ref{sec:fitstherr} 
can be used in essentially the same way as the standard NNPDF
sets.
%
In this section we discuss how MHOUs included in PDF sets should
be combined with those in hard matrix elements, specifically
addressing some conceptual issues, and we then
provide detailed instructions for their use.
%
We then discuss the delivery of the
PDF sets presented in
this work, and provide a list of the sets which are being made publicly
available by means of the {\tt LHAPDF} interface.

\FloatBarrier

\subsection{Combining MHOUs in PDFs and hard matrix elements}
\label{sec:combmhou}

As discussed in the introduction, the MHOU on PDFs discussed in this
paper arise due to the fact that PDFs are determined using perturbative
computations performed at finite order in the perturbative expansion,
and it manifests itself in the fact that PDFs change when varying the order 
at which they are
determined: in other words, NLO and NNLO PDFs differ.
%
We have further seen in
Sect.~\ref{sec:scalevarn} that there exist two distinct 
sources of MHOU in the PDF: that related to MHOs in the computation of
the hard cross-sections for those processes used for PDF determination, and
that coming from MHOs in the anomalous dimensions.
%
These two sources of MHOU in the PDFs
are respectively associated with
renormalization and factorization scale variation and can be treated
as independent of each other, at least
with the definition given here and summarized in
Table~\ref{tab:scale_nomenclature}.

Thus when considering a factorised
prediction for a PDF-dependent hard process not used in the 
determination of the PDFs, 
but rather predicted using a given PDF set, there are two independent
sources of MHOUs: those specific to the hard process itself (in the hard
cross-section for the process and in the evolution of the PDF to the scale of the process), and those in the PDF (due the MHOUs in the hard cross-sections and evolution kernels used to determine the PDF).
%
Clearly, each of these two sources receives contributions from both
renormalization and factorization scale variation.
%
This immediately raises the question as to whether some of these 
uncertainties are correlated, and if this is the case
how and whether this correlation should
be kept into account.

A first obvious source of correlation arises when producing a
prediction for a process which is among those included  for the PDF
determination.
%
Examples of this category of processes are top quark pair and gauge boson production, discussed
in Sect.~\ref{sec:pheno} and which are already included among the processes of
Table~\ref{tab:datasets_process_categorisation}.
%
The MHOU coming from
renormalization scale variation is then in principle
correlated.
%
Indeed, we know from Fig.~\ref{fig:corrmats} that any two
predictions for the same physical process are highly correlated.
%
This correlation is not taken into account if the MHOU in the
PDF and in the hard matrix element are simply combined in quadrature,
as will be recommended in Sect.~\ref{eq:unccomp}.
%
This correlation is mostly positive,
e.g. between predictions for the same process for points which are
kinematically close, so neglecting it provides a conservative estimate
of uncertainties, but it may also be negative, for points in different
regions of phase space, or perhaps for different observables related
to the same process, such as e.g. a rapidity and a transverse momentum
distribution. 

Given that we have demonstrated that MHOU on PDFs are generally small, and that most individual
processes give a relatively small contribution in a global fit based on a wide dataset (see
e.g. Ref.~\cite{Ball:2017nwa}), this lack of correlation is likely to be
a very small or even negligible effect.
%
However, if it is felt that a particular
process should be predicted in a way that is free of this problem, the
only completely safe way to proceed would be to remove that process from the
dataset used for PDF determination.
%
The situation here is akin to what
happens when one wishes to avoid the
prediction for a given process to be biased
by the inclusion of that same process in the PDF determination.
%
Indeed, several
PDF sets in which specific datasets are removed were presented and discussed in
Ref.~\cite{Ball:2017nwa}, and additional custom-made sets excluding particular
datasets have been provided for specific applications.

A potentially more serious problem was recently raised in
Ref.~\cite{Harland-Lang:2018bxd}, where it was pointed out that the
factorization scale dependence of the PDF and the hard matrix element
are strongly correlated, and in fact fully correlated for a process
(such as nonsinglet deep-inelastic structure function) which
depends on one PDF only.
%
This can be easily understood recalling that
factorization scale variation estimates MHOU in the anomalous
dimension, and thus in perturbative evolution.
%
Consider then
a PDF set in which all PDFs are parametrised at a
certain scale $Q_0$.
%
Assume for the sake of argument that one wishes to
predict a hard process whose scale $Q$ is this same scale $Q_0$.
%
It is clear that then there should be no evolution uncertainty, and thus one
should not vary the factorization scale in the hard matrix
element.
%
This is the limiting case of the cases discussed in
Ref.~\cite{Harland-Lang:2018bxd}: the MHOU related to factorization
scale, being related to perturbative evolution, is in principle
correlated between
the process used for PDF determination and the process which is being
predicted in a way that only depends on the evolution length.

However, further reflection shows that this correlation is always
lost for realistic PDF determinations, because PDF sets are
parametrised at a (typically low) scale $Q_0$ which does not coincide
with the scale of typical hard processes, and that is actually in most cases
below the minimum kinematic cut $Q_{\rm min}$.
%
This implies that the information on the
correlation of the evolution uncertainty when evolving back to the scale of 
hard processes is lost when constructing the PDF set at $Q_0$.
%
In principle, one could produce various PDF sets,
each parametrised at the scale of an individual process, such as
``Higgs PDFs'' with $Q_0=m_H/2$ (the scale of Higgs production),
``Drell-Yan PDFs''with $Q_0=m_Z$, and so on.
%
Predictions obtained with these PDFs
for the corresponding processes would then have all factorization scale
uncertainties (due to evolving from the scales of data used in the PDF 
fit to $Q_0$) already incorporated into the PDF uncertainty, so the only 
additional uncertainty in the prediction would be that from renormalization 
scale variation of the hard cross-section. However the price to pay would 
be loss of PDF universality: the ``Higgs PDFs'' and ``Drell-Yan PDFs'' would 
be different, in the sense that one could no longer be obtained from the 
other entirely through fixed order evolution.

Note that the correlation of factorization scale between all processes
used for PDF determination is instead fully accounted for by our
formalism, and is included in the theory covariance matrix when
adopting any prescription (such as our default 9-point prescription)
in which factorization scale variation is fully correlated.
%
Therefore,
in practice, by neglecting this correlation in factorization scale between the evolution to $Q_0$ in the PDF determination and the evolution from $Q_0$ when making our prediction, we are at worst producing an overestimate of the MHOU.
%
Given the moderate effect of MHOUs on PDFs, this is likely to be a small effect.

We conclude that the uncorrelated combination of the MHOU on the PDF with the 
MHOU of the hard matrix element of the predicted process is both pragmatic 
and realistic, especially given the well known uncertainties intrinsic to 
the estimation of MHOUs. 

\subsection{Computation of the total uncertainty}
\label{eq:unccomp}

Having concluded that uncorrelated combination of the MHOU on the PDF
and on the hard matrix element is justified, we summarize
our procedure for computing uncertainties in practice.

To begin with, the PDF uncertainty $\sigma^{\rm PDF}_{\mathcal{F}}$
associated with a given cross-section $\mathcal{F}$ is  evaluated
as usual in the NNPDF methodology as the standard deviation over the
replica set:
 \be
\sigma^{\rm PDF}_{\mathcal{F}} =
\left( \frac{1}{N_{\rm rep}-1}
\sum_{k=1}^{N_{\rm rep}}   
\lp \mathcal{F} [ \{  q^{(k)} \}] 
-   \la \mathcal{F} [ \{  q \}] \ra\rp^2 
 \right)^{1/2}.
 \label{eq:mastersig}
 \ee
%
If this prescription is applied to a PDF set with ``standard'' PDF uncertainty (such as the published
NNPDF3.1~\cite{Ball:2017nwa}) set, the resulting uncertainty only includes
the correlated statistical and systematic uncertainties from the data,
and the methodological uncertainty intrinsic to any PDF fit.
%
If the PDF sets including MHOU
presented in Sect.~\ref{sec:results}
of this paper are used instead, the resulting uncertainty obtained
from Eq.~(\ref{eq:mastersig}) accounts for both the data-driven
and MHOU on the PDF, with all correlations taken into account.

Because the MHOU on the hard matrix element is treated as uncorrelated
to the PDF uncertainty, it can in principle be computed with any
prescription preferred by the end-user.
%
A commonly used
prescription is 7-point scale variation~\cite{deFlorian:2016spz}.
%
Our preferred prescription is instead to use the same methodology as used for
the computation of the theory covariance matrix.
%
In this case, the uncertainty on
the cross-section $\mathcal{F}$ is then simply the corresponding diagonal 
entry of the covariance matrix element, namely
\begin{equation}\label{eq:thuncmh}
\sigma_{\mathcal{F}}^{\rm th} = \left[S^{(\rm 9pt)}_{{\mathcal{F}}{\mathcal{F}}}\right]^{1/2},
\end{equation}
where $S^{(\rm 9pt)}_{{\mathcal{F}}{\mathcal{F}}}$ is evaluated using  our default
9-point prescription defined by
Eq.~\eqref{9S}, with $\Delta_{ij}$ computed for $i=j=\mathcal{F}$,
i.e. the theory prediction for the given observable.
%
We showed in 
Sect.~\ref{sec:pheno} that for various standard candles our 9-point theory 
covariance matrix prescription and the 7-point envelope prescription give 
very similar results, provided the envelope prescription is symmetrized.

The PDF uncertainty Eq.~(\ref{eq:mastersig}) and the uncertainty on
the hard matrix element Eq.~(\ref{eq:thuncmh}) can then be combined as
uncorrelated uncertainties.
%
For instance, one can combine them in quadrature and thus the total
uncertainty on the cross-section $\mathcal{F}$ is simply
\be
\sigma_{\mathcal{F}}^{\rm tot} = \lp \lp \sigma_{\mathcal{F}}^{\rm th} \rp^2 + \lp \sigma^{\rm PDF}_{\mathcal{F}}
\rp^2\rp^{1/2} \, .
\ee

Note that when using a $\chi^2$ to assess the quality of the agreement between 
experimental data and the associated theory predictions for a PDF set which includes MHOUs, the MHOU must be always be included in the definition of the 
$\chi^2$ estimator, ideally (though not necessarily) by means of the 
theory covariance matrix.
%
This is because, as seen in Sect.~\ref{sec:globmhou}, the inclusion of 
MHOU modifies the best-fit central value, and thus if the MHOU were 
not included in the $\chi^2$, these PDFs would not provide the best fit, and 
the results might be misleading.
%
In this sense, the theory covariance matrix should be regarded as an 
additional systematic uncertainty, specific to the determination of PDFs 
from the data, to be added in quadrature to the usual experimental systematics.

 
\subsection{Delivery}
\label{sec:delivery}

The variants of the NNPDF3.1 NLO global sets presented in this work are publicly available
in the {\tt LHAPDF} format~\cite{Buckley:2014ana} from the NNPDF website:

\begin{center}
 \href{http://nnpdf.mi.infn.it/nnpdf3-1th/}{\tt http://nnpdf.mi.infn.it/nnpdf3-1th/}
\end{center}

\noindent
In the following, we list the PDF sets that are made available.
%
The NLO sets based on the theory covariance matrix are: 
\begin{center}
  \tt NNPDF31\_nlo\_as\_0118\_scalecov\_9pt \\
  \tt NNPDF31\_nlo\_as\_0118\_scalecov\_7pt \\
  \tt NNPDF31\_nlo\_as\_0118\_scalecov\_3pt
\end{center}
which correspond to the fits based on Eq.~(\ref{eq:chi2_v3})
in the cases in which the theory covariance matrix $S_{ij}$ has been evaluated with
the 9-, 7-, and 3-point prescriptions, respectively.
%

We have also constructed NLO PDF sets based on 
scale-varied theories, to be discussed in
Appendix~\ref{sec:fitsscalesvar} below. These are  determined
using Eq.~(\ref{eq:chi2_v2}), and they are
\begin{center}
  \tt NNPDF31\_nlo\_as\_0118\_kF\_1\_kR\_1 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_2\_kR\_2 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_0p5\_kR\_0p5 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_2\_kR\_1 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_1\_kR\_2 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_0p5\_kR\_1 \\
  \tt NNPDF31\_nlo\_as\_0118\_kF\_1\_kR\_0p5 
\end{center}
where the naming convention indicates the values of the scale ratios $k_f$ and $k_r$.
%
Note that the {\tt NNPDF31\_nlo\_as\_0118\_kF\_1\_kR\_1} set is also the baseline (central scales and
experimental covariance matrix only) to be used in the comparisons with the fits based
on the theory covariance matrix listed above.
%
Finally, we also provide the set
\begin{center}
  \tt NNPDF31\_nnlo\_as\_0118\_kF\_1\_kR\_1
\end{center}
which corresponds to the NNLO fit with central scales and
experimental covariance matrix only, that has been produced for validation purposes.

It is  important to bear in mind
that the variants of the NNPDF3.1 fits presented in this work
are based on a somewhat different dataset to that used in the default 
NNPDF3.1 analysis.
%
Therefore, when using these sets it is important to be consistent:
for example by
comparing fits with and without MHOU that are based on a common input dataset.

In addition to the sets listed above, the other PDF sets presented in this paper, such as the DIS-only fits based on scale-varied calculations and on the theory covariance matrix, are available from the authors upon request.

\section{Summary and outlook}
\label{sec:summary}

In this work we have presented the first PDF determination that includes 
MHOU as part of the PDF uncertainty.
%
This is in principle required for consistency,
given that MHOU are routinely part of the theoretical predictions for hadron
collider processes, and likely to become a requirement for precision collider
phenomenology as other sources of uncertainties decrease.

The bulk of our work amounted to establishing a general
language and formalism for the inclusion of MHOU when multiple
processes  are considered at once in the global PDF fit, constructing 
prescriptions for
estimating these MHOU by means of scale variation, and for validating them
in cases in which the higher order corrections are known.
%
The formalism presented here is sufficiently flexible that it can also be
applied to different sources of theoretical uncertainty, such as nuclear
corrections or higher twists, and could also be used in
conjunction with alternative ways of estimating MHOU, such as for example 
the Cacciari-Houdeau method.

The validation studies presented here suggest however that the conventional 
scale variation method to estimate the MHOU works remarkably well.
%
Indeed, when coupled to the
theory covariance matrix formalism that we introduced, this method turns 
out to be free of
the instabilities that plague envelope techniques, and it leads to results
which appear to be reasonably stable and thus insensitive to the arbitrary
choices that are inherent to its implementation.
%
The reason for these properties is
essentially that, within a covariance matrix approach, possible
directions which do not correspond to actual MHO have no impact on the fitting.

Our results however also suggest that even more realistic estimates of
MHOU might be obtained through more complex patterns of scale variation 
than those considered here.
%
For example, it might be advantageous to vary 
independently the renormalization scales in different partonic
sub-channels, or the factorization scales for singlet, nonsinglet and 
valence partons that evolve independently.
%
Indeed, we have observed from the validation of our
estimate of MHOU, while always reasonably successful for the datasets
considered here, deteriorates as the size of the dataset increases,
which suggests that more complex structures  might be advantageous.
%
Here we have performed a first investigation, and the
exploration of these more complex patterns of scale variation will be 
left for future work.

On the phenomenological side, our results show that at least at NLO the
main effect of the inclusion of MHOU in PDF determination is to
improve the accuracy of the result, while not significantly reducing
its precision.
%
Indeed, whenever experimental information is abundant,
in particular for a global dataset, we have found that the
total PDF uncertainty is only moderately affected by the inclusion 
of MHOU --- in fact, for the datapoints included in PDF determination 
it even decreases --- but the central value moves close to the true
result.
%
Moreover, the fit quality improves, thereby showing that the main effect 
of the inclusion of MHOU is in reducing tensions between datasets due to 
imperfections in their theoretical description.

The most interesting future phenomenological development will be of
course the extension of our methodology to the determination of MHOU
in a state-of-the-art global NNLO PDF set.
%
It will be interesting to
assess to what extent the behaviour observed at NLO persists there.
%
More generally, the inclusion of MHOU at NNLO is expected to lead to 
the most precise and accurate PDF sets that can be determined with 
currently available theoretical and experimental information.













